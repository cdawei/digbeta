{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple example of  multilable learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os, sys, time\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import cython\n",
    "from scipy.io import arff\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "yeast_ftrain = os.path.join(data_dir, 'yeast/yeast-train.arff')\n",
    "yeast_ftest  = os.path.join(data_dir, 'yeast/yeast-test.arff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load yeast dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train, meta_train = arff.loadarff(yeast_ftrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_test, meta_test = arff.loadarff(yeast_ftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(data_train[0])[:-14], dtype=np.float).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(data_train[0])[-14:], dtype=np.int).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nFeatures = 103\n",
    "nLabels = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "917"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a logistic regression model for each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_training_set(label_ix, data):\n",
    "    \"\"\"\n",
    "        Create the labelled dataset for a given label index\n",
    "        \n",
    "        Input:\n",
    "            - label_ix: label index, number in { 0, ..., # labels }\n",
    "            - data: original data with features + labels\n",
    "            \n",
    "        Output:\n",
    "            - (Feature, Label) pair (X, y)\n",
    "              X comprises the features for each example\n",
    "              y comprises the labels of the corresponding example\n",
    "    \"\"\"\n",
    "\n",
    "    assert(label_ix >= 0)\n",
    "    assert(label_ix < nLabels)\n",
    "\n",
    "    N = len(data)\n",
    "    d = nFeatures\n",
    "\n",
    "    X = np.zeros((N, d), dtype = np.float)\n",
    "    y = np.zeros(N, dtype = np.int)\n",
    "       \n",
    "    for i in range(N):\n",
    "        X[i, :] = list(data[i])[:-14]\n",
    "        y[i]    = list(data[i])[-14:][label_ix]\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss between a ground truth and a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evalPred(truth, pred, lossType = 'Hamming'):\n",
    "    \"\"\"\n",
    "        Compute loss given ground truth and prediction\n",
    "        \n",
    "        Input:\n",
    "            - truth:    binary array of true labels\n",
    "            - pred:     real-valued array of predictions\n",
    "            - lossType: can be subset 0-1, Hamming, ranking, and Precision@K where K = # positive labels.\n",
    "    \"\"\"\n",
    "\n",
    "    assert(len(truth) == len(pred))\n",
    "    L = len(truth)\n",
    "    nPos = np.sum(truth)\n",
    "    \n",
    "    predBin = np.array((pred > 0), dtype=np.int)\n",
    "    \n",
    "    if lossType == 'Subset01':\n",
    "        return 1 - int(np.all(truth == predBin))\n",
    "    \n",
    "    elif lossType == 'Hamming':\n",
    "        return np.sum(truth != predBin) / L\n",
    "    \n",
    "    elif lossType == 'Ranking':\n",
    "        loss = 0\n",
    "        for i in range(L-1):\n",
    "            for j in range(i+1, L):\n",
    "                if truth[i] > truth[j]:\n",
    "                    if pred[i] < pred[j]: \n",
    "                        loss += 1\n",
    "                    if pred[i] == pred[j]:\n",
    "                        loss += 0.5\n",
    "        #return loss / (nPos * (L-nPos))\n",
    "        return loss\n",
    "        \n",
    "    elif lossType == 'Precision@K':\n",
    "        # sorted indices of the labels most likely to be +'ve\n",
    "        idx = np.argsort(pred)[::-1]\n",
    "        \n",
    "        # true labels according to the sorted order\n",
    "        y = truth[idx]\n",
    "        \n",
    "        # fraction of +'ves in the top K predictions\n",
    "        return np.mean(y[:nPos])\n",
    "    \n",
    "    else:\n",
    "        assert(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printEvaluation(allPreds, allTruths):\n",
    "\n",
    "    for lossType in ['Subset01', 'Hamming', 'Ranking', 'Precision@K']:\n",
    "        losses = [ ]\n",
    "        for i in range(allPreds.shape[0]):\n",
    "            pred  = allPreds[i, :]\n",
    "            truth = allTruths[i, :]\n",
    "            losses.append(evalPred(truth, pred, lossType))\n",
    "\n",
    "            #print(allPreds[i])\n",
    "            #print(pred)\n",
    "            #print(truth)\n",
    "            #break\n",
    "\n",
    "        print('%24s: %1.4f' % ('Average %s Loss' % lossType, np.mean(losses)))\n",
    "        #plt.hist(aucs, bins = 10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary relevance baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers = [ LogisticRegression(class_weight = 'balanced', C = 10**0) for i in range(nLabels) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allPreds  = [ ]\n",
    "allTruths = [ ]\n",
    "coefMat = [ ]\n",
    "labelIndices = [ ]\n",
    "\n",
    "for label_ix in range(nLabels):\n",
    "    X_train, y_train = gen_training_set(label_ix, data = data_train)\n",
    "    X_test, y_test   = gen_training_set(label_ix, data = data_test)\n",
    "    \n",
    "    allTruths.append(y_test) \n",
    "    \n",
    "    assert( (not np.all(y_train == 0)) or (not np.all(y_train == 1)) )\n",
    "\n",
    "    classifiers[label_ix].fit(X_train, y_train)\n",
    "    allPreds.append(classifiers[label_ix].decision_function(X_test))\n",
    "\n",
    "    coefMat.append(classifiers[label_ix].coef_.reshape(-1))\n",
    "    #labelIndices.append(label_ix)\n",
    "    #print(classifiers[label_ix].coef_)\n",
    "    #print(classifiers[label_ix].intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(917, 14)\n",
      "(917, 14)\n"
     ]
    }
   ],
   "source": [
    "allPreds  = np.array(allPreds).T\n",
    "allTruths = np.array(allTruths).T\n",
    "\n",
    "print(allPreds.shape)\n",
    "print(allTruths.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.15997494, -0.51477752, -1.18553419,  0.21972233,  0.96896183,\n",
       "        0.00853919,  0.32721911,  0.37575265, -0.80121226, -2.4663948 ,\n",
       "       -1.79701745,  0.92752986,  0.89316058, -2.04288556])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allPreds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Average Subset01 Loss: 0.9302\n",
      "    Average Hamming Loss: 0.3325\n",
      "    Average Ranking Loss: 5.2203\n",
      "Average Precision@K Loss: 0.5149\n"
     ]
    }
   ],
   "source": [
    "printEvaluation(allPreds, allTruths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coefficient matrix `(#Genres, #Songs)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coefMat = np.array(coefMat).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 14)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefMat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sns.heatmap(coefMat[:, :30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary relevance with bipartite ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%cython -a\n",
    "\n",
    "import numpy as np\n",
    "#cimport numpy as np\n",
    "\n",
    "#cpdef obj_rank(w, X, y):\n",
    "\n",
    "def obj_rank(w, X, y):\n",
    "    \"\"\"\n",
    "        Pairwise ranking objective\n",
    "        \n",
    "        Input:\n",
    "            - w: current weight vector\n",
    "            - X: feature matrix, N x D\n",
    "            - y: label vector,   N x 1\n",
    "    \"\"\"\n",
    "    assert(len(y) == X.shape[0])\n",
    "    assert(len(w) == X.shape[1])\n",
    "\n",
    "    #cdef int nPos, nNeg, i, j\n",
    "    #cdef double J, term, denom\n",
    "    nPos = np.sum(y)      # num of positive examples\n",
    "    nNeg = len(y) - nPos  # num of negative examples\n",
    "    \n",
    "    ixPos = np.nonzero(y)[0].tolist()                    # indices positive examples\n",
    "    ixNeg = list(set(np.arange(len(y))) - set(ixPos))    # indices negative examples\n",
    "    \n",
    "    J = 0.0  # cost\n",
    "    g = np.zeros_like(w)  # gradient    \n",
    "\n",
    "    scorePos = X[ixPos, :].dot(w)[:,np.newaxis] # nPos x 1\n",
    "    scoreNeg = X[ixNeg, :].dot(w)[:,np.newaxis] # nNeg x 1\n",
    "    scoreDif = scorePos - scoreNeg.T            # nPos x nNeg\n",
    "    #J = np.mean(np.log(1 + np.exp(-scoreDif)))\n",
    "    J = 0.5 * np.dot(w, w) + np.mean(np.log1p(np.exp(-scoreDif)))\n",
    "    \n",
    "    A = -1/(1 + np.exp(scoreDif))\n",
    "\n",
    "    T1 = X[ixPos, :].T.dot(A.sum(axis = 1))\n",
    "    T2 = X[ixNeg, :].T.dot(A.sum(axis = 0))\n",
    "    g  = w + 1/(nPos * nNeg) * (T1 - T2)\n",
    "    \n",
    "    return (J, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 14 \n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.687650\n",
      "         Iterations: 5\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "2 / 14 \n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.690264\n",
      "         Iterations: 5\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "3 / 14 \n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.687208\n",
      "         Iterations: 5\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "4 / 14 \n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.684365\n",
      "         Iterations: 5\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "5 / 14 \n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.687649\n",
      "         Iterations: 5\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "6 / 14 \n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.689686\n",
      "         Iterations: 5\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "7 / 14 \n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.690316\n",
      "         Iterations: 5\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "8 / 14 \n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.690929\n",
      "         Iterations: 5\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "9 / 14 \n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.690514\n",
      "         Iterations: 5\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "10 / 14 \n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.689401\n",
      "         Iterations: 5\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "11 / 14 \n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.690708\n",
      "         Iterations: 5\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "12 / 14 \n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.690920\n",
      "         Iterations: 5\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "13 / 14 \n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.690952\n",
      "         Iterations: 5\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "14 / 14 \n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.682634\n",
      "         Iterations: 5\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n"
     ]
    }
   ],
   "source": [
    "params    = [ ]\n",
    "allPreds  = [ ]\n",
    "allTruths = [ ]\n",
    "\n",
    "for label_ix in range(nLabels):\n",
    "    #sys.stdout.write('\\r%d / %d' % (label_ix + 1, nLabels))\n",
    "    #sys.stdout.flush()\n",
    "    print('\\r%d / %d ' % (label_ix + 1, nLabels))\n",
    "    \n",
    "    X_train, y_train = gen_training_set(label_ix, data = data_train)\n",
    "    X_test, y_test   = gen_training_set(label_ix, data = data_test)\n",
    "    \n",
    "    allTruths.append(y_test) \n",
    "    \n",
    "    assert( (not np.all(y_train == 0)) or (not np.all(y_train == 1)) )\n",
    "        \n",
    "    opt_method = 'BFGS' #'Newton-CG' \n",
    "    #opt_method = 'nelder-mead'\n",
    "    options = {'disp': True}\n",
    "    \n",
    "    w = np.random.rand(X_train.shape[1])  # initial guess\n",
    "    opt = minimize(obj_rank, w, args=(X_train, y_train), method=opt_method, jac=True, options=options)\n",
    "    \n",
    "    if opt.success == True:\n",
    "        w = opt.x\n",
    "        params.append(w)\n",
    "        allPreds.append(np.dot(X_test, w))\n",
    "    else:\n",
    "        sys.stderr.write('Optimisation failed, label_ix=%d\\n' % label_ix)\n",
    "        w = np.zeros(X_train.shape[1])\n",
    "        params.append(w)\n",
    "        allPreds.append(np.dot(X_test, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(917, 14)\n",
      "(917, 14)\n"
     ]
    }
   ],
   "source": [
    "allPreds = np.array(allPreds).T\n",
    "allTruths = np.array(allTruths).T\n",
    "\n",
    "print(allPreds.shape)\n",
    "print(allTruths.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0104151 , -0.02343351, -0.01492025,  0.04254992,  0.03156288,\n",
       "       -0.02135415, -0.01013771, -0.01079809, -0.02023345, -0.055591  ,\n",
       "       -0.03785123,  0.02253736,  0.02141025, -0.00042799])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allPreds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Average Subset01 Loss: 0.9335\n",
      "    Average Hamming Loss: 0.4301\n",
      "    Average Ranking Loss: 7.2246\n",
      "Average Precision@K Loss: 0.4400\n"
     ]
    }
   ],
   "source": [
    "printEvaluation(allPreds, allTruths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking loss optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%cython -a\n",
    "\n",
    "import numpy as np\n",
    "#cimport numpy as np\n",
    "\n",
    "#cpdef obj_rank(w, X, y):\n",
    "\n",
    "def obj_ranking_loss(w, X, Y):\n",
    "    \"\"\"\n",
    "        Pairwise ranking objective\n",
    "        \n",
    "        Input:\n",
    "            - w: current weight vector, flattened L x D\n",
    "            - X: feature matrix, N x D\n",
    "            - Y: label matrix,   N x L\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "    L = Y.shape[1]\n",
    "    assert(w.shape[0] == L * D)\n",
    "    \n",
    "    W = w.reshape(L, D)  # reshape weight matrix    \n",
    "    \n",
    "    #cdef int nPos, nNeg, i, j\n",
    "    #cdef double J, term, denom\n",
    "    \n",
    "    J = 0.0  # cost\n",
    "    G = np.zeros_like(W)  # gradient matrix\n",
    "    \n",
    "    for n in range(N):\n",
    "        Jn = 0.0\n",
    "        Gn = np.zeros_like(W)\n",
    "        x = X[n, :]\n",
    "        y = Y[n, :]\n",
    "        nPos = np.sum(y)   # num of positive examples\n",
    "        nNeg = L - nPos    # num of negative examples\n",
    "        denom = nPos * nNeg\n",
    "        \n",
    "        ixPos = np.nonzero(y)[0].tolist()               # indices positive examples\n",
    "        ixNeg = list(set(np.arange(L)) - set(ixPos))    # indices negative examples\n",
    "        \n",
    "        for i in ixPos:\n",
    "            for j in ixNeg:\n",
    "                wDiff = W[i, :] - W[j, :]\n",
    "                sDiff = np.dot(wDiff, x)\n",
    "                Jn += np.log1p(np.exp(-sDiff))\n",
    "                Gn[i, :] = Gn[i, :] - x / (1 + np.exp(sDiff))\n",
    "                Gn[j, :] = Gn[j, :] + x / (1 + np.exp(sDiff))\n",
    "        J += Jn / denom\n",
    "        G = G + Gn / denom\n",
    "    J = 0.5 * np.dot(w, w) + J / N\n",
    "    G = W + G / N\n",
    "    \n",
    "    return (J, G.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_dataset(data):\n",
    "    \"\"\"\n",
    "        Create the labelled dataset for a given label index\n",
    "        \n",
    "        Input:\n",
    "            - data: original data with features + labels\n",
    "            \n",
    "        Output:\n",
    "            - (Feature, Label) pair (X, y)\n",
    "              X comprises the features for each example\n",
    "              Y comprises the labels of the corresponding example\n",
    "    \"\"\"\n",
    "\n",
    "    N = len(data)\n",
    "    D = nFeatures\n",
    "    L = nLabels\n",
    "\n",
    "    X = np.zeros((N, D), dtype = np.float)\n",
    "    Y = np.zeros((N, L), dtype = np.int)\n",
    "       \n",
    "    for i in range(N):\n",
    "        X[i, :] = list(data[i])[:-14]\n",
    "        Y[i, :] = list(data[i])[-14:]\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.692868\n",
      "         Iterations: 3\n",
      "         Function evaluations: 5\n",
      "         Gradient evaluations: 5\n"
     ]
    }
   ],
   "source": [
    "allPreds  = None\n",
    "allTruths = None\n",
    "\n",
    "X_train, Y_train = gen_dataset(data = data_train)\n",
    "X_test,  Y_test  = gen_dataset(data = data_test)\n",
    "\n",
    "allTruths = Y_test\n",
    "\n",
    "opt_method = 'BFGS' #'Newton-CG' \n",
    "#opt_method = 'nelder-mead'\n",
    "options = {'disp': True}\n",
    "\n",
    "w = np.random.rand(nFeatures * nLabels)  # initial guess\n",
    "opt = minimize(obj_ranking_loss, w, args=(X_train, Y_train), method=opt_method, jac=True, options=options)\n",
    "\n",
    "if opt.success == True:\n",
    "    w = opt.x\n",
    "    params.append(w)\n",
    "    allPreds = np.dot(X_test, w.reshape(nLabels, nFeatures).T)\n",
    "else:\n",
    "    sys.stderr.write('Optimisation failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(917, 14)\n",
      "(917, 14)\n"
     ]
    }
   ],
   "source": [
    "#allPreds = np.array(allPreds).T\n",
    "#allTruths = np.array(allTruths).T\n",
    "\n",
    "print(allPreds.shape)\n",
    "print(allTruths.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -5.21698486e-04,  -2.13450548e-03,  -1.21590949e-03,\n",
       "         3.85674846e-03,   2.51582389e-03,  -1.59627624e-03,\n",
       "        -5.36843205e-04,  -6.12649687e-04,  -3.77931340e-04,\n",
       "        -1.70135681e-03,  -1.38937390e-03,   1.82069781e-03,\n",
       "         1.79463600e-03,   9.86120611e-05])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allPreds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Average Subset01 Loss: 0.9433\n",
      "    Average Hamming Loss: 0.4331\n",
      "    Average Ranking Loss: 6.7612\n",
      "Average Precision@K Loss: 0.4903\n"
     ]
    }
   ],
   "source": [
    "printEvaluation(allPreds, allTruths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
