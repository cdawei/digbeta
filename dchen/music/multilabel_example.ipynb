{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple example of  multilable learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os, sys, time\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import cython\n",
    "import itertools\n",
    "\n",
    "from scipy.io import arff\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import check_grad\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "yeast_ftrain = os.path.join(data_dir, 'yeast/yeast-train.arff')\n",
    "yeast_ftest  = os.path.join(data_dir, 'yeast/yeast-test.arff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load yeast dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train, meta_train = arff.loadarff(yeast_ftrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_test, meta_test = arff.loadarff(yeast_ftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#features: 103\n"
     ]
    }
   ],
   "source": [
    "nFeatures = np.array(list(data_train[0])[:-14], dtype=np.float).shape[0]\n",
    "print('#features:', nFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#labels: 14\n"
     ]
    }
   ],
   "source": [
    "nLabels = np.array(list(data_train[0])[-14:], dtype=np.int).shape[0]\n",
    "print('#labels:', nLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#training examples: 1500\n"
     ]
    }
   ],
   "source": [
    "print('#training examples:', len(data_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#test examples: 917\n"
     ]
    }
   ],
   "source": [
    "print('#test examples:', len(data_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataset(label_ix, data):\n",
    "    \"\"\"\n",
    "        Create the labelled dataset for a given label index\n",
    "        \n",
    "        Input:\n",
    "            - label_ix: label index, number in { 0, ..., # labels }\n",
    "            - data: original data with features + labels\n",
    "            \n",
    "        Output:\n",
    "            - (Feature, Label) pair (X, y)\n",
    "              X comprises the features for each example\n",
    "              y comprises the labels of the corresponding example\n",
    "    \"\"\"\n",
    "\n",
    "    assert(label_ix >= 0)\n",
    "    assert(label_ix < nLabels)\n",
    "\n",
    "    N = len(data)\n",
    "    d = nFeatures\n",
    "\n",
    "    X = np.zeros((N, d), dtype = np.float)\n",
    "    y = np.zeros(N, dtype = np.int)\n",
    "       \n",
    "    for i in range(N):\n",
    "        X[i, :] = list(data[i])[:-14]\n",
    "        y[i]    = list(data[i])[-14:][label_ix]\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataset_v2(data):\n",
    "    \"\"\"\n",
    "        Create the labelled dataset for a given label index\n",
    "        \n",
    "        Input:\n",
    "            - data: original data with features + labels\n",
    "            \n",
    "        Output:\n",
    "            - (Feature, Label) pair (X, y)\n",
    "              X comprises the features for each example\n",
    "              Y comprises the labels of the corresponding example\n",
    "    \"\"\"\n",
    "\n",
    "    N = len(data)\n",
    "    D = nFeatures\n",
    "    L = nLabels\n",
    "\n",
    "    X = np.zeros((N, D), dtype = np.float)\n",
    "    Y = np.zeros((N, L), dtype = np.int)\n",
    "       \n",
    "    for i in range(N):\n",
    "        X[i, :] = list(data[i])[:-14]\n",
    "        Y[i, :] = list(data[i])[-14:]\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss between a ground truth and a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evalPred(truth, pred, lossType = 'Hamming'):\n",
    "    \"\"\"\n",
    "        Compute loss given ground truth and prediction\n",
    "        \n",
    "        Input:\n",
    "            - truth:    binary array of true labels\n",
    "            - pred:     real-valued array of predictions\n",
    "            - lossType: can be subset 0-1, Hamming, ranking, and Precision@K where K = # positive labels.\n",
    "    \"\"\"\n",
    "\n",
    "    assert(len(truth) == len(pred))\n",
    "    L = len(truth)\n",
    "    nPos = np.sum(truth)\n",
    "    \n",
    "    predBin = np.array((pred > 0), dtype=np.int)\n",
    "    \n",
    "    if lossType == 'Subset01':\n",
    "        return 1 - int(np.all(truth == predBin))\n",
    "    \n",
    "    elif lossType == 'Hamming':\n",
    "        return np.sum(truth != predBin) / L\n",
    "    \n",
    "    elif lossType == 'Ranking':\n",
    "        loss = 0\n",
    "        for i in range(L-1):\n",
    "            for j in range(i+1, L):\n",
    "                if truth[i] > truth[j]:\n",
    "                    if pred[i] < pred[j]: \n",
    "                        loss += 1\n",
    "                    if pred[i] == pred[j]:\n",
    "                        loss += 0.5\n",
    "        #return loss / (nPos * (L-nPos))\n",
    "        return loss\n",
    "        \n",
    "    elif lossType == 'Precision@K':\n",
    "        # sorted indices of the labels most likely to be +'ve\n",
    "        idx = np.argsort(pred)[::-1]\n",
    "        \n",
    "        # true labels according to the sorted order\n",
    "        y = truth[idx]\n",
    "        \n",
    "        # fraction of +'ves in the top K predictions\n",
    "        return np.mean(y[:nPos])\n",
    "    \n",
    "    elif lossType == 'Precision@3':\n",
    "        # sorted indices of the labels most likely to be +'ve\n",
    "        idx = np.argsort(pred)[::-1]\n",
    "        \n",
    "        # true labels according to the sorted order\n",
    "        y = truth[idx]\n",
    "        \n",
    "        # fraction of +'ves in the top K predictions\n",
    "        return np.mean(y[:3])\n",
    "    \n",
    "    elif lossType == 'Precision@5':\n",
    "        # sorted indices of the labels most likely to be +'ve\n",
    "        idx = np.argsort(pred)[::-1]\n",
    "        \n",
    "        # true labels according to the sorted order\n",
    "        y = truth[idx]\n",
    "        \n",
    "        # fraction of +'ves in the top K predictions\n",
    "        return np.mean(y[:5])\n",
    "    \n",
    "    else:\n",
    "        assert(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printEvaluation(allPreds, allTruths):\n",
    "\n",
    "    for lossType in ['Subset01', 'Hamming', 'Ranking', 'Precision@K', 'Precision@3', 'Precision@5']:\n",
    "        losses = [ ]\n",
    "        for i in range(allPreds.shape[0]):\n",
    "            pred  = allPreds[i, :]\n",
    "            truth = allTruths[i, :]\n",
    "            losses.append(evalPred(truth, pred, lossType))\n",
    "\n",
    "            #print(allPreds[i])\n",
    "            #print(pred)\n",
    "            #print(truth)\n",
    "            #break\n",
    "\n",
    "        print('%24s: %1.4f' % ('Average %s Loss' % lossType, np.mean(losses)))\n",
    "        #plt.hist(aucs, bins = 10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary relevance baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a logistic regression model for each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers = [ LogisticRegression(class_weight = 'balanced', C = 10**0) for i in range(nLabels) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allPreds  = [ ]\n",
    "allTruths = [ ]\n",
    "coefMat = [ ]\n",
    "labelIndices = [ ]\n",
    "\n",
    "for label_ix in range(nLabels):\n",
    "    X_train, y_train = create_dataset(label_ix, data = data_train)\n",
    "    X_test, y_test   = create_dataset(label_ix, data = data_test)\n",
    "    \n",
    "    allTruths.append(y_test) \n",
    "    \n",
    "    assert( (not np.all(y_train == 0)) or (not np.all(y_train == 1)) )\n",
    "\n",
    "    classifiers[label_ix].fit(X_train, y_train)\n",
    "    allPreds.append(classifiers[label_ix].decision_function(X_test))\n",
    "\n",
    "    coefMat.append(classifiers[label_ix].coef_.reshape(-1))\n",
    "    #labelIndices.append(label_ix)\n",
    "    #print(classifiers[label_ix].coef_)\n",
    "    #print(classifiers[label_ix].intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(917, 14)\n",
      "(917, 14)\n"
     ]
    }
   ],
   "source": [
    "allPreds  = np.array(allPreds).T\n",
    "allTruths = np.array(allTruths).T\n",
    "\n",
    "print(allPreds.shape)\n",
    "print(allTruths.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allPreds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Average Subset01 Loss: 0.9302\n",
      "    Average Hamming Loss: 0.3325\n",
      "    Average Ranking Loss: 5.2203\n",
      "Average Precision@K Loss: 0.5149\n",
      "Average Precision@3 Loss: 0.5209\n",
      "Average Precision@5 Loss: 0.4733\n"
     ]
    }
   ],
   "source": [
    "printEvaluation(allPreds, allTruths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coefficient matrix `(#Genres, #Songs)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coefMat = np.array(coefMat).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 14)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefMat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sns.heatmap(coefMat[:, :30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary relevance with bipartite ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%cython -a\n",
    "\n",
    "import numpy as np\n",
    "#cimport numpy as np\n",
    "\n",
    "#cpdef obj_biranking(w, X, y):\n",
    "\n",
    "def obj_biranking(w, X, y):\n",
    "    \"\"\"\n",
    "        Objective with L2 regularisation and bipartite ranking loss\n",
    "        \n",
    "        Input:\n",
    "            - w: current weight vector\n",
    "            - X: feature matrix, N x D\n",
    "            - y: label vector,   N x 1\n",
    "    \"\"\"\n",
    "    assert(len(y) == X.shape[0])\n",
    "    assert(len(w) == X.shape[1])\n",
    "\n",
    "    #cdef int nPos, nNeg, i, j\n",
    "    #cdef double J, term, denom\n",
    "    nPos = np.sum(y)      # num of positive examples\n",
    "    nNeg = len(y) - nPos  # num of negative examples\n",
    "    \n",
    "    ixPos = np.nonzero(y)[0].tolist()                    # indices positive examples\n",
    "    ixNeg = list(set(np.arange(len(y))) - set(ixPos))    # indices negative examples\n",
    "    \n",
    "    J = 0.0  # cost\n",
    "    g = np.zeros_like(w)  # gradient    \n",
    "\n",
    "    scorePos = X[ixPos, :].dot(w)[:,np.newaxis] # nPos x 1\n",
    "    scoreNeg = X[ixNeg, :].dot(w)[:,np.newaxis] # nNeg x 1\n",
    "    scoreDif = scorePos - scoreNeg.T            # nPos x nNeg\n",
    "    #J = np.mean(np.log(1 + np.exp(-scoreDif)))\n",
    "    J = 0.5 * np.dot(w, w) + np.mean(np.log1p(np.exp(-scoreDif)))\n",
    "    \n",
    "    A = -1/(1 + np.exp(scoreDif))\n",
    "\n",
    "    T1 = X[ixPos, :].T.dot(A.sum(axis = 1))\n",
    "    T2 = X[ixNeg, :].T.dot(A.sum(axis = 0))\n",
    "    g  = w + 1/(nPos * nNeg) * (T1 - T2)\n",
    "    \n",
    "    return (J, g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_, y_train_ = create_dataset(6, data = data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0552253909154409e-06"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w0 = w = np.random.rand(X_train_.shape[1])\n",
    "check_grad(lambda w: obj_biranking(w, X_train_, y_train_)[0], \\\n",
    "           lambda w: obj_biranking(w, X_train_, y_train_)[1], w0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.2398604792352576e-06"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.1331503772158218e-06 * np.sqrt(nLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 14 \n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.687650\n",
      "         Iterations: 5\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "2 / 14 \n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.690264\n",
      "         Iterations: 5\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "3 / 14 \n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.687208\n",
      "         Iterations: 5\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "4 / 14 \n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.684365\n",
      "         Iterations: 5\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "5 / 14 \n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.687649\n",
      "         Iterations: 5\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "6 / 14 \n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.689686\n",
      "         Iterations: 5\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "7 / 14 \n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.690316\n",
      "         Iterations: 5\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "8 / 14 \n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.690929\n",
      "         Iterations: 5\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "9 / 14 \n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.690514\n",
      "         Iterations: 5\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "10 / 14 \n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.689401\n",
      "         Iterations: 5\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "11 / 14 \n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.690708\n",
      "         Iterations: 5\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "12 / 14 \n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.690920\n",
      "         Iterations: 5\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "13 / 14 \n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.690952\n",
      "         Iterations: 4\n",
      "         Function evaluations: 5\n",
      "         Gradient evaluations: 5\n",
      "14 / 14 \n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.682634\n",
      "         Iterations: 5\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n"
     ]
    }
   ],
   "source": [
    "params    = [ ]\n",
    "allPreds  = [ ]\n",
    "allTruths = [ ]\n",
    "\n",
    "for label_ix in range(nLabels):\n",
    "    #sys.stdout.write('\\r%d / %d' % (label_ix + 1, nLabels))\n",
    "    #sys.stdout.flush()\n",
    "    print('\\r%d / %d ' % (label_ix + 1, nLabels))\n",
    "    \n",
    "    X_train, y_train = create_dataset(label_ix, data = data_train)\n",
    "    X_test, y_test   = create_dataset(label_ix, data = data_test)\n",
    "    \n",
    "    allTruths.append(y_test) \n",
    "    \n",
    "    assert( (not np.all(y_train == 0)) or (not np.all(y_train == 1)) )\n",
    "        \n",
    "    opt_method = 'BFGS' #'Newton-CG' \n",
    "    #opt_method = 'nelder-mead'\n",
    "    options = {'disp': True}\n",
    "    \n",
    "    w = np.random.rand(X_train.shape[1])  # initial guess\n",
    "    opt = minimize(obj_biranking, w, args=(X_train, y_train), method=opt_method, jac=True, options=options)\n",
    "    \n",
    "    if opt.success == True:\n",
    "        w = opt.x\n",
    "        params.append(w)\n",
    "        allPreds.append(np.dot(X_test, w))\n",
    "    else:\n",
    "        sys.stderr.write('Optimisation failed, label_ix=%d\\n' % label_ix)\n",
    "        w = np.zeros(X_train.shape[1])\n",
    "        params.append(w)\n",
    "        allPreds.append(np.dot(X_test, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(917, 14)\n",
      "(917, 14)\n"
     ]
    }
   ],
   "source": [
    "allPreds = np.array(allPreds).T\n",
    "allTruths = np.array(allTruths).T\n",
    "\n",
    "print(allPreds.shape)\n",
    "print(allTruths.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allPreds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Average Subset01 Loss: 0.9335\n",
      "    Average Hamming Loss: 0.4301\n",
      "    Average Ranking Loss: 7.2246\n",
      "Average Precision@K Loss: 0.4400\n",
      "Average Precision@3 Loss: 0.4427\n",
      "Average Precision@5 Loss: 0.4100\n"
     ]
    }
   ],
   "source": [
    "printEvaluation(allPreds, allTruths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%cython -a\n",
    "\n",
    "import numpy as np\n",
    "#cimport numpy as np\n",
    "\n",
    "#cpdef obj_ranking(w, X, y):\n",
    "\n",
    "def obj_ranking_loop(w, X, Y, C):\n",
    "    \"\"\"\n",
    "        Objective with L2 regularisation and ranking loss\n",
    "        \n",
    "        Input:\n",
    "            - w: current weight vector, flattened L x D\n",
    "            - X: feature matrix, N x D\n",
    "            - Y: label matrix,   N x L\n",
    "            - C: regularisation constant\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "    L = Y.shape[1]\n",
    "    assert(w.shape[0] == L * D)\n",
    "    \n",
    "    W = w.reshape(L, D)  # reshape weight matrix    \n",
    "    \n",
    "    #cdef int nPos, nNeg, i, j\n",
    "    #cdef double J, term, denom\n",
    "    \n",
    "    J = 0.0  # cost\n",
    "    G = np.zeros_like(W)  # gradient matrix\n",
    "    \n",
    "    for n in range(N):\n",
    "        Jn = 0.0\n",
    "        Gn = np.zeros_like(W)\n",
    "        x = X[n, :]\n",
    "        y = Y[n, :]\n",
    "        nPos = np.sum(y)   # num of positive examples\n",
    "        nNeg = L - nPos    # num of negative examples\n",
    "        denom = nPos * nNeg\n",
    "        \n",
    "        ixPos = np.nonzero(y)[0].tolist()               # indices positive examples\n",
    "        ixNeg = list(set(np.arange(L)) - set(ixPos))    # indices negative examples\n",
    "        \n",
    "        for i in ixPos:\n",
    "            for j in ixNeg:\n",
    "                wDiff = W[i, :] - W[j, :]\n",
    "                sDiff = np.dot(wDiff, x)\n",
    "                term = np.exp(sDiff)\n",
    "                Jn += np.log1p(1.0 / term)\n",
    "                Gn[i, :] = Gn[i, :] - x / (1 + term)        \n",
    "        #for j in ixNeg:\n",
    "        #    for i in ixPos:\n",
    "        #        wDiff = W[i, :] - W[j, :]\n",
    "        #        sDiff = np.dot(wDiff, x)\n",
    "        #        term = np.exp(sDiff)\n",
    "                Gn[j, :] = Gn[j, :] + x / (1 + term)\n",
    "                \n",
    "        J += Jn / denom\n",
    "        G = G + Gn / denom\n",
    "        \n",
    "    J = 0.5 * C * np.dot(w, w) + J / N\n",
    "    G = C * W + G / N\n",
    "    \n",
    "    return (J, G.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.tile([1,2,3], (3,1)) * np.array([0.1, 0.2, 0.3])[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def obj_ranking(w, X, Y, C):\n",
    "    \"\"\"\n",
    "        Objective with L2 regularisation and ranking loss\n",
    "        \n",
    "        Input:\n",
    "            - w: current weight vector, flattened L x D\n",
    "            - X: feature matrix, N x D\n",
    "            - Y: label matrix,   N x L\n",
    "            - C: regularisation constant\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "    L = Y.shape[1]\n",
    "    assert(w.shape[0] == L * D)\n",
    "    \n",
    "    W = w.reshape(L, D)  # reshape weight matrix    \n",
    "    \n",
    "    J = 0.0  # cost\n",
    "    G = np.zeros_like(W)  # gradient matrix\n",
    "    \n",
    "    for n in range(N):\n",
    "        Jn = 0.0\n",
    "        Gn = np.zeros_like(W)\n",
    "        x = X[n, :]\n",
    "        y = Y[n, :]\n",
    "        nPos = np.sum(y)   # num of positive examples\n",
    "        nNeg = L - nPos    # num of negative examples\n",
    "        denom = nPos * nNeg\n",
    "        \n",
    "        ixPos = np.nonzero(y)[0].tolist()               # indices positive examples\n",
    "        ixNeg = list(set(np.arange(L)) - set(ixPos))    # indices negative examples\n",
    "        \n",
    "        ixmat = np.array(list(itertools.product(ixPos, ixNeg)))  # shape: ixPos*ixNeg by 2\n",
    "        dW = W[ixmat[:, 0], :] - W[ixmat[:, 1], :]\n",
    "        sVec = np.dot(dW, x)\n",
    "        Jn = np.sum(np.log1p(np.exp(-sVec)))\n",
    "        \n",
    "        coeffVec = np.divide(1, 1 + np.exp(sVec))\n",
    "        coeffPos = pd.DataFrame(coeffVec)\n",
    "        coeffPos['gid'] = ixmat[:, 0]\n",
    "        coeffPos = coeffPos.groupby('gid', sort=False).sum()\n",
    "        coeffNeg = pd.DataFrame(coeffVec)\n",
    "        coeffNeg['gid'] = ixmat[:, 1]\n",
    "        coeffNeg = coeffNeg.groupby('gid', sort=False).sum()\n",
    "        \n",
    "        #print(coeffPos)\n",
    "        #print(coeffNeg)\n",
    "        \n",
    "        coeffs = np.ones(L)\n",
    "        coeffs[ixPos] = -coeffPos.loc[ixPos].values.squeeze()\n",
    "        coeffs[ixNeg] = coeffNeg.loc[ixNeg].values.squeeze()\n",
    "        \n",
    "        #print(coeffs)\n",
    "        Gn = np.tile(x, (L, 1)) * coeffs[:, None]\n",
    "                        \n",
    "        J += Jn / denom\n",
    "        G = G + Gn / denom\n",
    "        \n",
    "    J = 0.5 * C * np.dot(w, w) + J / N\n",
    "    G = C * W + G / N\n",
    "    \n",
    "    return (J, G.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, Y_train = create_dataset_v2(data = data_train)\n",
    "X_test,  Y_test  = create_dataset_v2(data = data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.023048495675116e-05"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%script false\n",
    "C = 1\n",
    "w0 = np.random.rand(nFeatures * nLabels)\n",
    "check_grad(lambda w: obj_ranking(w, X_train[:20], Y_train[:20], C)[0], \\\n",
    "           lambda w: obj_ranking(w, X_train[:20], Y_train[:20], C)[1], w0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.692868\n",
      "         Iterations: 3\n",
      "         Function evaluations: 5\n",
      "         Gradient evaluations: 5\n"
     ]
    }
   ],
   "source": [
    "allPreds  = None\n",
    "allTruths = Y_test\n",
    "\n",
    "opt_method = 'BFGS' #'Newton-CG' \n",
    "#opt_method = 'nelder-mead'\n",
    "options = {'disp': True}\n",
    "\n",
    "C = 1\n",
    "w = np.random.rand(nFeatures * nLabels)  # initial guess\n",
    "opt = minimize(obj_ranking, w, args=(X_train, Y_train, C), method=opt_method, jac=True, options=options)\n",
    "\n",
    "if opt.success == True:\n",
    "    w = opt.x\n",
    "    allPreds = np.dot(X_test, w.reshape(nLabels, nFeatures).T)\n",
    "else:\n",
    "    sys.stderr.write('Optimisation failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(917, 14)\n",
      "(917, 14)\n"
     ]
    }
   ],
   "source": [
    "#allPreds = np.array(allPreds).T\n",
    "#allTruths = np.array(allTruths).T\n",
    "\n",
    "print(allPreds.shape)\n",
    "print(allTruths.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allPreds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Average Subset01 Loss: 0.9433\n",
      "    Average Hamming Loss: 0.4329\n",
      "    Average Ranking Loss: 6.7644\n",
      "Average Precision@K Loss: 0.4901\n",
      "Average Precision@3 Loss: 0.5075\n",
      "Average Precision@5 Loss: 0.4412\n"
     ]
    }
   ],
   "source": [
    "printEvaluation(allPreds, allTruths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P-norm push loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def obj_pnorm_push0(w, X, Y, p, C):\n",
    "    \"\"\"\n",
    "        Objective with L2 regularisation and p-norm push loss\n",
    "        \n",
    "        Input:\n",
    "            - w: current weight vector, flattened L x D\n",
    "            - X: feature matrix, N x D\n",
    "            - Y: label matrix,   N x L\n",
    "            - p: constant for p-norm push loss\n",
    "            - C: regularisation constant\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "    L = Y.shape[1]\n",
    "    assert(w.shape[0] == L * D)\n",
    "    assert(p >= 1)\n",
    "    assert(C >= 0)\n",
    "    \n",
    "    W = w.reshape(L, D)  # reshape weight matrix\n",
    "    \n",
    "    J = 0.0  # cost\n",
    "    G = np.zeros_like(W)  # gradient matrix\n",
    "    \n",
    "    for n in range(N):\n",
    "        Gn = np.zeros_like(W)\n",
    "        x = X[n, :]\n",
    "        y = Y[n, :]\n",
    "        nPos = np.sum(y)   # num of positive examples\n",
    "        nNeg = L - nPos    # num of negative examples\n",
    "        \n",
    "        ixPos = np.nonzero(y)[0].tolist()               # indices positive examples\n",
    "        ixNeg = list(set(np.arange(L)) - set(ixPos))    # indices negative examples\n",
    "        \n",
    "        # positive labels\n",
    "        Jp = 0.0\n",
    "        for k in ixPos:\n",
    "            wk = W[k, :]\n",
    "            term = np.exp(p * np.dot(wk, x))\n",
    "            Jp += term / p\n",
    "            Gn[k, :] = term * x / nPos\n",
    "        J += Jp / nPos\n",
    "        \n",
    "        # negative labels\n",
    "        Jn = 0.0\n",
    "        for k in ixNeg:\n",
    "            wk = W[k, :]\n",
    "            term = np.exp(-np.dot(wk, x))\n",
    "            Jn += term\n",
    "            Gn[k, :] = -term * x / nNeg\n",
    "        J += Jn / nNeg\n",
    "        \n",
    "        G = G + Gn\n",
    "        \n",
    "    J = 0.5 * C * np.dot(w, w) + J / N\n",
    "    G = C * W + G / N\n",
    "    \n",
    "    return (J, G.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def obj_pnorm_push(w, X, Y, p, C):\n",
    "    \"\"\"\n",
    "        Objective with L2 regularisation and p-norm push loss\n",
    "        \n",
    "        Input:\n",
    "            - w: current weight vector, flattened L x D\n",
    "            - X: feature matrix, N x D\n",
    "            - Y: label matrix,   N x L\n",
    "            - p: constant for p-norm push loss\n",
    "            - C: regularisation constant\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "    L = Y.shape[1]\n",
    "    assert(w.shape[0] == L * D)\n",
    "    assert(p >= 1)\n",
    "    assert(C >= 0)\n",
    "    \n",
    "    W = w.reshape(L, D)  # reshape weight matrix\n",
    "    \n",
    "    J = 0.0  # cost\n",
    "    G = np.zeros_like(W)  # gradient matrix\n",
    "    \n",
    "    for n in range(N):\n",
    "        Gn = np.zeros_like(W)\n",
    "        x = X[n, :]\n",
    "        y = Y[n, :]\n",
    "        nPos = np.sum(y)   # num of positive examples\n",
    "        nNeg = L - nPos    # num of negative examples\n",
    "        \n",
    "        for k in range(L):\n",
    "            wk = W[k, :]\n",
    "            term = np.dot(wk, x)\n",
    "            if y[k] == 1:\n",
    "                term2 = np.exp(p * term) / nPos\n",
    "                J += term2 / p\n",
    "                Gn[k, :] = x * term2\n",
    "            else:\n",
    "                term2 = np.exp(-term) / nNeg\n",
    "                J += term2\n",
    "                Gn[k, :] = -x * term2\n",
    "        G = G + Gn\n",
    "        \n",
    "    J = 0.5 * C * np.dot(w, w) + J / N\n",
    "    G = C * W + G / N\n",
    "    \n",
    "    return (J, G.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, Y_train = create_dataset_v2(data = data_train)\n",
    "X_test,  Y_test  = create_dataset_v2(data = data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5949397484521654e-05"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 1\n",
    "C = 1\n",
    "w0 = np.random.rand(nFeatures * nLabels)\n",
    "check_grad(lambda w: obj_pnorm_push(w, X_train, Y_train, p, C)[0], \\\n",
    "           lambda w: obj_pnorm_push(w, X_train, Y_train, p, C)[1], w0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.752710\n",
      "         Iterations: 334\n",
      "         Function evaluations: 336\n",
      "         Gradient evaluations: 336\n"
     ]
    }
   ],
   "source": [
    "allPreds  = None\n",
    "allTruths = Y_test\n",
    "\n",
    "opt_method = 'BFGS' #'Newton-CG' \n",
    "#opt_method = 'nelder-mead'\n",
    "options = {'disp': True}\n",
    "\n",
    "w = np.random.rand(nFeatures * nLabels)  # initial guess\n",
    "p = 1  # [1, 10]\n",
    "C = 0  # [0, 1]\n",
    "opt = minimize(obj_pnorm_push, w, args=(X_train, Y_train, p, C), method=opt_method, jac=True, options=options)\n",
    "\n",
    "if opt.success == True:\n",
    "    w = opt.x\n",
    "    allPreds = np.dot(X_test, w.reshape(nLabels, nFeatures).T)\n",
    "else:\n",
    "    sys.stderr.write('Optimisation failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(917, 14)\n",
      "(917, 14)\n"
     ]
    }
   ],
   "source": [
    "#allPreds = np.array(allPreds).T\n",
    "#allTruths = np.array(allTruths).T\n",
    "\n",
    "print(allPreds.shape)\n",
    "print(allTruths.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allPreds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Average Subset01 Loss: 1.0000\n",
      "    Average Hamming Loss: 0.5779\n",
      "    Average Ranking Loss: 13.3064\n",
      "Average Precision@K Loss: 0.2290\n",
      "Average Precision@3 Loss: 0.2119\n",
      "Average Precision@5 Loss: 0.2310\n"
     ]
    }
   ],
   "source": [
    "printEvaluation(allPreds, allTruths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for different hyper-parameter configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------\n",
      "p in loss: 1, C for regularisation: 0\n",
      "Evaluation on training set:\n",
      "   Average Subset01 Loss: 1.0000\n",
      "    Average Hamming Loss: 0.6474\n",
      "    Average Ranking Loss: 15.1733\n",
      "Average Precision@K Loss: 0.1505\n",
      "Average Precision@3 Loss: 0.1211\n",
      "Average Precision@5 Loss: 0.1565\n",
      "\n",
      "Evaluation on test set:\n",
      "   Average Subset01 Loss: 1.0000\n",
      "    Average Hamming Loss: 0.5783\n",
      "    Average Ranking Loss: 13.3119\n",
      "Average Precision@K Loss: 0.2290\n",
      "Average Precision@3 Loss: 0.2116\n",
      "Average Precision@5 Loss: 0.2308\n",
      "\n",
      "-------------------------------------\n",
      "p in loss: 1, C for regularisation: 1\n",
      "Evaluation on training set:\n",
      "   Average Subset01 Loss: 0.9980\n",
      "    Average Hamming Loss: 0.5813\n",
      "    Average Ranking Loss: 13.5993\n",
      "Average Precision@K Loss: 0.2499\n",
      "Average Precision@3 Loss: 0.2313\n",
      "Average Precision@5 Loss: 0.2509\n",
      "\n",
      "Evaluation on test set:\n",
      "   Average Subset01 Loss: 1.0000\n",
      "    Average Hamming Loss: 0.5675\n",
      "    Average Ranking Loss: 13.0905\n",
      "Average Precision@K Loss: 0.2735\n",
      "Average Precision@3 Loss: 0.2585\n",
      "Average Precision@5 Loss: 0.2694\n",
      "\n",
      "-------------------------------------\n",
      "p in loss: 10, C for regularisation: 0\n",
      "Evaluation on training set:\n",
      "   Average Subset01 Loss: 1.0000\n",
      "    Average Hamming Loss: 0.6439\n",
      "    Average Ranking Loss: 14.7547\n",
      "Average Precision@K Loss: 0.1146\n",
      "Average Precision@3 Loss: 0.0567\n",
      "Average Precision@5 Loss: 0.1180\n",
      "\n",
      "Evaluation on test set:\n",
      "   Average Subset01 Loss: 1.0000\n",
      "    Average Hamming Loss: 0.5683\n",
      "    Average Ranking Loss: 12.7241\n",
      "Average Precision@K Loss: 0.1955\n",
      "Average Precision@3 Loss: 0.1585\n",
      "Average Precision@5 Loss: 0.1993\n",
      "\n",
      "-------------------------------------\n",
      "p in loss: 10, C for regularisation: 1\n",
      "Evaluation on training set:\n",
      "   Average Subset01 Loss: 0.9980\n",
      "    Average Hamming Loss: 0.5834\n",
      "    Average Ranking Loss: 13.6607\n",
      "Average Precision@K Loss: 0.2459\n",
      "Average Precision@3 Loss: 0.2249\n",
      "Average Precision@5 Loss: 0.2447\n",
      "\n",
      "Evaluation on test set:\n",
      "   Average Subset01 Loss: 1.0000\n",
      "    Average Hamming Loss: 0.5689\n",
      "    Average Ranking Loss: 13.1407\n",
      "Average Precision@K Loss: 0.2691\n",
      "Average Precision@3 Loss: 0.2526\n",
      "Average Precision@5 Loss: 0.2656\n"
     ]
    }
   ],
   "source": [
    "allTruths = Y_test\n",
    "allTruths_train = Y_train\n",
    "opt_method = 'BFGS' #'Newton-CG' \n",
    "\n",
    "for p in [1, 10]:\n",
    "    for C in [0, 1]:\n",
    "        print('\\n-------------------------------------')\n",
    "        print('p in loss: {}, C for regularisation: {}'.format(p, C))\n",
    "        allPreds  = None\n",
    "\n",
    "        w = np.random.rand(nFeatures * nLabels)  # initial guess\n",
    "        opt = minimize(obj_pnorm_push, w, args=(X_train, Y_train, p, C), method=opt_method, jac=True)\n",
    "\n",
    "        if opt.success == True:\n",
    "            w = opt.x\n",
    "            allPreds = np.dot(X_test, w.reshape(nLabels, nFeatures).T)\n",
    "            allPreds_train = np.dot(X_train, w.reshape(nLabels, nFeatures).T)\n",
    "        else:\n",
    "            sys.stderr.write('Optimisation failed')\n",
    "        print('Evaluation on training set:')\n",
    "        printEvaluation(allPreds_train, allTruths_train)\n",
    "        print()\n",
    "        print('Evaluation on test set:')\n",
    "        printEvaluation(allPreds, allTruths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
