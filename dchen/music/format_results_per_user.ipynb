{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate results per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [('30music', '30Music'), ('aotm2011', 'AotM-2011')]\n",
    "TOPs = [5, 10, 20, 30, 50, 100, 200, 300, 500, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [('Hit-Rate', 'HitRate@100'), ('AUC', 'AUC')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cold Songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 1\n",
    "base_dir = 'setting%d' % task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algos = [('nsr', 'Multitask Classification'),\n",
    "         ('br1', 'Logistic Regression'),\n",
    "         ('pop', 'Popularity Ranking'), \n",
    "         ('cagh', 'CAGH'), ('sagh', 'SAGH')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = metrics[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows, ncols = len(algos), len(datasets)\n",
    "colors = [\"#2ecc71\", \"#9b59b6\", \"#3498db\", \"#34495e\", \"#ff1006\", \"#e74c3c\"]\n",
    "fig = plt.figure(figsize=[10, 20])\n",
    "for j in range(len(datasets)):\n",
    "    dataset = datasets[j]\n",
    "    data_dir = 'data/%s/%s' % (dataset[0], base_dir)\n",
    "    cliques = pkl.load(gzip.open(os.path.join(data_dir, 'cliques_trndev.pkl.gz'), 'rb'))\n",
    "    Y_test = pkl.load(gzip.open(os.path.join(data_dir, 'Y_test.pkl.gz'), 'rb'))\n",
    "    fperfs = [os.path.join(data_dir, 'perf-%s.pkl' % algo) for algo, _ in algos]\n",
    "    perf_dicts = [pkl.load(open(fperf, 'rb')) if os.path.exists(fperf) else None for fperf in fperfs]\n",
    "    \n",
    "    npos = Y_test.sum(axis=0).A.reshape(-1)\n",
    "    nz_ix = sorted(np.nonzero(npos)[0].tolist())\n",
    "    # print(nz_ix)\n",
    "    \n",
    "    U = len(cliques)\n",
    "    u2pl = dict()\n",
    "    pl2u = np.zeros(Y_test.shape[1], dtype=np.int)\n",
    "    for u in range(U):\n",
    "        clq = cliques[u]\n",
    "        u2pl[u] = clq\n",
    "        pl2u[clq] = u\n",
    "    \n",
    "    u2perf_dicts = []\n",
    "    for i in range(len(perf_dicts)):\n",
    "        perf = perf_dicts[i]\n",
    "        assert len(perf[dataset[0]]['Test_All']['AUC']) == len(nz_ix)\n",
    "        u2perf = dict()\n",
    "        for k in range(len(nz_ix)):\n",
    "            u = pl2u[nz_ix[k]]\n",
    "            auc = perf[dataset[0]]['Test_All']['AUC'][k] \\\n",
    "                  if metric[0] == 'AUC' else perf[dataset[0]]['Test_All']['Hit-Rate'][100][k]\n",
    "            try:\n",
    "                u2perf[u].append(auc)\n",
    "            except KeyError:\n",
    "                u2perf[u] = [auc]\n",
    "        u2perf_dicts.append(u2perf)\n",
    "        npl_user = [len(u2pl[u]) for u in sorted(u2perf)]\n",
    "        mean_auc = [np.mean(u2perf[u]) for u in sorted(u2perf)]\n",
    "        ax = plt.subplot(nrows, ncols, i * len(datasets) + j + 1)\n",
    "        ax.scatter(npl_user, mean_auc, color=colors[i], alpha=0.5, s=20)\n",
    "        lim = [-0.03, 1.03]\n",
    "        ax.set_ylim(lim)\n",
    "        if i == len(algos) - 1:\n",
    "            ax.set_xlabel('#Playlists per User for Training')\n",
    "        if j == 0:\n",
    "            ax.set_ylabel('Mean %s per User' % metric[1])\n",
    "        ax.set_title('%s (%s)' % (algos[i][1], dataset[1]))\n",
    "plt.savefig('%s_per_user%d.svg' % (metric[0].replace('-', '').lower(), 0 if task == 1 else task-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cold Playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 3\n",
    "base_dir = 'setting%d' % task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algos = [('mtc', 'Multitask Classification'),\n",
    "         ('pop', 'Popularity Ranking'),\n",
    "         ('cagh', 'CAGH'), ('sagh', 'SAGH')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = metrics[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows, ncols = len(algos), len(datasets)\n",
    "colors = [\"#2ecc71\", \"#9b59b6\", \"#3498db\", \"#34495e\", \"#ff1006\", \"#e74c3c\"]\n",
    "fig = plt.figure(figsize=[10, 20])\n",
    "for j in range(len(datasets)):\n",
    "    dataset = datasets[j]\n",
    "    data_dir = 'data/%s/%s' % (dataset[0], base_dir)\n",
    "    Y_train = pkl.load(gzip.open(os.path.join(data_dir, 'Y_train.pkl.gz'), 'rb'))\n",
    "    Y_test = pkl.load(gzip.open(os.path.join(data_dir, 'Y_test.pkl.gz'), 'rb'))\n",
    "    cliques_train = pkl.load(gzip.open(os.path.join(data_dir, 'cliques_train.pkl.gz'), 'rb'))\n",
    "    cliques_all = pkl.load(gzip.open(os.path.join(data_dir, 'cliques_all.pkl.gz'), 'rb'))\n",
    "    fperfs = [os.path.join(data_dir, 'perf-%s.pkl' % algo) for algo, _ in algos]\n",
    "    perf_dicts = [pkl.load(open(fperf, 'rb')) if os.path.exists(fperf) else None for fperf in fperfs]\n",
    "    \n",
    "    pl2u_train = np.zeros(Y_train.shape[1], dtype=np.int)\n",
    "    pl2u_all = np.zeros(Y_train.shape[1] + Y_test.shape[1], dtype=np.int)\n",
    "    U = len(cliques_all)\n",
    "    assert U == len(cliques_train)\n",
    "    for u in range(U):\n",
    "        pl2u_train[cliques_train[u]] = u\n",
    "        pl2u_all[cliques_all[u]] = u\n",
    "    assert np.all(pl2u_train == pl2u_all[:Y_train.shape[1]])\n",
    "    \n",
    "    u2perf_dicts = []\n",
    "    offset = Y_train.shape[1]\n",
    "    for i in range(len(perf_dicts)):\n",
    "        perf = perf_dicts[i]\n",
    "        assert len(perf[dataset[0]]['Test_All']['AUC']) == Y_test.shape[1]\n",
    "        u2perf = dict()\n",
    "        for k in range(Y_test.shape[1]):\n",
    "            u = pl2u_all[k + offset]\n",
    "            num = perf[dataset[0]]['Test_All']['AUC'][k] \\\n",
    "                  if metric[0] == 'AUC' else perf[dataset[0]]['Test_All']['Hit-Rate'][100][k]\n",
    "            try:\n",
    "                u2perf[u].append(num)\n",
    "            except KeyError:\n",
    "                u2perf[u] = [auc]\n",
    "        u2perf_dicts.append(u2perf)\n",
    "        npl_user = [len(cliques_train[u]) for u in sorted(u2perf)]\n",
    "        mean_num = [np.mean(u2perf[u]) for u in sorted(u2perf)]\n",
    "        ax = plt.subplot(nrows, ncols, i * len(datasets) + j + 1)\n",
    "        ax.scatter(npl_user, mean_num, color=colors[i], alpha=0.5, s=20)\n",
    "        lim = [-0.03, 1.03]\n",
    "        ax.set_ylim(lim)\n",
    "        if i == len(algos) - 1:\n",
    "            ax.set_xlabel('#Playlists per User for Training')\n",
    "        if j == 0:\n",
    "            ax.set_ylabel('Mean %s per User' % metric[1])\n",
    "        ax.set_title('%s (%s)' % (algos[i][1], dataset[1]))\n",
    "plt.savefig('%s_per_user%d.svg' % (metric[0].replace('-', '').lower(), 0 if task == 1 else task-2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
