{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines - playlist generation for known users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os, sys, time, gzip\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "from scipy.sparse import lil_matrix, issparse, csc_matrix, csr_matrix\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tools import calc_RPrecision_HitRate\n",
    "from tools import calc_metrics, diversity, softmax\n",
    "# from tools import calc_Precision_Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPs = [5, 10, 20, 30, 50, 100, 200, 300, 500, 700, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['aotm2011', '30music']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'30music'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dix = 1\n",
    "dataset_name = datasets[dix]\n",
    "dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/%s/coldstart/setting3' % dataset_name\n",
    "X = pkl.load(gzip.open(os.path.join(data_dir, 'X.pkl.gz'), 'rb'))\n",
    "Y_train = pkl.load(gzip.open(os.path.join(data_dir, 'Y_train.pkl.gz'), 'rb'))\n",
    "Y_test = pkl.load(gzip.open(os.path.join(data_dir, 'Y_test.pkl.gz'), 'rb'))\n",
    "song2pop_train = pkl.load(gzip.open(os.path.join(data_dir, 'song2pop_train.pkl.gz'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists3 = pkl.load(gzip.open(os.path.join(data_dir, 'playlists_train_test_s3.pkl.gz'), 'rb'))\n",
    "train_playlists = playlists3['train_playlists']\n",
    "test_playlists = playlists3['test_playlists']\n",
    "user2songs = dict()\n",
    "\n",
    "for pl, u in train_playlists:\n",
    "    try:\n",
    "        user2songs[u].update(set(pl))\n",
    "    except KeyError:\n",
    "        user2songs[u] = set(pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_songs = pkl.load(gzip.open(os.path.join(data_dir, 'all_songs.pkl.gz'), 'rb'))\n",
    "index2song = {ix: sid for ix, (sid, _) in enumerate(all_songs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "song2index = {sid: ix for ix, (sid, _) in enumerate(all_songs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_song2artist = pkl.load(gzip.open('data/msd/song2artist.pkl.gz', 'rb'))\n",
    "song2artist = {sid: _song2artist[sid] for sid, _ in all_songs if sid in _song2artist}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist2songs = dict()\n",
    "\n",
    "for sid in sorted(song2artist):\n",
    "    artist = song2artist[sid]\n",
    "    try:\n",
    "        artist2songs[artist].append(sid)\n",
    "    except KeyError:\n",
    "        artist2songs[artist] = [sid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45,468 | 9,981\n"
     ]
    }
   ],
   "source": [
    "print('{:,} | {:,}'.format(len(song2artist), len(artist2songs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "song2genre = pkl.load(gzip.open('data/msd/song2genre.pkl.gz', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "song2pop = pkl.load(gzip.open(os.path.join(data_dir, 'song2pop.pkl.gz'), 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collocated Artists - Greatest Hits (CAGH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the similarity of two artist $a_1$ and $a_2$ given a set of playlist $P$:   \n",
    "$$\n",
    "\\text{sim}(a_1, a_2) \n",
    "= \\frac{\\sum_{p \\in P} \\delta(a_1, p) \\times \\delta(a_2, p)}\n",
    "       {\\sqrt{\\sum_{p \\in P} \\delta(a_1, p) \\times \\sum_{p \\in P} \\delta(a_2, p)}}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\delta(a, p) \n",
    "= \\begin{cases}\n",
    "1, \\ \\text{at least one song in playlist $p$ is from artist $a$}, \\\\\n",
    "0, \\ \\text{otherwise}.\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommend according to the popularity of songs, but weighted by similarity of (`artist in user's listening history`, `artist of song`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_artist = sorted(set([song2artist[sid] for pl, _ in train_playlists for sid in pl if sid in song2artist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist2index = {aid: ix for ix, aid in enumerate(all_artist)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Na = len(all_artist)\n",
    "Np = len(train_playlists)\n",
    "Delta = lil_matrix((Na, Np), dtype=np.float)\n",
    "for j in range(Np):\n",
    "    pl_artist = sorted(set([song2artist[sid] for sid in train_playlists[j][0] if sid in song2artist]))\n",
    "    ix = [artist2index[aid] for aid in pl_artist]\n",
    "    Delta[ix, j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Delta = Delta.tocsr()\n",
    "Dsum = Delta.sum(axis=1).A.reshape(-1)\n",
    "ColloMat = Delta.dot(Delta.T).A\n",
    "\n",
    "assert np.all(np.isclose(ColloMat.diagonal(), Dsum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9981 9981\n"
     ]
    }
   ],
   "source": [
    "print(len(Dsum), len(all_artist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(ColloMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = 1. / np.sqrt(Dsum)\n",
    "NormMat = np.dot(T1.reshape(Na, 1), T1.reshape(1, Na))\n",
    "\n",
    "WeightMat = np.multiply(ColloMat, NormMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2195 / 2195\n",
      "2195 / 2195\n"
     ]
    }
   ],
   "source": [
    "rps_cagh = []\n",
    "hitrates_cagh = {top: [] for top in TOPs}\n",
    "aucs_cagh = []\n",
    "spreads_cagh = []\n",
    "novelties_cagh = {top: dict() for top in TOPs}\n",
    "ptops_cagh = []\n",
    "# artist_diversities_cagh = {top: [] for top in TOPs}\n",
    "# genre_diversities_cagh = {top: [] for top in TOPs}\n",
    "np.random.seed(0)\n",
    "\n",
    "assert Y_test.shape[1] == len(test_playlists)\n",
    "\n",
    "sid_legal = [sid for sid, _ in all_songs if sid in song2artist]\n",
    "aix_legal = [artist2index[song2artist[sid]] for sid in sid_legal]\n",
    "pop_legal = np.asarray([song2pop_train[sid] for sid in sid_legal])\n",
    "ix_legal = [song2index[sid] for sid in sid_legal]\n",
    "\n",
    "prev_u = None\n",
    "prev_y = None\n",
    "\n",
    "for j in range(Y_test.shape[1]):\n",
    "    sys.stdout.write('\\r%d / %d' % (j+1, Y_test.shape[1]))\n",
    "    sys.stdout.flush()\n",
    "    y_true = Y_test[:, j].A.reshape(-1)\n",
    "    \n",
    "    u = test_playlists[j][1]\n",
    "    if prev_u is None or prev_u != u:\n",
    "        artists = sorted(set([song2artist[sid] for sid in user2songs[u] if sid in song2artist]))\n",
    "        artists_ix = [artist2index[aid] for aid in artists]\n",
    "        y_pred = np.zeros(y_true.shape)\n",
    "        y_pred[ix_legal] = np.log(pop_legal) * np.asarray([WeightMat[aix, artists_ix].sum() for aix in aix_legal])\n",
    "\n",
    "        # for ix in ix_legal:\n",
    "        #     sid = index2song[ix]\n",
    "        #     aix = artist2index[song2artist[sid]]\n",
    "        #     pop = song2pop_test[sid]\n",
    "        #     y_pred[ix] = pop * WeightMat[aix, artists_ix].sum()\n",
    "        \n",
    "        prev_u = u\n",
    "        prev_y = y_pred\n",
    "    else:\n",
    "        y_pred = prev_y\n",
    "\n",
    "    # rp, hr_dict = calc_RPrecision_HitRate(y_true, y_pred, tops=TOPs)\n",
    "    rp, hr_dict, auc = calc_metrics(y_true, y_pred, tops=TOPs)\n",
    "    rps_cagh.append(rp)\n",
    "    for top in TOPs:\n",
    "        hitrates_cagh[top].append(hr_dict[top])\n",
    "    aucs_cagh.append(auc)\n",
    "    \n",
    "    # spread\n",
    "    y_pred_prob = softmax(y_pred)\n",
    "    spreads_cagh.append(-np.dot(y_pred_prob, np.log(y_pred_prob)))\n",
    "\n",
    "    # novelty\n",
    "    sortix = np.argsort(-y_pred)\n",
    "    for top in TOPs:\n",
    "        nov = np.mean([-np.log2(song2pop[index2song[ix]]) for ix in sortix[:top]])\n",
    "        try:\n",
    "            novelties_cagh[top][u].append(nov)\n",
    "        except KeyError:\n",
    "            novelties_cagh[top][u] = [nov]\n",
    "    \n",
    "    # PTop: (#pos ranked above the top-ranked negative) / #pos\n",
    "    assert y_true.dtype == np.bool\n",
    "    npos = y_true.sum()\n",
    "    assert npos > 0\n",
    "    negIx = (1 - y_true).astype(np.bool)\n",
    "    negMax = y_pred[negIx].max()\n",
    "    pt = (y_pred[y_true] > negMax).sum() / npos\n",
    "    ptops_cagh.append(pt)\n",
    "    \n",
    "    # artist/genre diversity\n",
    "#     for top in TOPs:\n",
    "#         artist_vec = np.array([song2artist[index2song[ix]] if index2song[ix] in song2artist\n",
    "#                                else str(np.random.rand()) for ix in sortix[:top]])\n",
    "#         genre_vec = np.array([song2genre[index2song[ix]] if index2song[ix] in song2genre \\\n",
    "#                               else str(np.random.rand()) for ix in sortix[:top]])\n",
    "#         artist_diversities_cagh[top].append( diversity(artist_vec) )\n",
    "#         genre_diversities_cagh[top].append( diversity(genre_vec) )\n",
    "\n",
    "print('\\n%d / %d' % (len(rps_cagh), Y_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=[20, 5])\n",
    "# ax1 = plt.subplot(131)\n",
    "# ax1.hist(rps_cagh, bins=100)\n",
    "# ax1.set_yscale('log')\n",
    "# ax1.set_title('R-Precision')\n",
    "# #ax.set_xlim(0, xmax)\n",
    "# ax2 = plt.subplot(132)\n",
    "# ax2.hist(aucs_cagh, bins=100)\n",
    "# ax2.set_yscale('log')\n",
    "# ax2.set_title('AUC')\n",
    "# pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R-Precision': 0.04319798205721797,\n",
       " 'Hit-Rate': {5: 0.02521471715758077,\n",
       "  10: 0.043921921531783446,\n",
       "  20: 0.07366269688790775,\n",
       "  30: 0.09581443548438519,\n",
       "  50: 0.13063921817169946,\n",
       "  100: 0.20099355056502818,\n",
       "  200: 0.2939449086419079,\n",
       "  300: 0.3547684460173996,\n",
       "  500: 0.44579655354978615,\n",
       "  700: 0.5075424610930664,\n",
       "  1000: 0.576546531767024},\n",
       " 'AUC': 0.9483727023751518,\n",
       " 'Spread': 5.790900154856364,\n",
       " 'Novelty': {5: -7.058046504828398,\n",
       "  10: -6.725432177526543,\n",
       "  20: -6.3156666454542805,\n",
       "  30: -6.0401671802802674,\n",
       "  50: -5.740252835295074,\n",
       "  100: -5.5421073371922995,\n",
       "  200: -5.457428058333383,\n",
       "  300: -5.390313360005151,\n",
       "  500: -5.266346105989974,\n",
       "  700: -5.154919662139392,\n",
       "  1000: -5.008269281341808},\n",
       " 'PTop': 0.009496450024095335}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cagh_perf = {dataset_name: {'Test': {'R-Precision': np.mean(rps_cagh), \n",
    "                                     'Hit-Rate': {top: np.mean(hitrates_cagh[top]) for top in TOPs},\n",
    "                                     'AUC': np.mean(aucs_cagh),\n",
    "                                     'Spread': np.mean(spreads_cagh),\n",
    "                                     'Novelty': {t: np.mean([np.mean(novelties_cagh[t][u]) \n",
    "                                                             for u in novelties_cagh[t]]) for t in TOPs},\n",
    "                                     'PTop': np.mean(ptops_cagh),\n",
    "                                     # 'Artist-Diversity': {t: np.mean(artist_diversities_cagh[t]) for t in TOPs},\n",
    "                                     # 'Genre-Diversity': {t: np.mean(genre_diversities_cagh[t]) for t in TOPs}},\n",
    "                                    },\n",
    "                            'Test_All': {'R-Precision': rps_cagh, \n",
    "                                         'Hit-Rate': {top: hitrates_cagh[top] for top in TOPs},\n",
    "                                         'AUC': aucs_cagh,\n",
    "                                         'Spread': spreads_cagh,\n",
    "                                         'Novelty': novelties_cagh,\n",
    "                                         'PTop': ptops_cagh,\n",
    "                                         # 'Artist-Diversity': artist_diversities_cagh,\n",
    "                                         # 'Genre-Diversity': genre_diversities_cagh}}}\n",
    "                                        }}}\n",
    "cagh_perf[dataset_name]['Test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/30music/coldstart/setting3/perf-cagh.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'R-Precision': 0.04319798205721797,\n",
       " 'Hit-Rate': {5: 0.02521471715758077,\n",
       "  10: 0.043921921531783446,\n",
       "  20: 0.07366269688790775,\n",
       "  30: 0.09581443548438519,\n",
       "  50: 0.13063921817169946,\n",
       "  100: 0.20099355056502818,\n",
       "  200: 0.2939449086419079,\n",
       "  300: 0.3547684460173996,\n",
       "  500: 0.44579655354978615,\n",
       "  700: 0.5075424610930664,\n",
       "  1000: 0.576546531767024},\n",
       " 'AUC': 0.9483727023751518,\n",
       " 'Spread': 5.790900154856364,\n",
       " 'Novelty': {5: -7.058046504828398,\n",
       "  10: -6.725432177526543,\n",
       "  20: -6.3156666454542805,\n",
       "  30: -6.0401671802802674,\n",
       "  50: -5.740252835295074,\n",
       "  100: -5.5421073371922995,\n",
       "  200: -5.457428058333383,\n",
       "  300: -5.390313360005151,\n",
       "  500: -5.266346105989974,\n",
       "  700: -5.154919662139392,\n",
       "  1000: -5.008269281341808},\n",
       " 'PTop': 0.009496450024095335}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fperf_cagh = os.path.join(data_dir, 'perf-cagh.pkl')\n",
    "print(fperf_cagh)\n",
    "pkl.dump(cagh_perf, open(fperf_cagh, 'wb'))\n",
    "pkl.load(open(fperf_cagh, 'rb'))[dataset_name]['Test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same Artists - Greatest Hits (SAGH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommend according to the popularity of songs of artists in listening history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100 / 2195\n",
      "2195 / 2195\n"
     ]
    }
   ],
   "source": [
    "rps_sagh = []\n",
    "hitrates_sagh = {top: [] for top in TOPs}\n",
    "aucs_sagh = []\n",
    "spreads_sagh = []\n",
    "novelties_sagh = {top: dict() for top in TOPs}\n",
    "ptops_sagh = []\n",
    "# artist_diversities_sagh = {top: [] for top in TOPs}\n",
    "# genre_diversities_sagh = {top: [] for top in TOPs}\n",
    "np.random.seed(0)\n",
    "\n",
    "assert Y_test.shape[1] == len(test_playlists)\n",
    "for j in range(Y_test.shape[1]):\n",
    "    if (j+1) % 100 == 0:\n",
    "        sys.stdout.write('\\r%d / %d' % (j+1, Y_test.shape[1]))\n",
    "        sys.stdout.flush()\n",
    "    y_true = Y_test[:, j].A.reshape(-1)\n",
    "    y_pred = np.zeros(y_true.shape)\n",
    "    \n",
    "    u = test_playlists[j][1]\n",
    "    artists = sorted(set([song2artist[sid] for sid in user2songs[u] if sid in song2artist]))\n",
    "    candidates = []\n",
    "    for a in artists:\n",
    "        candidates += artist2songs[a]\n",
    "    candidates = sorted(set(candidates))\n",
    "    if len(candidates) > 0:\n",
    "        for sid in candidates:\n",
    "            ix = song2index[sid]\n",
    "            y_pred[ix] = np.log(song2pop_train[sid])\n",
    "\n",
    "    # rp, hr_dict = calc_RPrecision_HitRate(y_true, y_pred, tops=TOPs)\n",
    "    rp, hr_dict, auc = calc_metrics(y_true, y_pred, tops=TOPs)\n",
    "    rps_sagh.append(rp)\n",
    "    for top in TOPs:\n",
    "        hitrates_sagh[top].append(hr_dict[top])\n",
    "    aucs_sagh.append(auc)\n",
    "    \n",
    "    # spread\n",
    "    y_pred_prob = softmax(y_pred)\n",
    "    spreads_sagh.append(-np.dot(y_pred_prob, np.log(y_pred_prob)))\n",
    "\n",
    "    # novelty\n",
    "    sortix = np.argsort(-y_pred)\n",
    "    for top in TOPs:\n",
    "        nov = np.mean([-np.log2(song2pop[index2song[ix]]) for ix in sortix[:top]])\n",
    "        try:\n",
    "            novelties_sagh[top][u].append(nov)\n",
    "        except KeyError:\n",
    "            novelties_sagh[top][u] = [nov]\n",
    "            \n",
    "    # PTop: (#pos ranked above the top-ranked negative) / #pos\n",
    "    assert y_true.dtype == np.bool\n",
    "    npos = y_true.sum()\n",
    "    assert npos > 0\n",
    "    negIx = (1 - y_true).astype(np.bool)\n",
    "    negMax = y_pred[negIx].max()\n",
    "    pt = (y_pred[y_true] > negMax).sum() / npos\n",
    "    ptops_sagh.append(pt)\n",
    "    \n",
    "    # artist/genre diversity\n",
    "#     for top in TOPs:\n",
    "#         artist_vec = np.array([song2artist[index2song[ix]] if index2song[ix] in song2artist\n",
    "#                                else str(np.random.rand()) for ix in sortix[:top]])\n",
    "#         genre_vec = np.array([song2genre[index2song[ix]] if index2song[ix] in song2genre \\\n",
    "#                               else str(np.random.rand()) for ix in sortix[:top]])\n",
    "#         artist_diversities_sagh[top].append( diversity(artist_vec) )\n",
    "#         genre_diversities_sagh[top].append( diversity(genre_vec) )\n",
    "print('\\n%d / %d' % (len(rps_sagh), Y_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=[20, 5])\n",
    "# ax1 = plt.subplot(131)\n",
    "# ax1.hist(rps_sagh, bins=100)\n",
    "# ax1.set_yscale('log')\n",
    "# ax1.set_title('R-Precision')\n",
    "# #ax.set_xlim(0, xmax)\n",
    "# ax2 = plt.subplot(132)\n",
    "# ax2.hist(aucs_sagh, bins=100)\n",
    "# ax2.set_yscale('log')\n",
    "# ax2.set_title('AUC')\n",
    "# pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R-Precision': 0.0452645392008858,\n",
       " 'Hit-Rate': {5: 0.02635875113186022,\n",
       "  10: 0.045496088620980986,\n",
       "  20: 0.07606360445870414,\n",
       "  30: 0.09861250709516567,\n",
       "  50: 0.13239572961049764,\n",
       "  100: 0.1813284612206776,\n",
       "  200: 0.22717142363225395,\n",
       "  300: 0.25187588947116424,\n",
       "  500: 0.2757905842759898,\n",
       "  700: 0.28873514860458266,\n",
       "  1000: 0.2995276029801112},\n",
       " 'AUC': 0.6450527914435169,\n",
       " 'Spread': 10.326562735197296,\n",
       " 'Novelty': {5: -7.264256802379904,\n",
       "  10: -6.905920319602588,\n",
       "  20: -6.423426350202923,\n",
       "  30: -6.072672093643402,\n",
       "  50: -5.540663129776558,\n",
       "  100: -4.685427723970891,\n",
       "  200: -3.7278987461349784,\n",
       "  300: -3.18750649526425,\n",
       "  500: -2.5793628921778686,\n",
       "  700: -2.2859353866779566,\n",
       "  1000: -2.033143122718425},\n",
       " 'PTop': 0.008706126423116696}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagh_perf = {dataset_name: {'Test': {'R-Precision': np.mean(rps_sagh), \n",
    "                                     'Hit-Rate': {top: np.mean(hitrates_sagh[top]) for top in TOPs},\n",
    "                                     'AUC': np.mean(aucs_sagh),\n",
    "                                     'Spread': np.mean(spreads_sagh),\n",
    "                                     'Novelty': {t: np.mean([np.mean(novelties_sagh[t][u]) \n",
    "                                                             for u in novelties_sagh[t]]) for t in TOPs},\n",
    "                                     'PTop': np.mean(ptops_sagh),\n",
    "                                     # 'Artist-Diversity': {t: np.mean(artist_diversities_sagh[t]) for t in TOPs},\n",
    "                                     # 'Genre-Diversity': {t: np.mean(genre_diversities_sagh[t]) for t in TOPs}},\n",
    "                                    },\n",
    "                            'Test_All': {'R-Precision': rps_sagh, \n",
    "                                         'Hit-Rate': {top: hitrates_sagh[top] for top in TOPs},\n",
    "                                         'AUC': aucs_sagh,\n",
    "                                         'Spread': spreads_sagh,\n",
    "                                         'Novelty': novelties_sagh,\n",
    "                                         'PTop': ptops_sagh,\n",
    "                                         # 'Artist-Diversity': artist_diversities_sagh,\n",
    "                                         # 'Genre-Diversity': genre_diversities_sagh}}}\n",
    "                                        }}}\n",
    "sagh_perf[dataset_name]['Test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/30music/coldstart/setting3/perf-sagh.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'R-Precision': 0.0452645392008858,\n",
       " 'Hit-Rate': {5: 0.02635875113186022,\n",
       "  10: 0.045496088620980986,\n",
       "  20: 0.07606360445870414,\n",
       "  30: 0.09861250709516567,\n",
       "  50: 0.13239572961049764,\n",
       "  100: 0.1813284612206776,\n",
       "  200: 0.22717142363225395,\n",
       "  300: 0.25187588947116424,\n",
       "  500: 0.2757905842759898,\n",
       "  700: 0.28873514860458266,\n",
       "  1000: 0.2995276029801112},\n",
       " 'AUC': 0.6450527914435169,\n",
       " 'Spread': 10.326562735197296,\n",
       " 'Novelty': {5: -7.264256802379904,\n",
       "  10: -6.905920319602588,\n",
       "  20: -6.423426350202923,\n",
       "  30: -6.072672093643402,\n",
       "  50: -5.540663129776558,\n",
       "  100: -4.685427723970891,\n",
       "  200: -3.7278987461349784,\n",
       "  300: -3.18750649526425,\n",
       "  500: -2.5793628921778686,\n",
       "  700: -2.2859353866779566,\n",
       "  1000: -2.033143122718425},\n",
       " 'PTop': 0.008706126423116696}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fperf_sagh = os.path.join(data_dir, 'perf-sagh.pkl')\n",
    "print(fperf_sagh)\n",
    "pkl.dump(sagh_perf, open(fperf_sagh, 'wb'))\n",
    "pkl.load(open(fperf_sagh, 'rb'))[dataset_name]['Test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity based recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2190 / 2195\n",
      "2195 / 2195\n"
     ]
    }
   ],
   "source": [
    "rps_pop = []\n",
    "hitrates_pop = {top: [] for top in TOPs}\n",
    "aucs_pop = []\n",
    "novelties_pop = {top: dict() for top in TOPs}\n",
    "ptops_pop = []\n",
    "# artist_diversities_pop = {top: [] for top in TOPs}\n",
    "# genre_diversities_pop = {top: [] for top in TOPs}\n",
    "np.random.seed(0)\n",
    "\n",
    "y_pred = np.array([song2pop_train[index2song[ix]] for ix in range(len(all_songs))])\n",
    "y_pred_prob = softmax(np.log(y_pred))\n",
    "spread_pop = -np.dot(y_pred_prob, np.log(y_pred_prob))\n",
    "sortix = np.argsort(-y_pred)\n",
    "\n",
    "assert Y_test.shape[1] == len(test_playlists)\n",
    "for j in range(Y_test.shape[1]):\n",
    "    if (j+1) % 10 == 0:\n",
    "        sys.stdout.write('\\r%d / %d' % (j+1, Y_test.shape[1]))\n",
    "        sys.stdout.flush()\n",
    "    y_true = Y_test[:, j].A.reshape(-1)\n",
    "    \n",
    "    # rp, hr_dict = calc_RPrecision_HitRate(y_true, y_pred, tops=TOPs)\n",
    "    rp, hr_dict, auc = calc_metrics(y_true, y_pred, tops=TOPs)\n",
    "    rps_pop.append(rp)\n",
    "    for top in TOPs:\n",
    "        hitrates_pop[top].append(hr_dict[top])\n",
    "    aucs_pop.append(auc)\n",
    "\n",
    "    # novelty\n",
    "    u = test_playlists[j][1]\n",
    "    for top in TOPs:\n",
    "        nov = np.mean([-np.log2(song2pop[index2song[ix]]) for ix in sortix[:top]])\n",
    "        try:\n",
    "            novelties_pop[top][u].append(nov)\n",
    "        except KeyError:\n",
    "            novelties_pop[top][u] = [nov]\n",
    "            \n",
    "    # PTop: (#pos ranked above the top-ranked negative) / #pos\n",
    "    assert y_true.dtype == np.bool\n",
    "    npos = y_true.sum()\n",
    "    assert npos > 0\n",
    "    negIx = (1 - y_true).astype(np.bool)\n",
    "    negMax = y_pred[negIx].max()\n",
    "    pt = (y_pred[y_true] > negMax).sum() / npos\n",
    "    ptops_pop.append(pt)\n",
    "\n",
    "    # artist/genre diversity\n",
    "#     for top in TOPs:\n",
    "#         artist_vec = np.array([song2artist[index2song[ix]] if index2song[ix] in song2artist\n",
    "#                                else str(np.random.rand()) for ix in sortix[:top]])\n",
    "#         genre_vec = np.array([song2genre[index2song[ix]] if index2song[ix] in song2genre \\\n",
    "#                               else str(np.random.rand()) for ix in sortix[:top]])\n",
    "#         artist_diversities_pop[top].append( diversity(artist_vec) )\n",
    "#         genre_diversities_pop[top].append( diversity(genre_vec) )\n",
    "    \n",
    "print('\\n%d / %d' % (len(rps_pop), Y_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=[20, 5])\n",
    "# ax1 = plt.subplot(131)\n",
    "# ax1.hist(rps_pop, bins=100)\n",
    "# ax1.set_yscale('log')\n",
    "# ax1.set_title('R-Precision')\n",
    "# #ax.set_xlim(0, xmax)\n",
    "# ax2 = plt.subplot(132)\n",
    "# ax2.hist(aucs_pop, bins=100)\n",
    "# ax2.set_yscale('log')\n",
    "# ax2.set_title('AUC')\n",
    "# pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R-Precision': 0.021789486717889057,\n",
       " 'Hit-Rate': {5: 0.010145439453664305,\n",
       "  10: 0.0190906029791239,\n",
       "  20: 0.035023385784414565,\n",
       "  30: 0.04652897408134314,\n",
       "  50: 0.06902868603298959,\n",
       "  100: 0.11953569058765297,\n",
       "  200: 0.1921951014338093,\n",
       "  300: 0.24737848161229312,\n",
       "  500: 0.32612280951457073,\n",
       "  700: 0.3905026295790617,\n",
       "  1000: 0.462820533654615},\n",
       " 'AUC': 0.9402710379314311,\n",
       " 'Spread': 9.800781689204657,\n",
       " 'Novelty': {5: -8.406420692558143,\n",
       "  10: -8.2740968572769,\n",
       "  20: -8.127371393547135,\n",
       "  30: -8.010500208389617,\n",
       "  50: -7.856553487793756,\n",
       "  100: -7.6026583564350805,\n",
       "  200: -7.283651706691955,\n",
       "  300: -7.052911271895382,\n",
       "  500: -6.728155958468345,\n",
       "  700: -6.4973974242965795,\n",
       "  1000: -6.231012799438416},\n",
       " 'PTop': 0.0027028189198567555}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_perf = {dataset_name: {'Test': {'R-Precision': np.mean(rps_pop), \n",
    "                                    'Hit-Rate': {top: np.mean(hitrates_pop[top]) for top in TOPs},\n",
    "                                    'AUC': np.mean(aucs_pop),\n",
    "                                    'Spread': spread_pop,\n",
    "                                    'Novelty': {t: np.mean([np.mean(novelties_pop[t][u]) for u in novelties_pop[t]]) \n",
    "                                                for t in TOPs},\n",
    "                                    'PTop': np.mean(ptops_pop),\n",
    "                                    #'Artist-Diversity': {top: np.mean(artist_diversities_pop[top]) for top in TOPs},\n",
    "                                    #'Genre-Diversity': {top: np.mean(genre_diversities_pop[top]) for top in TOPs}},\n",
    "                                   },\n",
    "                           'Test_All': {'R-Precision': rps_pop, \n",
    "                                        'Hit-Rate': {top: hitrates_pop[top] for top in TOPs},\n",
    "                                        'AUC': aucs_pop,\n",
    "                                        'Spread': spread_pop,\n",
    "                                        'Novelty': novelties_pop,\n",
    "                                        'PTop': ptops_pop,\n",
    "                                        # 'Artist-Diversity': artist_diversities_pop,\n",
    "                                        # 'Genre-Diversity': genre_diversities_pop}}}\n",
    "                                       }}}\n",
    "pop_perf[dataset_name]['Test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/30music/coldstart/setting3/perf-pop.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'R-Precision': 0.021789486717889057,\n",
       " 'Hit-Rate': {5: 0.010145439453664305,\n",
       "  10: 0.0190906029791239,\n",
       "  20: 0.035023385784414565,\n",
       "  30: 0.04652897408134314,\n",
       "  50: 0.06902868603298959,\n",
       "  100: 0.11953569058765297,\n",
       "  200: 0.1921951014338093,\n",
       "  300: 0.24737848161229312,\n",
       "  500: 0.32612280951457073,\n",
       "  700: 0.3905026295790617,\n",
       "  1000: 0.462820533654615},\n",
       " 'AUC': 0.9402710379314311,\n",
       " 'Spread': 9.800781689204657,\n",
       " 'Novelty': {5: -8.406420692558143,\n",
       "  10: -8.2740968572769,\n",
       "  20: -8.127371393547135,\n",
       "  30: -8.010500208389617,\n",
       "  50: -7.856553487793756,\n",
       "  100: -7.6026583564350805,\n",
       "  200: -7.283651706691955,\n",
       "  300: -7.052911271895382,\n",
       "  500: -6.728155958468345,\n",
       "  700: -6.4973974242965795,\n",
       "  1000: -6.231012799438416},\n",
       " 'PTop': 0.0027028189198567555}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fperf_pop = os.path.join(data_dir, 'perf-pop.pkl')\n",
    "print(fperf_pop)\n",
    "pkl.dump(pop_perf, open(fperf_pop, 'wb'))\n",
    "pkl.load(open(fperf_pop, 'rb'))[dataset_name]['Test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $S \\in \\mathbb{R}^{M \\times D}, V \\in \\mathbb{R}^{U \\times D}$ be the latent factors of songs and users, respectively.\n",
    "Let $R \\in \\mathbb{R}^{M \\times U}$ be the play-count of songs for users, and $T = \\mathbf{1}(R > 0) \\in \\{0,1\\}^{M \\times U}$ be a binary matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimisation objective:\n",
    "$\n",
    "\\begin{aligned}\n",
    "J = \\sum_{m=1}^M \\sum_{u=1}^U q_{m, u}\n",
    "    \\left( t_{m,u} - \\mathbf{s}_m^\\top \\mathbf{v}_u \\right)^2\n",
    "    + C \\left( \\sum_{m=1}^M \\mathbf{s}_m^\\top \\mathbf{s}_m + \\sum_{u=1}^U \\mathbf{v}_n^\\top \\mathbf{v}_n \\right)\n",
    "\\end{aligned} \n",
    "$  \n",
    "where $\\alpha, \\epsilon$ are hyper-parameters, and $q_{m, u} = 1 + \\alpha \\log(1 + \\epsilon^{-1} r_{m,u})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use alternating least squares optimisation method:\n",
    "\n",
    "1. Fix $S$, then let\n",
    "$\n",
    "\\begin{aligned}\n",
    "\\mathbf{0}\n",
    "= \\frac{\\partial J}{\\partial \\mathbf{v}_u}\n",
    "= \\sum_{m=1}^M 2 q_{m,u} \\left( t_{m,u} - \\mathbf{s}_m^\\top \\mathbf{v}_u \\right) (-\\mathbf{s}_m) + 2 C \\mathbf{v}_u\n",
    "\\end{aligned}\n",
    "$  \n",
    "in other words\n",
    "$\n",
    "\\begin{aligned}\n",
    "\\sum_{m=1}^M q_{m,u} t_{m,u} \\mathbf{s}_m \n",
    "= \\sum_{m=1}^M q_{m,u} (\\mathbf{s}_m^\\top \\mathbf{v}_u^*) \\mathbf{s}_m + C \\mathbf{v}_u^*\n",
    "= \\sum_{m=1}^M q_{m,u} \\mathbf{s}_m \\mathbf{s}_m^\\top \\mathbf{v}_u^* + C \\mathbf{v}_u^*\n",
    "= \\left( \\sum_{m=1}^M q_{m,u} \\mathbf{s}_m \\mathbf{s}_m^\\top + C \\mathbf{I} \\right) \\mathbf{v}_u^*\n",
    "\\end{aligned}\n",
    "$  \n",
    "where $\\mathbf{I} \\in \\mathbb{R}^{D \\times D}$ is the identity matrix.  \n",
    "So \n",
    "$\n",
    "\\begin{aligned}\n",
    "\\mathbf{v}_u^* = \\left( \\sum_{m=1}^M q_{m,u} \\mathbf{s}_m \\mathbf{s}_m^\\top + C \\mathbf{I} \\right)^{-1} \\sum_{m=1}^M q_{m,u} t_{m,u} \\mathbf{s}_m \n",
    "\\end{aligned}\n",
    "$  \n",
    "or equivalently\n",
    "$\n",
    "\\begin{aligned}\n",
    "\\mathbf{v}_u^* \n",
    "= \\left( (\\mathbf{q}_{:,u}[..., \\text{np.newaxis}] \\times S)^\\top S + C \\mathbf{I} \\right)^{-1} \\left( (\\mathbf{q}_{:u} \\circ \\mathbf{t}_{:,u})^\\top S \\right)^\\top\n",
    "\\end{aligned}\n",
    "$  \n",
    "where np.newaxis is for numpy broadcasting and $\\circ$ is entrywise product of vector/matrix.  \n",
    "*It seems we have to use 3-dimension tensor (U by M by D) if we want to compute all values at once, this could be impractical due to memory usage.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Fix $V$, then let\n",
    "$\n",
    "\\begin{aligned}\n",
    "\\mathbf{0}\n",
    "= \\frac{\\partial J}{\\partial \\mathbf{s}_m}\n",
    "= \\sum_{u=1}^U 2 q_{m,u} \\left( t_{m,u} - \\mathbf{s}_m^\\top \\mathbf{v}_u \\right) (-\\mathbf{v}_u) + 2 C \\mathbf{s}_m\n",
    "\\end{aligned}\n",
    "$  \n",
    "by symmetry, we have  \n",
    "$\n",
    "\\begin{aligned}\n",
    "\\mathbf{s}_m^* \n",
    "= \\left( (\\mathbf{q}_{m:}[\\text{np.newaxis}, ...] \\times V)^\\top V + C \\mathbf{I} \\right)^{-1} \\left( (\\mathbf{q}_{m:} \\circ \\mathbf{t}_{m,:})^\\top V \\right)^\\top\n",
    "\\end{aligned}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8070\n"
     ]
    }
   ],
   "source": [
    "users = sorted({u for _, u in train_playlists})\n",
    "user2index = {u: uix for uix, u in enumerate(users)}\n",
    "print(len(users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15262it [00:12, 1200.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(45468, 8070)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = X.shape[0]\n",
    "U = len(users)\n",
    "\n",
    "R = np.zeros((M, U))\n",
    "for pix, (_, u) in tqdm(enumerate(train_playlists)):\n",
    "    R[:, user2index[u]] += Y_train[:, pix].A.reshape(-1)\n",
    "R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45468, 8070)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = (R > 0).astype(np.float32)\n",
    "T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.cuda.is_available()\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/u5708856/apps/miniconda3/lib/python3.6/site-packages/torch/cuda/__init__.py:116: UserWarning: \n",
      "    Found GPU1 Quadro K600 which is of cuda capability 3.0.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\n"
     ]
    }
   ],
   "source": [
    "D = 100\n",
    "C = 1e-5\n",
    "alpha = 40\n",
    "eps = 1e-8\n",
    "\n",
    "torch.manual_seed(0)\n",
    "S = torch.rand(M, D).to(device)\n",
    "V = torch.rand(U, D).to(device)\n",
    "\n",
    "Q = 1 + alpha * (np.log(1 / eps) + np.log(eps + R))  # M by U, dense\n",
    "QT = np.multiply(Q, T).astype(np.float32)  # M by U\n",
    "QT_csc = csc_matrix(QT)\n",
    "QT_csr = csr_matrix(QT)\n",
    "Q = torch.from_numpy(Q.astype(np.float32)).to(device)\n",
    "del QT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000 / 8070\n",
      "45400 / 45468\n",
      "V diff: 521.322937, S diff: 1006.677539 in 291.3 seconds.\n",
      "8000 / 8070\n",
      "45400 / 45468\n",
      "V diff: 27.668184, S diff: 145.611794 in 240.4 seconds.\n",
      "8000 / 8070\n",
      "45400 / 45468\n",
      "V diff: 15.029595, S diff: 90.212691 in 233.6 seconds.\n",
      "8000 / 8070\n",
      "45400 / 45468\n",
      "V diff: 10.327211, S diff: 67.395220 in 252.1 seconds.\n",
      "8000 / 8070\n",
      "45400 / 45468\n",
      "V diff: 7.904257, S diff: 52.229260 in 242.2 seconds.\n",
      "8000 / 8070\n",
      "45400 / 45468\n",
      "V diff: 6.400798, S diff: 42.176519 in 255.1 seconds.\n",
      "8000 / 8070\n",
      "45400 / 45468\n",
      "V diff: 5.366733, S diff: 35.256144 in 246.3 seconds.\n",
      "8000 / 8070\n",
      "45400 / 45468\n",
      "V diff: 4.610273, S diff: 30.242341 in 224.9 seconds.\n",
      "8000 / 8070\n",
      "45400 / 45468\n",
      "V diff: 4.033070, S diff: 26.439593 in 225.8 seconds.\n",
      "8000 / 8070\n",
      "45400 / 45468\n",
      "V diff: 3.578605, S diff: 23.448129 in 225.9 seconds.\n",
      "8000 / 8070\n",
      "45400 / 45468\n",
      "V diff: 3.211968, S diff: 21.034353 in 224.0 seconds.\n",
      "8000 / 8070\n",
      "45400 / 45468\n",
      "V diff: 2.910349, S diff: 19.047010 in 224.4 seconds.\n",
      "8000 / 8070\n",
      "45400 / 45468\n",
      "V diff: 2.658185, S diff: 17.385883 in 222.6 seconds.\n",
      "8000 / 8070\n",
      "45400 / 45468\n",
      "V diff: 2.444423, S diff: 15.977725 in 224.0 seconds.\n",
      "8000 / 8070\n",
      "45400 / 45468\n",
      "V diff: 2.261050, S diff: 14.770885 in 221.1 seconds.\n",
      "8000 / 8070\n",
      "45400 / 45468\n",
      "V diff: 2.102114, S diff: 13.724324 in 220.2 seconds.\n",
      "8000 / 8070\n",
      "45400 / 45468\n",
      "V diff: 1.963108, S diff: 12.809409 in 224.1 seconds.\n",
      "8000 / 8070\n",
      "45400 / 45468\n",
      "V diff: 1.840540, S diff: 12.001982 in 222.5 seconds.\n",
      "8000 / 8070\n",
      "45400 / 45468\n",
      "V diff: 1.731719, S diff: 11.284453 in 221.1 seconds.\n",
      "8000 / 8070\n",
      "45400 / 45468\n",
      "V diff: 1.634455, S diff: 10.643604 in 219.6 seconds.\n"
     ]
    }
   ],
   "source": [
    "n_sweeps = 20\n",
    "\n",
    "# alternating least squares\n",
    "for sweep in range(n_sweeps):\n",
    "    t0 = time.time()\n",
    "    vdiff2 = 0.\n",
    "    sdiff2 = 0.\n",
    "    \n",
    "    # fix S, optimise V\n",
    "    S_cpu = S.cpu().numpy()\n",
    "    for uix in range(U):\n",
    "        if (uix + 1) % 100 == 0:\n",
    "            sys.stdout.write('\\r%d / %d' % (uix+1, U))\n",
    "            sys.stdout.flush()\n",
    "        QSu = torch.mm((Q[:, uix].reshape(M, 1) * S).t(), S)  # D by D\n",
    "        QSu[range(D), range(D)] = C + QSu.diag()\n",
    "        QTuS = torch.from_numpy(QT_csc[:, uix].transpose().dot(S_cpu).reshape(D, 1)).to(device)\n",
    "        v_u = torch.mm(torch.inverse(QSu), QTuS).reshape(-1)\n",
    "        diff = v_u - V[uix, :]\n",
    "        vdiff2 += torch.mm(diff.reshape(1, -1), diff.reshape(-1, 1)).cpu().item()\n",
    "        V[uix, :] = v_u\n",
    "\n",
    "    print()\n",
    "    \n",
    "    # fix V, optimise S\n",
    "    V_cpu = V.cpu().numpy()\n",
    "    for m in range(M):\n",
    "        if (m + 1) % 100 == 0:\n",
    "            sys.stdout.write('\\r%d / %d' % (m+1, M))\n",
    "            sys.stdout.flush()\n",
    "        QVm = torch.mm((Q[m, :].reshape(U, 1) * V).t(), V)  # D by D\n",
    "        QVm[range(D), range(D)] = C + QVm.diag()\n",
    "        QTmV = torch.from_numpy(QT_csr[m, :].dot(V_cpu).reshape(D, 1)).to(device)\n",
    "        s_m = torch.mm(torch.inverse(QVm), QTmV).reshape(-1)\n",
    "        diff = s_m - S[m, :]\n",
    "        sdiff2 += torch.mm(diff.reshape(1, -1), diff.reshape(-1, 1)).cpu().item()\n",
    "        S[m, :] = s_m\n",
    "    print('\\nV diff: {:8.6f}, S diff: {:8.6f} in {:.1f} seconds.'\n",
    "          .format(np.sqrt(vdiff2), np.sqrt(sdiff2), time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check: compute optimisation objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 4.94277e+06\n"
     ]
    }
   ],
   "source": [
    "cost = np.multiply(Q.cpu().numpy(), np.square(T - torch.mm(S, V.t()).cpu().numpy())).sum() \\\n",
    "       + C * (torch.mul(S, S).sum().cpu().item() + torch.mul(V, V).sum().cpu().item())\n",
    "print('Cost: %g' % cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del QT\n",
    "# T = torch.from_numpy(T).to(device)\n",
    "# cost = torch.mul(Q, (T - torch.mm(S, V.t())) ** 2).sum() + C * (torch.mul(S, S).sum() + torch.mul(V, V).sum())\n",
    "# print('Cost: %g' % cost.cpu().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100 / 2195\n",
      "2195 / 2195\n"
     ]
    }
   ],
   "source": [
    "rps_mf = []\n",
    "hitrates_mf = {top: [] for top in TOPs}\n",
    "aucs_mf = []\n",
    "spreads_mf = []\n",
    "novelties_mf = {top: dict() for top in TOPs}\n",
    "ptops_mf = []\n",
    "# artist_diversities_mf = {top: [] for top in TOPs}\n",
    "# genre_diversities_mf = {top: [] for top in TOPs}\n",
    "np.random.seed(0)\n",
    "\n",
    "npos = Y_test.sum(axis=0).A.reshape(-1)\n",
    "for j in range(Y_test.shape[1]):\n",
    "    if (j+1) % 100 == 0:\n",
    "        sys.stdout.write('\\r%d / %d' % (j+1, Y_test.shape[1]))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    assert npos[j] > 0\n",
    "    y_true = Y_test[:, j].A.reshape(-1)\n",
    "    \n",
    "    u = test_playlists[j][1]\n",
    "    uix = user2index[u]\n",
    "    y_pred = torch.mm(S, V[uix, :].reshape(D, 1)).reshape(-1).cpu().numpy()\n",
    "\n",
    "    rp, hr_dict, auc = calc_metrics(y_true, y_pred, tops=TOPs)\n",
    "    rps_mf.append(rp)\n",
    "    for top in TOPs:\n",
    "        hitrates_mf[top].append(hr_dict[top])\n",
    "    # auc = roc_auc_score(y_true, y_pred)\n",
    "    aucs_mf.append(auc)\n",
    "    \n",
    "    # spread\n",
    "    y_pred_prob = softmax(y_pred)\n",
    "    spreads_mf.append(-np.dot(y_pred_prob, np.log(y_pred_prob)))\n",
    "\n",
    "    # novelty\n",
    "    sortix = np.argsort(-y_pred)\n",
    "    for top in TOPs:\n",
    "        nov = np.mean([-np.log2(song2pop[index2song[ix]]) for ix in sortix[:top]])\n",
    "        try:\n",
    "            novelties_mf[top][u].append(nov)\n",
    "        except KeyError:\n",
    "            novelties_mf[top][u] = [nov]\n",
    "    \n",
    "    # PTop: (#pos ranked above the top-ranked negative) / #pos\n",
    "    assert y_true.dtype == np.bool\n",
    "    negIx = (1 - y_true).astype(np.bool)\n",
    "    negMax = y_pred[negIx].max()\n",
    "    pt = (y_pred[y_true] > negMax).sum() / npos[j]\n",
    "    ptops_mf.append(pt)\n",
    "    \n",
    "    # artist/genre diversity\n",
    "#     for top in TOPs:\n",
    "#         artist_vec = np.array([song2artist[index2song[ix]] if index2song[ix] in song2artist\n",
    "#                                else str(np.random.rand()) for ix in sortix[:top]])\n",
    "#         genre_vec = np.array([song2genre[index2song[ix]] if index2song[ix] in song2genre \\\n",
    "#                               else str(np.random.rand()) for ix in sortix[:top]])\n",
    "#         artist_diversities_mf[top].append( diversity(artist_vec) )\n",
    "#         genre_diversities_mf[top].append( diversity(genre_vec) )\n",
    "    \n",
    "print('\\n%d / %d' % (len(rps_mf), Y_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R-Precision': 0.049377764803008574,\n",
       " 'Hit-Rate': {5: 0.02926413021841258,\n",
       "  10: 0.05145004242622205,\n",
       "  20: 0.08365600180191513,\n",
       "  30: 0.10832635049146337,\n",
       "  50: 0.14684679166554612,\n",
       "  100: 0.20944700009287984,\n",
       "  200: 0.2839112515396292,\n",
       "  300: 0.3305675286049512,\n",
       "  500: 0.393693238383796,\n",
       "  700: 0.4332726753350746,\n",
       "  1000: 0.4786869565897743},\n",
       " 'AUC': 0.795183426779958,\n",
       " 'Spread': 10.714413,\n",
       " 'Novelty': {5: -6.018945667786334,\n",
       "  10: -5.72709257141705,\n",
       "  20: -5.536654436754104,\n",
       "  30: -5.466014811385599,\n",
       "  50: -5.377907076684237,\n",
       "  100: -5.239391290556176,\n",
       "  200: -5.006387650968637,\n",
       "  300: -4.817936851371754,\n",
       "  500: -4.521864744646671,\n",
       "  700: -4.295592416792713,\n",
       "  1000: -4.03507939188452},\n",
       " 'PTop': 0.008486400283950701}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_mf = {dataset_name: {'Test': {'R-Precision': np.mean(rps_mf), \n",
    "                                'Hit-Rate': {top: np.mean(hitrates_mf[top]) for top in TOPs},\n",
    "                                'AUC': np.mean(aucs_mf),\n",
    "                                'Spread': np.mean(spreads_mf),\n",
    "                                'Novelty': {t: np.mean([np.mean(novelties_mf[t][u]) for u in novelties_mf[t]]) \n",
    "                                            for t in TOPs},\n",
    "                                'PTop': np.mean(ptops_mf),\n",
    "                                # 'Artist-Diversity': {top: np.mean(artist_diversities_mf[top]) for top in TOPs},\n",
    "                                # 'Genre-Diversity': {top: np.mean(genre_diversities_mf[top]) for top in TOPs}},\n",
    "                                  },\n",
    "                        'Test_All': {'R-Precision': rps_mf,\n",
    "                                    'Hit-Rate': {top: hitrates_mf[top] for top in TOPs},\n",
    "                                    'AUC': aucs_mf,\n",
    "                                    'Spread': spreads_mf,\n",
    "                                    'Novelty': novelties_mf,\n",
    "                                    'PTop': ptops_mf,\n",
    "                                    # 'Artist-Diversity': artist_diversities_mf,\n",
    "                                    # 'Genre-Diversity': genre_diversities_mf}}}\n",
    "                                    }}}\n",
    "perf_mf[dataset_name]['Test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/30music/coldstart/setting3/perf-mf.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'R-Precision': 0.049377764803008574,\n",
       " 'Hit-Rate': {5: 0.02926413021841258,\n",
       "  10: 0.05145004242622205,\n",
       "  20: 0.08365600180191513,\n",
       "  30: 0.10832635049146337,\n",
       "  50: 0.14684679166554612,\n",
       "  100: 0.20944700009287984,\n",
       "  200: 0.2839112515396292,\n",
       "  300: 0.3305675286049512,\n",
       "  500: 0.393693238383796,\n",
       "  700: 0.4332726753350746,\n",
       "  1000: 0.4786869565897743},\n",
       " 'AUC': 0.795183426779958,\n",
       " 'Spread': 10.714413,\n",
       " 'Novelty': {5: -6.018945667786334,\n",
       "  10: -5.72709257141705,\n",
       "  20: -5.536654436754104,\n",
       "  30: -5.466014811385599,\n",
       "  50: -5.377907076684237,\n",
       "  100: -5.239391290556176,\n",
       "  200: -5.006387650968637,\n",
       "  300: -4.817936851371754,\n",
       "  500: -4.521864744646671,\n",
       "  700: -4.295592416792713,\n",
       "  1000: -4.03507939188452},\n",
       " 'PTop': 0.008486400283950701}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fperf_mf = os.path.join(data_dir, 'perf-mf.pkl')\n",
    "print(fperf_mf)\n",
    "pkl.dump(perf_mf, open(fperf_mf, 'wb'))\n",
    "pkl.load(open(fperf_mf, 'rb'))[dataset_name]['Test']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
