{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playlist augmentation baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys, time, gzip\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.sparse import lil_matrix, issparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import MTC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from tools import calc_RPrecision_HitRate\n",
    "from tools import calc_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPs = [5, 10, 20, 30, 50, 100, 200, 300, 500, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['aotm2011', '30music']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dix = 0\n",
    "dataset_name = datasets[dix]\n",
    "dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = pkl.load(gzip.open(os.path.join(base_dir, 'X_train_dev.pkl.gz'), 'rb'))\n",
    "# Y = pkl.load(gzip.open(os.path.join(base_dir, 'Y.pkl.gz'), 'rb'))\n",
    "# PU_test = pkl.load(gzip.open(os.path.join(base_dir, 'PU_test.pkl.gz'), 'rb'))\n",
    "# playlists2 = pkl.load(gzip.open(os.path.join(base_dir, 'playlists_train_dev_test_s2.pkl.gz'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_seed = 1\n",
    "data_dir = 'data/%s/setting2' % dataset_name\n",
    "X = pkl.load(gzip.open(os.path.join(data_dir, 'X_trndev_%d.pkl.gz' % n_seed), 'rb'))\n",
    "Y = pkl.load(gzip.open(os.path.join(data_dir, 'Y.pkl.gz'), 'rb'))\n",
    "PU_test = pkl.load(gzip.open(os.path.join(data_dir, 'PU_test_%d.pkl.gz' % n_seed), 'rb'))\n",
    "song2pop = pkl.load(gzip.open(os.path.join(data_dir, 'song2pop.pkl.gz'), 'rb'))\n",
    "playlists2 = pkl.load(gzip.open(os.path.join(data_dir, 'playlists_train_dev_test_s2_%d.pkl.gz' % n_seed), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = Y[:, -PU_test.shape[1]:]\n",
    "print(Y_test.shape)\n",
    "#Y_test.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_songs = pkl.load(gzip.open(os.path.join(data_dir, 'all_songs.pkl.gz'), 'rb'))\n",
    "index2song = {ix: sid for ix, (sid, _) in enumerate(all_songs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song2index = {sid: ix for ix, (sid, _) in enumerate(all_songs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song2pop_test = song2pop.copy()\n",
    "\n",
    "for ppl in playlists2['test_playlists_held']:\n",
    "    for sid in ppl:\n",
    "        song2pop_test[sid] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray([song2pop[sid] for sid, _ in all_songs], dtype=np.float).reshape(len(all_songs), 1)\n",
    "X_train_mean = np.mean(X_train, axis=0)\n",
    "X_train_std = np.std(X_train, axis=0) + 1e-6\n",
    "X_train -= X_train_mean\n",
    "X_train /= X_train_std\n",
    "\n",
    "pkl.dump(X_train, gzip.open(os.path.join(data_dir, 'X_trndev_pop_%d.pkl.gz' % n_seed), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song2artist = pkl.load(gzip.open('data/msd/song2artist.pkl.gz', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist2song = dict()\n",
    "\n",
    "for sid in sorted(song2artist):\n",
    "    artist = song2artist[sid]\n",
    "    try:\n",
    "        artist2song[artist].append(sid)\n",
    "    except KeyError:\n",
    "        artist2song[artist] = [sid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{:,} | {:,}'.format(len(song2artist), len(artist2song)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collocated Artists - Greatest Hits (CAGH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the similarity of two artist $a_1$ and $a_2$ given a set of playlist $P$:   \n",
    "$$\n",
    "\\text{sim}(a_1, a_2) \n",
    "= \\frac{\\sum_{p \\in P} \\delta(a_1, p) \\times \\delta(a_2, p)}\n",
    "       {\\sqrt{\\sum_{p \\in P} \\delta(a_1, p) \\times \\sum_{p \\in P} \\delta(a_2, p)}}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\delta(a, p) \n",
    "= \\begin{cases}\n",
    "1, \\ \\text{at least one song in playlist $p$ is from artist $a$}, \\\\\n",
    "0, \\ \\text{otherwise}.\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_playlist = pkl.load(gzip.open('data/%s/%s-playlist.pkl.gz' % (dataset_name, dataset_name), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_artist = sorted(set([song2artist[sid] for pl, _ in all_playlist for sid in pl if sid in song2artist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist2index = {aid: ix for ix, aid in enumerate(all_artist)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Na = len(all_artist)\n",
    "Np = len(all_playlist)\n",
    "Delta = lil_matrix((Na, Np), dtype=np.float)\n",
    "for j in range(Np):\n",
    "    pl_artist = sorted(set([song2artist[sid] for sid in all_playlist[j][0] if sid in song2artist]))\n",
    "    ix = [artist2index[aid] for aid in pl_artist]\n",
    "    Delta[ix, j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Delta = Delta.tocsr()\n",
    "Dsum = Delta.sum(axis=1).A.reshape(-1)\n",
    "ColloMat = Delta.dot(Delta.T).A\n",
    "\n",
    "assert np.all(np.isclose(ColloMat.diagonal(), Dsum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(Dsum), len(all_artist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(ColloMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = 1. / np.sqrt(Dsum)\n",
    "NormMat = np.dot(T1.reshape(Na, 1), T1.reshape(1, Na))\n",
    "\n",
    "WeightMat = np.multiply(ColloMat, NormMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rps_cagh = []\n",
    "hitrates_cagh = {top: [] for top in TOPs}\n",
    "aucs_cagh = []\n",
    "\n",
    "assert Y_test.shape == PU_test.shape\n",
    "for j in range(Y_test.shape[1]):\n",
    "    sys.stdout.write('\\r%d / %d' % (j+1, Y_test.shape[1]))\n",
    "    sys.stdout.flush()\n",
    "    y1 = Y_test[:, j].toarray().reshape(-1)\n",
    "    y2 = PU_test[:, j].toarray().reshape(-1)\n",
    "    indices = np.where(0 == y2)[0]\n",
    "    y_true = y1[indices]\n",
    "    \n",
    "    seeds = [index2song[ix] for ix in np.where(y2 > 0)[0]]\n",
    "    artists = sorted(set([song2artist[sid] for sid in seeds if sid in song2artist]))\n",
    "    artists_ix = [artist2index[aid] for aid in artists]\n",
    "    \n",
    "    y_pred = np.zeros(y1.shape)\n",
    "    ix_legal = [ix for ix in indices if index2song[ix] in song2artist]\n",
    "    sid_legal = [index2song[ix] for ix in ix_legal]\n",
    "    aix_legal = [artist2index[song2artist[sid]] for sid in sid_legal]\n",
    "    pop_legal = np.asarray([song2pop_test[sid] for sid in sid_legal])\n",
    "    y_pred[ix_legal] = pop_legal * np.asarray([WeightMat[aix, artists_ix].sum() for aix in aix_legal])\n",
    "    \n",
    "#     for ix in ix_legal:\n",
    "#         sid = index2song[ix]\n",
    "#         aix = artist2index[song2artist[sid]]\n",
    "#         pop = song2pop_test[sid]\n",
    "#         y_pred[ix] = pop * WeightMat[aix, artists_ix].sum()\n",
    "    \n",
    "    y_pred = y_pred[indices]\n",
    "    \n",
    "    # rp, hr_dict = calc_RPrecision_HitRate(y_true, y_pred, tops=TOPs)\n",
    "    rp, hr_dict, auc = calc_metrics(y_true, y_pred, tops=TOPs)\n",
    "    rps_cagh.append(rp)\n",
    "    for top in TOPs:\n",
    "        hitrates_cagh[top].append(hr_dict[top])\n",
    "    aucs_cagh.append(auc)\n",
    "    \n",
    "print('\\n%d / %d' % (len(rps_cagh), PU_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[20, 5])\n",
    "ax1 = plt.subplot(131)\n",
    "ax1.hist(rps_cagh, bins=100)\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_title('R-Precision')\n",
    "#ax.set_xlim(0, xmax)\n",
    "ax2 = plt.subplot(132)\n",
    "ax2.hist(aucs_cagh, bins=100)\n",
    "ax2.set_yscale('log')\n",
    "ax2.set_title('AUC')\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cagh_perf = {dataset_name: {'Test': {'R-Precision': np.mean(rps_cagh), \n",
    "                                     'Hit-Rate': {top: np.mean(hitrates_cagh[top]) for top in hitrates_cagh},\n",
    "                                     'AUC': np.mean(aucs_cagh),}}}\n",
    "cagh_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fperf_cagh = os.path.join(data_dir, 'perf-cagh-%d.pkl' % n_seed)\n",
    "print(fperf_cagh)\n",
    "pkl.dump(cagh_perf, open(fperf_cagh, 'wb'))\n",
    "pkl.load(open(fperf_cagh, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same Artists - Greatest Hits (SAGH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommend according to the popularity of songs of artists in listening history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rps_sagh = []\n",
    "hitrates_sagh = {top: [] for top in TOPs}\n",
    "aucs_sagh = []\n",
    "\n",
    "assert Y_test.shape == PU_test.shape\n",
    "for j in range(Y_test.shape[1]):\n",
    "    if (j+1) % 10 == 0:\n",
    "        sys.stdout.write('\\r%d / %d' % (j+1, Y_test.shape[1]))\n",
    "        sys.stdout.flush()\n",
    "    y1 = Y_test[:, j].toarray().reshape(-1)\n",
    "    y2 = PU_test[:, j].toarray().reshape(-1)\n",
    "    indices = np.where(0 == y2)[0]\n",
    "    y_true = y1[indices]\n",
    "    \n",
    "    seeds = [index2song[ix] for ix in np.where(y2 > 0)[0]]\n",
    "    artists = sorted(set([song2artist[sid] for sid in seeds if sid in song2artist]))\n",
    "    y_pred = np.zeros(y1.shape)\n",
    "    candidates = []\n",
    "    for a in artists:\n",
    "        candidates += artist2song[a]\n",
    "    candidates = set(candidates) & set([index2song[ix] for ix in indices])\n",
    "    \n",
    "    if len(candidates) > 0:\n",
    "        for sid in candidates:\n",
    "            ix = song2index[sid]\n",
    "            y_pred[ix] = song2pop_test[sid]\n",
    "\n",
    "    y_pred = y_pred[indices]\n",
    "    # rp, hr_dict = calc_RPrecision_HitRate(y_true, y_pred, tops=TOPs)\n",
    "    rp, hr_dict, auc = calc_metrics(y_true, y_pred, tops=TOPs)\n",
    "    rps_sagh.append(rp)\n",
    "    for top in TOPs:\n",
    "        hitrates_sagh[top].append(hr_dict[top])\n",
    "    aucs_sagh.append(auc)\n",
    "    \n",
    "print('\\n%d / %d' % (len(rps_sagh), PU_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[20, 5])\n",
    "ax1 = plt.subplot(131)\n",
    "ax1.hist(rps_sagh, bins=100)\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_title('R-Precision')\n",
    "#ax.set_xlim(0, xmax)\n",
    "ax2 = plt.subplot(132)\n",
    "ax2.hist(aucs_sagh, bins=100)\n",
    "ax2.set_yscale('log')\n",
    "ax2.set_title('AUC')\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagh_perf = {dataset_name: {'Test': {'R-Precision': np.mean(rps_sagh), \n",
    "                                     'Hit-Rate': {top: np.mean(hitrates_sagh[top]) for top in hitrates_sagh},\n",
    "                                     'AUC': np.mean(aucs_sagh),}}}\n",
    "sagh_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fperf_sagh = os.path.join(data_dir, 'perf-sagh-%d.pkl' % n_seed)\n",
    "print(fperf_sagh)\n",
    "pkl.dump(sagh_perf, open(fperf_sagh, 'wb'))\n",
    "pkl.load(open(fperf_sagh, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression using song popularity as the only feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rps_lrpop = []\n",
    "hitrates_lrpop = {top: [] for top in TOPs}\n",
    "aucs_lrpop = []\n",
    "\n",
    "X_train = np.asarray([song2pop_test[sid] for sid, _ in all_songs], dtype=np.float).reshape(len(all_songs), 1)\n",
    "X_train_mean = np.mean(X_train, axis=0)\n",
    "X_train_std = np.std(X_train, axis=0) + 1e-6\n",
    "X_train -= X_train_mean\n",
    "X_train /= X_train_std\n",
    "for j in range(Y_test.shape[1]):\n",
    "    if (j+1) % 10 == 0:\n",
    "        sys.stdout.write('\\r%d / %d' % (j+1, Y_test.shape[1]))\n",
    "        sys.stdout.flush()\n",
    "    y1 = Y_test[:, j].toarray().reshape(-1)\n",
    "    y2 = PU_test[:, j].toarray().reshape(-1)\n",
    "    indices = np.where(0 == y2)[0]\n",
    "    y_true = y1[indices]\n",
    "    \n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train, y2)\n",
    "    #X_test = np.asarray([song2pop[index2song[ix]] for ix in indices]).reshape(len(indices), 1)\n",
    "    X_test = X_train\n",
    "    y_pred = clf.decision_function(X_test)[indices]\n",
    "    \n",
    "    rp, hr_dict, auc = calc_metrics(y_true, y_pred, tops=TOPs)\n",
    "    rps_lrpop.append(rp)\n",
    "    for top in TOPs:\n",
    "        hitrates_lrpop[top].append(hr_dict[top])\n",
    "    aucs_lrpop.append(auc)\n",
    "    \n",
    "print('\\n%d / %d' % (len(rps_lrpop), Y_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[20, 5])\n",
    "ax1 = plt.subplot(131)\n",
    "ax1.hist(rps_lrpop, bins=100)\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_title('R-Precision')\n",
    "#ax.set_xlim(0, xmax)\n",
    "ax2 = plt.subplot(132)\n",
    "ax2.hist(aucs_lrpop, bins=100)\n",
    "ax2.set_yscale('log')\n",
    "ax2.set_title('AUC')\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrpop_perf = {dataset_name: {'Test': {'R-Precision': np.mean(rps_lrpop), \n",
    "                                      'Hit-Rate': {top: np.mean(hitrates_lrpop[top]) for top in hitrates_lrpop},\n",
    "                                      'AUC': np.mean(aucs_lrpop),}}}\n",
    "lrpop_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fperf_lrpop = os.path.join(data_dir, 'perf-lrpop-%d.pkl' % n_seed)\n",
    "print(fperf_lrpop)\n",
    "pkl.dump(lrpop_perf, open(fperf_lrpop, 'wb'))\n",
    "pkl.load(open(fperf_lrpop, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity based recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rps_pop = []\n",
    "hitrates_pop = {top: [] for top in TOPs}\n",
    "aucs_pop = []\n",
    "\n",
    "assert Y_test.shape == PU_test.shape\n",
    "for j in range(Y_test.shape[1]):\n",
    "    if (j+1) % 10 == 0:\n",
    "        sys.stdout.write('\\r%d / %d' % (j+1, Y_test.shape[1]))\n",
    "        sys.stdout.flush()\n",
    "    y1 = Y_test[:, j].toarray().reshape(-1)\n",
    "    y2 = PU_test[:, j].toarray().reshape(-1)\n",
    "    indices = np.where(0 == y2)[0]\n",
    "    y_true = y1[indices]\n",
    "    \n",
    "    y_pred = np.array([song2pop_test[index2song[ix]] for ix in indices])\n",
    "    \n",
    "    # rp, hr_dict = calc_RPrecision_HitRate(y_true, y_pred, tops=TOPs)\n",
    "    rp, hr_dict, auc = calc_metrics(y_true, y_pred, tops=TOPs)\n",
    "    rps_pop.append(rp)\n",
    "    for top in TOPs:\n",
    "        hitrates_pop[top].append(hr_dict[top])\n",
    "    aucs_pop.append(auc)\n",
    "    \n",
    "print('\\n%d / %d' % (len(rps_pop), PU_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[20, 5])\n",
    "ax1 = plt.subplot(131)\n",
    "ax1.hist(rps_pop, bins=100)\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_title('R-Precision')\n",
    "#ax.set_xlim(0, xmax)\n",
    "ax2 = plt.subplot(132)\n",
    "ax2.hist(aucs_pop, bins=100)\n",
    "ax2.set_yscale('log')\n",
    "ax2.set_title('AUC')\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_perf = {dataset_name: {'Test': {'R-Precision': np.mean(rps_pop), \n",
    "                                    'Hit-Rate': {top: np.mean(hitrates_pop[top]) for top in hitrates_pop},\n",
    "                                    'AUC': np.mean(aucs_pop),}}}\n",
    "pop_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fperf_pop = os.path.join(data_dir, 'perf-pop-%d.pkl' % n_seed)\n",
    "print(fperf_pop)\n",
    "pkl.dump(pop_perf, open(fperf_pop, 'wb'))\n",
    "pkl.load(open(fperf_pop, 'rb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
