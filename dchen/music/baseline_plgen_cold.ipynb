{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines - playlist generation for known users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os, sys, time, gzip\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import lil_matrix, issparse, csc_matrix, csr_matrix\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tools import calc_RPrecision_HitRate\n",
    "from tools import calc_metrics, diversity, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPs = [5, 10, 20, 30, 50, 100, 200, 300, 500, 700, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['aotm2011', '30music']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'30music'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dix = 1\n",
    "dataset_name = datasets[dix]\n",
    "dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/%s/coldstart/setting4' % dataset_name\n",
    "X = pkl.load(gzip.open(os.path.join(data_dir, 'X.pkl.gz'), 'rb'))\n",
    "Y_train = pkl.load(gzip.open(os.path.join(data_dir, 'Y_train.pkl.gz'), 'rb'))\n",
    "Y_test = pkl.load(gzip.open(os.path.join(data_dir, 'Y_test.pkl.gz'), 'rb'))\n",
    "song2pop_train = pkl.load(gzip.open(os.path.join(data_dir, 'song2pop_train.pkl.gz'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists3 = pkl.load(gzip.open(os.path.join(data_dir, 'playlists_train_test_s4.pkl.gz'), 'rb'))\n",
    "train_playlists = playlists3['train_playlists']\n",
    "test_playlists = playlists3['test_playlists']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_songs = pkl.load(gzip.open(os.path.join(data_dir, 'all_songs.pkl.gz'), 'rb'))\n",
    "index2song = {ix: sid for ix, (sid, _) in enumerate(all_songs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "song2index = {sid: ix for ix, (sid, _) in enumerate(all_songs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_song2artist = pkl.load(gzip.open('data/msd/song2artist.pkl.gz', 'rb'))\n",
    "song2artist = {sid: _song2artist[sid] for sid, _ in all_songs if sid in _song2artist}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist2songs = dict()\n",
    "\n",
    "for sid in sorted(song2artist):\n",
    "    artist = song2artist[sid]\n",
    "    try:\n",
    "        artist2songs[artist].append(sid)\n",
    "    except KeyError:\n",
    "        artist2songs[artist] = [sid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45,468 | 9,981\n"
     ]
    }
   ],
   "source": [
    "print('{:,} | {:,}'.format(len(song2artist), len(artist2songs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist2pop = dict()\n",
    "\n",
    "for pl, _ in train_playlists:\n",
    "    for sid in pl:\n",
    "        if sid in song2artist:\n",
    "            aid = song2artist[sid]\n",
    "            try:\n",
    "                artist2pop[aid] += 1\n",
    "            except KeyError:\n",
    "                artist2pop[aid] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9981\n"
     ]
    }
   ],
   "source": [
    "print(len(artist2pop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "song2genre = pkl.load(gzip.open('data/msd/song2genre.pkl.gz', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "song2pop = pkl.load(gzip.open(os.path.join(data_dir, 'song2pop.pkl.gz'), 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collocated Artists - Greatest Hits (CAGH), Top 10 Artists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the similarity of two artist $a_1$ and $a_2$ given a set of playlist $P$:   \n",
    "$$\n",
    "\\text{sim}(a_1, a_2) \n",
    "= \\frac{\\sum_{p \\in P} \\delta(a_1, p) \\times \\delta(a_2, p)}\n",
    "       {\\sqrt{\\sum_{p \\in P} \\delta(a_1, p) \\times \\sum_{p \\in P} \\delta(a_2, p)}}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\delta(a, p) \n",
    "= \\begin{cases}\n",
    "1, \\ \\text{at least one song in playlist $p$ is from artist $a$}, \\\\\n",
    "0, \\ \\text{otherwise}.\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommend according to the popularity of songs, but weighted by similarity of (`top 10 artists`, `artist of song`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_artist = sorted(set([song2artist[sid] for pl, _ in train_playlists for sid in pl if sid in song2artist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist2index = {aid: ix for ix, aid in enumerate(all_artist)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Na = len(all_artist)\n",
    "Np = len(train_playlists)\n",
    "Delta = lil_matrix((Na, Np), dtype=np.float)\n",
    "for j in range(Np):\n",
    "    pl_artist = sorted(set([song2artist[sid] for sid in train_playlists[j][0] if sid in song2artist]))\n",
    "    ix = [artist2index[aid] for aid in pl_artist]\n",
    "    Delta[ix, j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Delta = Delta.tocsr()\n",
    "Dsum = Delta.sum(axis=1).A.reshape(-1)\n",
    "ColloMat = Delta.dot(Delta.T).A\n",
    "\n",
    "assert np.all(np.isclose(ColloMat.diagonal(), Dsum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9981 9981\n"
     ]
    }
   ],
   "source": [
    "print(len(Dsum), len(all_artist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(ColloMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = 1. / np.sqrt(Dsum)\n",
    "NormMat = np.dot(T1.reshape(Na, 1), T1.reshape(1, Na))\n",
    "\n",
    "WeightMat = np.multiply(ColloMat, NormMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3390 / 3390\n",
      "3390 / 3390\n"
     ]
    }
   ],
   "source": [
    "rps_cagh = []\n",
    "hitrates_cagh = {top: [] for top in TOPs}\n",
    "aucs_cagh = []\n",
    "novelties_cagh = {top: dict() for top in TOPs}\n",
    "ptops_cagh = []\n",
    "# artist_diversities_cagh = {top: [] for top in TOPs}\n",
    "# genre_diversities_cagh = {top: [] for top in TOPs}\n",
    "np.random.seed(0)\n",
    "\n",
    "assert Y_test.shape[1] == len(test_playlists)\n",
    "\n",
    "sid_legal = [sid for sid, _ in all_songs if sid in song2artist]\n",
    "aix_legal = [artist2index[song2artist[sid]] for sid in sid_legal]\n",
    "pop_legal = np.asarray([song2pop_train[sid] for sid in sid_legal])\n",
    "ix_legal = [song2index[sid] for sid in sid_legal]\n",
    "\n",
    "top10_artists = sorted(artist2pop, key=lambda aid: artist2pop[aid])[-10:]\n",
    "top10_artists_ix = [artist2index[aix] for aix in top10_artists]\n",
    "y_pred = np.zeros(Y_test.shape[0])\n",
    "y_pred[ix_legal] = np.log(pop_legal) * np.asarray([WeightMat[aix, top10_artists_ix].sum() for aix in aix_legal])\n",
    "\n",
    "y_pred_prob = softmax(y_pred)\n",
    "spread_cagh = -np.dot(y_pred_prob, np.log(y_pred_prob))\n",
    "sortix = np.argsort(-y_pred)\n",
    "\n",
    "for j in range(Y_test.shape[1]):\n",
    "    if (j + 1) % 10 == 0:\n",
    "        sys.stdout.write('\\r%d / %d' % (j+1, Y_test.shape[1]))\n",
    "        sys.stdout.flush()\n",
    "    y_true = Y_test[:, j].A.reshape(-1)\n",
    "    \n",
    "    # rp, hr_dict = calc_RPrecision_HitRate(y_true, y_pred, tops=TOPs)\n",
    "    rp, hr_dict, auc = calc_metrics(y_true, y_pred, tops=TOPs)\n",
    "    rps_cagh.append(rp)\n",
    "    for top in TOPs:\n",
    "        hitrates_cagh[top].append(hr_dict[top])\n",
    "    aucs_cagh.append(auc)\n",
    "    \n",
    "    # novelty\n",
    "    u = test_playlists[j][1]\n",
    "    for top in TOPs:\n",
    "        nov = np.mean([-np.log2(song2pop[index2song[ix]]) for ix in sortix[:top]])\n",
    "        try:\n",
    "            novelties_cagh[top][u].append(nov)\n",
    "        except KeyError:\n",
    "            novelties_cagh[top][u] = [nov]\n",
    "            \n",
    "    # PTop: (#pos ranked above the top-ranked negative) / #pos\n",
    "    assert y_true.dtype == np.bool\n",
    "    npos = y_true.sum()\n",
    "    assert npos > 0\n",
    "    negIx = (1 - y_true).astype(np.bool)\n",
    "    negMax = y_pred[negIx].max()\n",
    "    pt = (y_pred[y_true] > negMax).sum() / npos\n",
    "    ptops_cagh.append(pt)\n",
    "    \n",
    "    # artist/genre diversity\n",
    "#     for top in TOPs:\n",
    "#         artist_vec = np.array([song2artist[index2song[ix]] if index2song[ix] in song2artist\n",
    "#                                else str(np.random.rand()) for ix in sortix[:top]])\n",
    "#         genre_vec = np.array([song2genre[index2song[ix]] if index2song[ix] in song2genre \\\n",
    "#                               else str(np.random.rand()) for ix in sortix[:top]])\n",
    "#         artist_diversities_cagh[top].append( diversity(artist_vec) )\n",
    "#         genre_diversities_cagh[top].append( diversity(genre_vec) )\n",
    "\n",
    "print('\\n%d / %d' % (len(rps_cagh), Y_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=[20, 5])\n",
    "# ax1 = plt.subplot(131)\n",
    "# ax1.hist(rps_cagh, bins=100)\n",
    "# ax1.set_yscale('log')\n",
    "# ax1.set_title('R-Precision')\n",
    "# #ax.set_xlim(0, xmax)\n",
    "# ax2 = plt.subplot(132)\n",
    "# ax2.hist(aucs_cagh, bins=100)\n",
    "# ax2.set_yscale('log')\n",
    "# ax2.set_title('AUC')\n",
    "# pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R-Precision': 0.01888252139764334,\n",
       " 'Hit-Rate': {5: 0.00938561519158546,\n",
       "  10: 0.01572263751842785,\n",
       "  20: 0.02534186251584444,\n",
       "  30: 0.03258846833600736,\n",
       "  50: 0.04900519217497452,\n",
       "  100: 0.07072537518556539,\n",
       "  200: 0.09193169553829512,\n",
       "  300: 0.12787903588292893,\n",
       "  500: 0.1771391444749642,\n",
       "  700: 0.22561080673198688,\n",
       "  1000: 0.28822054570313776},\n",
       " 'AUC': 0.8630670319003828,\n",
       " 'Spread': 4.1655933352494365,\n",
       " 'Novelty': {5: -8.185462101695036,\n",
       "  10: -7.965696610547907,\n",
       "  20: -7.6989764025668554,\n",
       "  30: -7.5403224343729685,\n",
       "  50: -7.340238954177793,\n",
       "  100: -6.750895588251327,\n",
       "  200: -5.962041526922837,\n",
       "  300: -5.744536110879032,\n",
       "  500: -5.447525515755583,\n",
       "  700: -5.326314293460358,\n",
       "  1000: -5.185188858182191},\n",
       " 'PTop': 0.003145728156957101}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cagh = {dataset_name: {'Test': {'R-Precision': np.mean(rps_cagh), \n",
    "                                'Hit-Rate': {top: np.mean(hitrates_cagh[top]) for top in TOPs},\n",
    "                                'AUC': np.mean(aucs_cagh),\n",
    "                                'Spread': spread_cagh,\n",
    "                                'Novelty': {t: np.mean([np.mean(novelties_cagh[t][u]) \n",
    "                                                        for u in novelties_cagh[t]]) for t in TOPs},\n",
    "                                'PTop': np.mean(ptops_cagh),\n",
    "                                # 'Artist-Diversity': {t: np.mean(artist_diversities_cagh[t]) for t in TOPs},\n",
    "                                # 'Genre-Diversity': {t: np.mean(genre_diversities_cagh[t]) for t in TOPs}},\n",
    "                               },\n",
    "                       'Test_All': {'R-Precision': rps_cagh, \n",
    "                                    'Hit-Rate': {top: hitrates_cagh[top] for top in TOPs},\n",
    "                                    'AUC': aucs_cagh,\n",
    "                                    'Spread': spread_cagh,\n",
    "                                    'Novelty': novelties_cagh,\n",
    "                                    'PTop': ptops_cagh,\n",
    "                                    # 'Artist-Diversity': artist_diversities_cagh,\n",
    "                                    # 'Genre-Diversity': genre_diversities_cagh}}}\n",
    "                                   }}}\n",
    "cagh[dataset_name]['Test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/30music/coldstart/setting4/perf-cagh.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'R-Precision': 0.01888252139764334,\n",
       " 'Hit-Rate': {5: 0.00938561519158546,\n",
       "  10: 0.01572263751842785,\n",
       "  20: 0.02534186251584444,\n",
       "  30: 0.03258846833600736,\n",
       "  50: 0.04900519217497452,\n",
       "  100: 0.07072537518556539,\n",
       "  200: 0.09193169553829512,\n",
       "  300: 0.12787903588292893,\n",
       "  500: 0.1771391444749642,\n",
       "  700: 0.22561080673198688,\n",
       "  1000: 0.28822054570313776},\n",
       " 'AUC': 0.8630670319003828,\n",
       " 'Spread': 4.1655933352494365,\n",
       " 'Novelty': {5: -8.185462101695036,\n",
       "  10: -7.965696610547907,\n",
       "  20: -7.6989764025668554,\n",
       "  30: -7.5403224343729685,\n",
       "  50: -7.340238954177793,\n",
       "  100: -6.750895588251327,\n",
       "  200: -5.962041526922837,\n",
       "  300: -5.744536110879032,\n",
       "  500: -5.447525515755583,\n",
       "  700: -5.326314293460358,\n",
       "  1000: -5.185188858182191},\n",
       " 'PTop': 0.003145728156957101}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fperf_cagh = os.path.join(data_dir, 'perf-cagh.pkl')\n",
    "print(fperf_cagh)\n",
    "pkl.dump(cagh, open(fperf_cagh, 'wb'))\n",
    "pkl.load(open(fperf_cagh, 'rb'))[dataset_name]['Test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same Artists - Greatest Hits (SAGH), Top 10 Artists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommending according to the popularity of songs of the top 10 most popular artists in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3300 / 3390\n",
      "3390 / 3390\n"
     ]
    }
   ],
   "source": [
    "rps_sagh = []\n",
    "hitrates_sagh = {top: [] for top in TOPs}\n",
    "aucs_sagh = []\n",
    "novelties_sagh = {top: dict() for top in TOPs}\n",
    "ptops_sagh = []\n",
    "# artist_diversities_sagh = {top: [] for top in TOPs}\n",
    "# genre_diversities_sagh = {top: [] for top in TOPs}\n",
    "np.random.seed(0)\n",
    "\n",
    "top10_artists = sorted(artist2pop, key=lambda aid: artist2pop[aid])[-10:]\n",
    "candidates = []\n",
    "for aix in top10_artists:\n",
    "    candidates += artist2songs[aix]\n",
    "candidates = sorted(set(candidates))\n",
    "\n",
    "assert len(candidates) > 0\n",
    "y_pred = np.zeros(Y_test.shape[0])\n",
    "for sid in candidates:\n",
    "    ix = song2index[sid]\n",
    "    y_pred[ix] = np.log(song2pop_train[sid])\n",
    "\n",
    "y_pred_prob = softmax(y_pred)\n",
    "spread_sagh = -np.dot(y_pred_prob, np.log(y_pred_prob))\n",
    "sortix = np.argsort(-y_pred)\n",
    "    \n",
    "assert Y_test.shape[1] == len(test_playlists)\n",
    "for j in range(Y_test.shape[1]):\n",
    "    if (j+1) % 100 == 0:\n",
    "        sys.stdout.write('\\r%d / %d' % (j+1, Y_test.shape[1]))\n",
    "        sys.stdout.flush()\n",
    "    y_true = Y_test[:, j].A.reshape(-1)\n",
    "    \n",
    "    # rp, hr_dict = calc_RPrecision_HitRate(y_true, y_pred, tops=TOPs)\n",
    "    rp, hr_dict, auc = calc_metrics(y_true, y_pred, tops=TOPs)\n",
    "    rps_sagh.append(rp)\n",
    "    for top in TOPs:\n",
    "        hitrates_sagh[top].append(hr_dict[top])\n",
    "    aucs_sagh.append(auc)\n",
    "    \n",
    "    # novelty\n",
    "    u = test_playlists[j][1]\n",
    "    for top in TOPs:\n",
    "        nov = np.mean([-np.log2(song2pop[index2song[ix]]) for ix in sortix[:top]])\n",
    "        try:\n",
    "            novelties_sagh[top][u].append(nov)\n",
    "        except KeyError:\n",
    "            novelties_sagh[top][u] = [nov]\n",
    "            \n",
    "    # PTop: (#pos ranked above the top-ranked negative) / #pos\n",
    "    assert y_true.dtype == np.bool\n",
    "    npos = y_true.sum()\n",
    "    assert npos > 0\n",
    "    negIx = (1 - y_true).astype(np.bool)\n",
    "    negMax = y_pred[negIx].max()\n",
    "    pt = (y_pred[y_true] > negMax).sum() / npos\n",
    "    ptops_sagh.append(pt)\n",
    "    \n",
    "    # artist/genre diversity\n",
    "#     for top in TOPs:\n",
    "#         artist_vec = np.array([song2artist[index2song[ix]] if index2song[ix] in song2artist\n",
    "#                                else str(np.random.rand()) for ix in sortix[:top]])\n",
    "#         genre_vec = np.array([song2genre[index2song[ix]] if index2song[ix] in song2genre \\\n",
    "#                               else str(np.random.rand()) for ix in sortix[:top]])\n",
    "#         artist_diversities_sagh[top].append( diversity(artist_vec) )\n",
    "#         genre_diversities_sagh[top].append( diversity(genre_vec) )\n",
    "    \n",
    "print('\\n%d / %d' % (len(rps_sagh), Y_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=[20, 5])\n",
    "# ax1 = plt.subplot(131)\n",
    "# ax1.hist(rps_sagh, bins=100)\n",
    "# ax1.set_yscale('log')\n",
    "# ax1.set_title('R-Precision')\n",
    "# #ax.set_xlim(0, xmax)\n",
    "# ax2 = plt.subplot(132)\n",
    "# ax2.hist(aucs_sagh, bins=100)\n",
    "# ax2.set_yscale('log')\n",
    "# ax2.set_title('AUC')\n",
    "# pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R-Precision': 0.019539033099329386,\n",
       " 'Hit-Rate': {5: 0.009864948733442841,\n",
       "  10: 0.01668802746277457,\n",
       "  20: 0.02976315121789779,\n",
       "  30: 0.03921742056223373,\n",
       "  50: 0.05305102710593436,\n",
       "  100: 0.07251453629786718,\n",
       "  200: 0.0884805814287678,\n",
       "  300: 0.09574546708482436,\n",
       "  500: 0.09983024902262343,\n",
       "  700: 0.10270036029225334,\n",
       "  1000: 0.10759298806789613},\n",
       " 'AUC': 0.5447781428478882,\n",
       " 'Spread': 9.989773075426719,\n",
       " 'Novelty': {5: -8.256290364105753,\n",
       "  10: -8.114134680205186,\n",
       "  20: -7.913046125788259,\n",
       "  30: -7.7371587493803995,\n",
       "  50: -7.461509911161343,\n",
       "  100: -6.818909383162228,\n",
       "  200: -5.9392965490504945,\n",
       "  300: -5.311220097723328,\n",
       "  500: -4.117784135346873,\n",
       "  700: -3.2903991301560995,\n",
       "  1000: -2.6907111730674433},\n",
       " 'PTop': 0.0026354035723412904}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagh = {dataset_name: {'Test': {'R-Precision': np.mean(rps_sagh), \n",
    "                                'Hit-Rate': {top: np.mean(hitrates_sagh[top]) for top in TOPs},\n",
    "                                'AUC': np.mean(aucs_sagh),\n",
    "                                'Spread': spread_sagh,\n",
    "                                'Novelty': {t: np.mean([np.mean(novelties_sagh[t][u]) \n",
    "                                                        for u in novelties_sagh[t]]) for t in TOPs},\n",
    "                                'PTop': np.mean(ptops_sagh),\n",
    "                                # 'Artist-Diversity': {t: np.mean(artist_diversities_sagh[t]) for t in TOPs},\n",
    "                                # 'Genre-Diversity': {t: np.mean(genre_diversities_sagh[t]) for t in TOPs}},\n",
    "                               },\n",
    "                       'Test_All': {'R-Precision': rps_sagh, \n",
    "                                    'Hit-Rate': {top: hitrates_sagh[top] for top in TOPs},\n",
    "                                    'AUC': aucs_sagh,\n",
    "                                    'Spread': spread_sagh,\n",
    "                                    'Novelty': novelties_sagh,\n",
    "                                    'PTop': ptops_sagh,\n",
    "                                    # 'Artist-Diversity': artist_diversities_sagh,\n",
    "                                    # 'Genre-Diversity': genre_diversities_sagh}}}\n",
    "                                   }}}\n",
    "sagh[dataset_name]['Test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/30music/coldstart/setting4/perf-sagh.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'R-Precision': 0.019539033099329386,\n",
       " 'Hit-Rate': {5: 0.009864948733442841,\n",
       "  10: 0.01668802746277457,\n",
       "  20: 0.02976315121789779,\n",
       "  30: 0.03921742056223373,\n",
       "  50: 0.05305102710593436,\n",
       "  100: 0.07251453629786718,\n",
       "  200: 0.0884805814287678,\n",
       "  300: 0.09574546708482436,\n",
       "  500: 0.09983024902262343,\n",
       "  700: 0.10270036029225334,\n",
       "  1000: 0.10759298806789613},\n",
       " 'AUC': 0.5447781428478882,\n",
       " 'Spread': 9.989773075426719,\n",
       " 'Novelty': {5: -8.256290364105753,\n",
       "  10: -8.114134680205186,\n",
       "  20: -7.913046125788259,\n",
       "  30: -7.7371587493803995,\n",
       "  50: -7.461509911161343,\n",
       "  100: -6.818909383162228,\n",
       "  200: -5.9392965490504945,\n",
       "  300: -5.311220097723328,\n",
       "  500: -4.117784135346873,\n",
       "  700: -3.2903991301560995,\n",
       "  1000: -2.6907111730674433},\n",
       " 'PTop': 0.0026354035723412904}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fperf_sagh = os.path.join(data_dir, 'perf-sagh.pkl')\n",
    "print(fperf_sagh)\n",
    "pkl.dump(sagh, open(fperf_sagh, 'wb'))\n",
    "pkl.load(open(fperf_sagh, 'rb'))[dataset_name]['Test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity based recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3300 / 3390\n",
      "3390 / 3390\n"
     ]
    }
   ],
   "source": [
    "rps_pop = []\n",
    "hitrates_pop = {top: [] for top in TOPs}\n",
    "aucs_pop = []\n",
    "novelties_pop = {top: dict() for top in TOPs}\n",
    "ptops_pop = []\n",
    "# artist_diversities_pop = {top: [] for top in TOPs}\n",
    "# genre_diversities_pop = {top: [] for top in TOPs}\n",
    "np.random.seed(0)\n",
    "\n",
    "y_pred = np.array([song2pop_train[index2song[ix]] for ix in range(len(all_songs))])\n",
    "y_pred_prob = softmax(np.log(y_pred))\n",
    "spread_pop = -np.dot(y_pred_prob, np.log(y_pred_prob))\n",
    "sortix = np.argsort(-y_pred)\n",
    "\n",
    "assert Y_test.shape[1] == len(test_playlists)\n",
    "for j in range(Y_test.shape[1]):\n",
    "    if (j+1) % 100 == 0:\n",
    "        sys.stdout.write('\\r%d / %d' % (j+1, Y_test.shape[1]))\n",
    "        sys.stdout.flush()\n",
    "    y_true = Y_test[:, j].A.reshape(-1)\n",
    "    \n",
    "    # rp, hr_dict = calc_RPrecision_HitRate(y_true, y_pred, tops=TOPs)\n",
    "    rp, hr_dict, auc = calc_metrics(y_true, y_pred, tops=TOPs)\n",
    "    rps_pop.append(rp)\n",
    "    for top in TOPs:\n",
    "        hitrates_pop[top].append(hr_dict[top])\n",
    "    aucs_pop.append(auc)\n",
    "    \n",
    "    # novelty\n",
    "    u = test_playlists[j][1]\n",
    "    for top in TOPs:\n",
    "        nov = np.mean([-np.log2(song2pop[index2song[ix]]) for ix in sortix[:top]])\n",
    "        try:\n",
    "            novelties_pop[top][u].append(nov)\n",
    "        except KeyError:\n",
    "            novelties_pop[top][u] = [nov]\n",
    "            \n",
    "    # PTop: (#pos ranked above the top-ranked negative) / #pos\n",
    "    assert y_true.dtype == np.bool\n",
    "    npos = y_true.sum()\n",
    "    assert npos > 0\n",
    "    negIx = (1 - y_true).astype(np.bool)\n",
    "    negMax = y_pred[negIx].max()\n",
    "    pt = (y_pred[y_true] > negMax).sum() / npos\n",
    "    ptops_pop.append(pt)\n",
    "\n",
    "    # artist/genre diversity\n",
    "#     for top in TOPs:\n",
    "#         artist_vec = np.array([song2artist[index2song[ix]] if index2song[ix] in song2artist\n",
    "#                                else str(np.random.rand()) for ix in sortix[:top]])\n",
    "#         genre_vec = np.array([song2genre[index2song[ix]] if index2song[ix] in song2genre \\\n",
    "#                               else str(np.random.rand()) for ix in sortix[:top]])\n",
    "#         artist_diversities_pop[top].append( diversity(artist_vec) )\n",
    "#         genre_diversities_pop[top].append( diversity(genre_vec) )\n",
    "    \n",
    "print('\\n%d / %d' % (len(rps_pop), Y_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=[20, 5])\n",
    "# ax1 = plt.subplot(131)\n",
    "# ax1.hist(rps_pop, bins=100)\n",
    "# ax1.set_yscale('log')\n",
    "# ax1.set_title('R-Precision')\n",
    "# #ax.set_xlim(0, xmax)\n",
    "# ax2 = plt.subplot(132)\n",
    "# ax2.hist(aucs_pop, bins=100)\n",
    "# ax2.set_yscale('log')\n",
    "# ax2.set_title('AUC')\n",
    "# pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R-Precision': 0.021428444265297445,\n",
       " 'Hit-Rate': {5: 0.009421412623139338,\n",
       "  10: 0.017693135842819865,\n",
       "  20: 0.030350363239373485,\n",
       "  30: 0.04236770309796627,\n",
       "  50: 0.064210044410304,\n",
       "  100: 0.1100898554000556,\n",
       "  200: 0.16657225455059269,\n",
       "  300: 0.21514997232353228,\n",
       "  500: 0.2845075060090967,\n",
       "  700: 0.33773431633772094,\n",
       "  1000: 0.4002239301097651},\n",
       " 'AUC': 0.8834105138312494,\n",
       " 'Spread': 9.817103399959294,\n",
       " 'Novelty': {5: -8.407434890467627,\n",
       "  10: -8.259177501291077,\n",
       "  20: -8.10651878102958,\n",
       "  30: -8.005456564280452,\n",
       "  50: -7.859830806890705,\n",
       "  100: -7.602573864055904,\n",
       "  200: -7.2744726606667305,\n",
       "  300: -7.047383583766598,\n",
       "  500: -6.721057334888038,\n",
       "  700: -6.492052658348255,\n",
       "  1000: -6.223838708538693},\n",
       " 'PTop': 0.0023206785804504356}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_perf = {dataset_name: {'Test': {'R-Precision': np.mean(rps_pop), \n",
    "                                    'Hit-Rate': {top: np.mean(hitrates_pop[top]) for top in TOPs},\n",
    "                                    'AUC': np.mean(aucs_pop),\n",
    "                                    'Spread': spread_pop,\n",
    "                                    'Novelty': {t: np.mean([np.mean(novelties_pop[t][u]) for u in novelties_pop[t]]) \n",
    "                                                for t in TOPs},\n",
    "                                    'PTop': np.mean(ptops_pop),\n",
    "                                    #'Artist-Diversity': {top: np.mean(artist_diversities_pop[top]) for top in TOPs},\n",
    "                                    #'Genre-Diversity': {top: np.mean(genre_diversities_pop[top]) for top in TOPs}},\n",
    "                                   },\n",
    "                           'Test_All': {'R-Precision': rps_pop, \n",
    "                                        'Hit-Rate': {top: hitrates_pop[top] for top in TOPs},\n",
    "                                        'AUC': aucs_pop,\n",
    "                                        'Spread': spread_pop,\n",
    "                                        'Novelty': novelties_pop,\n",
    "                                        'PTop': ptops_pop,\n",
    "                                        # 'Artist-Diversity': artist_diversities_pop,\n",
    "                                        # 'Genre-Diversity': genre_diversities_pop}}}\n",
    "                                       }}}\n",
    "pop_perf[dataset_name]['Test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/30music/coldstart/setting4/perf-pop.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'R-Precision': 0.021428444265297445,\n",
       " 'Hit-Rate': {5: 0.009421412623139338,\n",
       "  10: 0.017693135842819865,\n",
       "  20: 0.030350363239373485,\n",
       "  30: 0.04236770309796627,\n",
       "  50: 0.064210044410304,\n",
       "  100: 0.1100898554000556,\n",
       "  200: 0.16657225455059269,\n",
       "  300: 0.21514997232353228,\n",
       "  500: 0.2845075060090967,\n",
       "  700: 0.33773431633772094,\n",
       "  1000: 0.4002239301097651},\n",
       " 'AUC': 0.8834105138312494,\n",
       " 'Spread': 9.817103399959294,\n",
       " 'Novelty': {5: -8.407434890467627,\n",
       "  10: -8.259177501291077,\n",
       "  20: -8.10651878102958,\n",
       "  30: -8.005456564280452,\n",
       "  50: -7.859830806890705,\n",
       "  100: -7.602573864055904,\n",
       "  200: -7.2744726606667305,\n",
       "  300: -7.047383583766598,\n",
       "  500: -6.721057334888038,\n",
       "  700: -6.492052658348255,\n",
       "  1000: -6.223838708538693},\n",
       " 'PTop': 0.0023206785804504356}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fperf_pop = os.path.join(data_dir, 'perf-pop.pkl')\n",
    "print(fperf_pop)\n",
    "pkl.dump(pop_perf, open(fperf_pop, 'wb'))\n",
    "pkl.load(open(fperf_pop, 'rb'))[dataset_name]['Test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $S \\in \\mathbb{R}^{M \\times D}, V \\in \\mathbb{R}^{U \\times D}$ be the latent factors of songs and users (in training set), respectively.\n",
    "Let $R \\in \\mathbb{R}^{M \\times U}$ be the play-count of songs for users (in training set), and $T = \\mathbf{1}(R > 0) \\in \\{0,1\\}^{M \\times U}$ be a binary matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimisation objective:\n",
    "$\n",
    "\\begin{aligned}\n",
    "J = \\sum_{m=1}^M \\sum_{u=1}^U q_{m, u}\n",
    "    \\left( t_{m,u} - \\mathbf{s}_m^\\top \\mathbf{v}_u \\right)^2\n",
    "    + C \\left( \\sum_{m=1}^M \\mathbf{s}_m^\\top \\mathbf{s}_m + \\sum_{u=1}^U \\mathbf{v}_n^\\top \\mathbf{v}_n \\right)\n",
    "\\end{aligned} \n",
    "$  \n",
    "where $\\alpha, \\epsilon$ are hyper-parameters, and $q_{m, u} = 1 + \\alpha \\log(1 + \\epsilon^{-1} r_{m,u})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use alternating least squares optimisation method:\n",
    "\n",
    "1. Fix $S$, then let\n",
    "$\n",
    "\\begin{aligned}\n",
    "\\mathbf{0}\n",
    "= \\frac{\\partial J}{\\partial \\mathbf{v}_u}\n",
    "= \\sum_{m=1}^M 2 q_{m,u} \\left( t_{m,u} - \\mathbf{s}_m^\\top \\mathbf{v}_u \\right) (-\\mathbf{s}_m) + 2 C \\mathbf{v}_u\n",
    "\\end{aligned}\n",
    "$  \n",
    "in other words\n",
    "$\n",
    "\\begin{aligned}\n",
    "\\sum_{m=1}^M q_{m,u} t_{m,u} \\mathbf{s}_m \n",
    "= \\sum_{m=1}^M q_{m,u} (\\mathbf{s}_m^\\top \\mathbf{v}_u^*) \\mathbf{s}_m + C \\mathbf{v}_u^*\n",
    "= \\sum_{m=1}^M q_{m,u} \\mathbf{s}_m \\mathbf{s}_m^\\top \\mathbf{v}_u^* + C \\mathbf{v}_u^*\n",
    "= \\left( \\sum_{m=1}^M q_{m,u} \\mathbf{s}_m \\mathbf{s}_m^\\top + C \\mathbf{I} \\right) \\mathbf{v}_u^*\n",
    "\\end{aligned}\n",
    "$  \n",
    "where $\\mathbf{I} \\in \\mathbb{R}^{D \\times D}$ is the identity matrix.  \n",
    "So \n",
    "$\n",
    "\\begin{aligned}\n",
    "\\mathbf{v}_u^* = \\left( \\sum_{m=1}^M q_{m,u} \\mathbf{s}_m \\mathbf{s}_m^\\top + C \\mathbf{I} \\right)^{-1} \\sum_{m=1}^M q_{m,u} t_{m,u} \\mathbf{s}_m \n",
    "\\end{aligned}\n",
    "$  \n",
    "or equivalently\n",
    "$\n",
    "\\begin{aligned}\n",
    "\\mathbf{v}_u^* \n",
    "= \\left( (\\mathbf{q}_{:,u}[..., \\text{np.newaxis}] \\times S)^\\top S + C \\mathbf{I} \\right)^{-1} \\left( (\\mathbf{q}_{:u} \\circ \\mathbf{t}_{:,u})^\\top S \\right)^\\top\n",
    "\\end{aligned}\n",
    "$  \n",
    "where np.newaxis is for numpy broadcasting and $\\circ$ is entrywise product of vector/matrix.  \n",
    "*It seems we have to use 3-dimension tensor (U by M by D) if we want to compute all values at once, this could be impractical due to memory usage.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Fix $V$, then let\n",
    "$\n",
    "\\begin{aligned}\n",
    "\\mathbf{0}\n",
    "= \\frac{\\partial J}{\\partial \\mathbf{s}_m}\n",
    "= \\sum_{u=1}^U 2 q_{m,u} \\left( t_{m,u} - \\mathbf{s}_m^\\top \\mathbf{v}_u \\right) (-\\mathbf{v}_u) + 2 C \\mathbf{s}_m\n",
    "\\end{aligned}\n",
    "$  \n",
    "by symmetry, we have  \n",
    "$\n",
    "\\begin{aligned}\n",
    "\\mathbf{s}_m^* \n",
    "= \\left( (\\mathbf{q}_{m:}[\\text{np.newaxis}, ...] \\times V)^\\top V + C \\mathbf{I} \\right)^{-1} \\left( (\\mathbf{q}_{m:} \\circ \\mathbf{t}_{m,:})^\\top V \\right)^\\top\n",
    "\\end{aligned}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert dataset_name == '30music'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5649\n"
     ]
    }
   ],
   "source": [
    "train_users = sorted({u for _, u in train_playlists})\n",
    "train_user2index = {u: uix for uix, u in enumerate(train_users)}\n",
    "print(len(train_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14067it [00:10, 1337.61it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(45468, 5649)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = X.shape[0]\n",
    "U = len(train_users)\n",
    "\n",
    "R = np.zeros((M, U))\n",
    "for pix, (_, u) in tqdm(enumerate(train_playlists)):\n",
    "    R[:, train_user2index[u]] += Y_train[:, pix].A.reshape(-1)\n",
    "R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45468, 5649)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = (R > 0).astype(np.float32)\n",
    "T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.cuda.is_available()\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/u5708856/apps/miniconda3/lib/python3.6/site-packages/torch/cuda/__init__.py:116: UserWarning: \n",
      "    Found GPU1 Quadro K600 which is of cuda capability 3.0.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\n"
     ]
    }
   ],
   "source": [
    "D = 100\n",
    "C = 1e-5\n",
    "alpha = 40\n",
    "eps = 1e-8\n",
    "\n",
    "torch.manual_seed(0)\n",
    "S = torch.rand(M, D).to(device)\n",
    "V = torch.rand(U, D).to(device)\n",
    "\n",
    "Q = 1 + alpha * (np.log(1 / eps) + np.log(eps + R))  # M by U, dense\n",
    "QT = np.multiply(Q, T).astype(np.float32)  # M by U\n",
    "QT_csc = csc_matrix(QT)\n",
    "QT_csr = csr_matrix(QT)\n",
    "Q = torch.from_numpy(Q.astype(np.float32)).to(device)\n",
    "del QT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600 / 5649\n",
      "45400 / 45468\n",
      "V diff: 436.278195, S diff: 1024.695076 in 205.5 seconds.\n",
      "5600 / 5649\n",
      "45400 / 45468\n",
      "V diff: 23.487190, S diff: 145.043530 in 203.1 seconds.\n",
      "5600 / 5649\n",
      "45400 / 45468\n",
      "V diff: 13.216787, S diff: 91.205938 in 203.1 seconds.\n",
      "5600 / 5649\n",
      "45400 / 45468\n",
      "V diff: 9.241411, S diff: 68.507168 in 203.7 seconds.\n",
      "5600 / 5649\n",
      "45400 / 45468\n",
      "V diff: 7.128352, S diff: 52.597159 in 204.5 seconds.\n",
      "5600 / 5649\n",
      "45400 / 45468\n",
      "V diff: 5.802107, S diff: 42.214396 in 203.1 seconds.\n",
      "5600 / 5649\n",
      "45400 / 45468\n",
      "V diff: 4.884201, S diff: 35.203325 in 202.9 seconds.\n",
      "5600 / 5649\n",
      "45400 / 45468\n",
      "V diff: 4.209020, S diff: 30.180051 in 206.9 seconds.\n",
      "5600 / 5649\n",
      "45400 / 45468\n",
      "V diff: 3.691421, S diff: 26.396446 in 204.7 seconds.\n",
      "5600 / 5649\n",
      "45400 / 45468\n",
      "V diff: 3.282319, S diff: 23.429591 in 203.5 seconds.\n",
      "5600 / 5649\n",
      "45400 / 45468\n",
      "V diff: 2.951144, S diff: 21.033568 in 204.0 seconds.\n",
      "5600 / 5649\n",
      "45400 / 45468\n",
      "V diff: 2.677741, S diff: 19.054410 in 207.8 seconds.\n",
      "5600 / 5649\n",
      "45400 / 45468\n",
      "V diff: 2.448329, S diff: 17.389146 in 215.6 seconds.\n",
      "5600 / 5649\n",
      "45400 / 45468\n",
      "V diff: 2.253175, S diff: 15.970046 in 229.2 seconds.\n",
      "5600 / 5649\n",
      "45400 / 45468\n",
      "V diff: 2.085247, S diff: 14.746630 in 229.7 seconds.\n",
      "5600 / 5649\n",
      "45400 / 45468\n",
      "V diff: 1.939347, S diff: 13.682306 in 230.5 seconds.\n",
      "5600 / 5649\n",
      "45400 / 45468\n",
      "V diff: 1.811542, S diff: 12.749323 in 229.2 seconds.\n",
      "5600 / 5649\n",
      "45400 / 45468\n",
      "V diff: 1.698779, S diff: 11.925980 in 223.1 seconds.\n",
      "5600 / 5649\n",
      "45400 / 45468\n",
      "V diff: 1.598667, S diff: 11.195439 in 211.4 seconds.\n",
      "5600 / 5649\n",
      "45400 / 45468\n",
      "V diff: 1.509277, S diff: 10.543625 in 289.5 seconds.\n"
     ]
    }
   ],
   "source": [
    "n_sweeps = 20\n",
    "\n",
    "# alternating least squares\n",
    "for sweep in range(n_sweeps):\n",
    "    t0 = time.time()\n",
    "    vdiff2 = 0.\n",
    "    sdiff2 = 0.\n",
    "    \n",
    "    # fix S, optimise V\n",
    "    S_cpu = S.cpu().numpy()\n",
    "    for uix in range(U):\n",
    "        if (uix + 1) % 100 == 0:\n",
    "            sys.stdout.write('\\r%d / %d' % (uix+1, U))\n",
    "            sys.stdout.flush()\n",
    "        QSu = torch.mm((Q[:, uix].reshape(M, 1) * S).t(), S)  # D by D\n",
    "        QSu[range(D), range(D)] = C + QSu.diag()\n",
    "        QTuS = torch.from_numpy(QT_csc[:, uix].transpose().dot(S_cpu).reshape(D, 1)).to(device)\n",
    "        v_u = torch.mm(torch.inverse(QSu), QTuS).reshape(-1)\n",
    "        diff = v_u - V[uix, :]\n",
    "        vdiff2 += torch.mm(diff.reshape(1, -1), diff.reshape(-1, 1)).cpu().item()\n",
    "        V[uix, :] = v_u\n",
    "\n",
    "    print()\n",
    "    \n",
    "    # fix V, optimise S\n",
    "    V_cpu = V.cpu().numpy()\n",
    "    for m in range(M):\n",
    "        if (m + 1) % 100 == 0:\n",
    "            sys.stdout.write('\\r%d / %d' % (m+1, M))\n",
    "            sys.stdout.flush()\n",
    "        QVm = torch.mm((Q[m, :].reshape(U, 1) * V).t(), V)  # D by D\n",
    "        QVm[range(D), range(D)] = C + QVm.diag()\n",
    "        QTmV = torch.from_numpy(QT_csr[m, :].dot(V_cpu).reshape(D, 1)).to(device)\n",
    "        s_m = torch.mm(torch.inverse(QVm), QTmV).reshape(-1)\n",
    "        diff = s_m - S[m, :]\n",
    "        sdiff2 += torch.mm(diff.reshape(1, -1), diff.reshape(-1, 1)).cpu().item()\n",
    "        S[m, :] = s_m\n",
    "    print('\\nV diff: {:8.6f}, S diff: {:8.6f} in {:.1f} seconds.'\n",
    "          .format(np.sqrt(vdiff2), np.sqrt(sdiff2), time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check: compute optimisation objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 3.76196e+06\n"
     ]
    }
   ],
   "source": [
    "cost = np.multiply(Q.cpu().numpy(), np.square(T - torch.mm(S, V.t()).cpu().numpy())).sum() \\\n",
    "       + C * (torch.mul(S, S).sum().cpu().item() + torch.mul(V, V).sum().cpu().item())\n",
    "del T\n",
    "print('Cost: %g' % cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User attributes in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>#Playlists</th>\n",
       "      <th>Age</th>\n",
       "      <th>Country</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Playcount</th>\n",
       "      <th>Subscribertype</th>\n",
       "      <th>Username</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1116715959</td>\n",
       "      <td>2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>US</td>\n",
       "      <td>F</td>\n",
       "      <td>221012</td>\n",
       "      <td>base</td>\n",
       "      <td>000123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1163123792</td>\n",
       "      <td>9</td>\n",
       "      <td>39.0</td>\n",
       "      <td>CZ</td>\n",
       "      <td>M</td>\n",
       "      <td>217535</td>\n",
       "      <td>base</td>\n",
       "      <td>000333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1184426573</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>49733</td>\n",
       "      <td>base</td>\n",
       "      <td>00elen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1123157597</td>\n",
       "      <td>2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>DE</td>\n",
       "      <td>M</td>\n",
       "      <td>168054</td>\n",
       "      <td>base</td>\n",
       "      <td>00Eraser00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1171302116</td>\n",
       "      <td>2</td>\n",
       "      <td>23.0</td>\n",
       "      <td>UK</td>\n",
       "      <td>M</td>\n",
       "      <td>45700</td>\n",
       "      <td>base</td>\n",
       "      <td>00fieldsy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Timestamp  #Playlists   Age Country Gender  Playcount Subscribertype  \\\n",
       "ID                                                                          \n",
       "1   1116715959           2  24.0      US      F     221012           base   \n",
       "2   1163123792           9  39.0      CZ      M     217535           base   \n",
       "3   1184426573           2   NaN     NaN      F      49733           base   \n",
       "4   1123157597           2  32.0      DE      M     168054           base   \n",
       "5   1171302116           2  23.0      UK      M      45700           base   \n",
       "\n",
       "      Username  \n",
       "ID              \n",
       "1       000123  \n",
       "2       000333  \n",
       "3       00elen  \n",
       "4   00Eraser00  \n",
       "5    00fieldsy  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_users = pd.read_csv('data/30music/users.csv', index_col='ID', sep=';')\n",
    "all_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5649, 8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_users_df = all_users.loc[train_users]\n",
    "train_users_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_set = set(train_users_df['Country'])\n",
    "# country_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_set.remove(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = sorted(country_set)\n",
    "country2index = {c: ix for ix, c in enumerate(countries)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_set = set(train_users_df['Gender'])\n",
    "# gender_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_set.remove(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "genders = sorted(gender_set)\n",
    "gender2index = {g: ix for ix, g in enumerate(genders)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subscriber type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscribe_set = set(train_users_df['Subscribertype'])\n",
    "# subscribe_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscribes = sorted(subscribe_set)\n",
    "subscribe2index = {s: ix for ix, s in enumerate(subscribes)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features: `Age, Country, Gender, Subscribertype`\n",
    "where we\n",
    "- normalise `Age`\n",
    "- use one-hot encoding of `Country`, `Gender` and `Subscribertype`\n",
    "- use 0 imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `#Playlists`\n",
    "#num_playlists = np.log10(train_users_df['#Playlists'])\n",
    "#num_playlists_mean = np.mean(num_playlists)\n",
    "#num_playlists_std = np.std(num_playlists)\n",
    "#num_playlists = (num_playlists - num_playlists_mean) / num_playlists_std\n",
    "\n",
    "# Age\n",
    "ages = np.array([0 if np.isnan(x) or x < 1 else x for x in train_users_df['Age']])\n",
    "ages_mean = np.mean(ages)\n",
    "ages_std = np.std(ages)\n",
    "ages = (ages - ages_mean) / ages_std\n",
    "\n",
    "# Country\n",
    "country_mat = np.zeros((len(train_users), len(countries)))\n",
    "for uix, u in enumerate(train_users):\n",
    "    c = train_users_df.loc[u, 'Country']\n",
    "    if c in country2index:\n",
    "        cix = country2index[c]\n",
    "        country_mat[uix, cix] = 1\n",
    "\n",
    "# Gender\n",
    "gender_mat = np.zeros((len(train_users), len(genders)))\n",
    "for uix, u in enumerate(train_users):\n",
    "    g = train_users_df.loc[u, 'Gender']\n",
    "    if g in gender2index:\n",
    "        gix = gender2index[g]\n",
    "        gender_mat[uix, gix] = 1\n",
    "    \n",
    "# Playcount\n",
    "#playcounts = np.array([0 if np.isnan(x) or x < 1 else np.log10(x) for x in train_users_df['Playcount']])\n",
    "#playcounts_mean = np.mean(playcounts)\n",
    "#playcounts_std = np.std(playcounts)\n",
    "#playcounts = (playcounts - playcounts_mean) / playcounts_std\n",
    "\n",
    "# Subscribertype\n",
    "subscribe_mat = np.zeros((len(train_users), len(subscribes)))\n",
    "for uix, u in enumerate(train_users):\n",
    "    s = train_users_df.loc[u, 'Subscribertype']\n",
    "    six = subscribe2index[s]\n",
    "    subscribe_mat[uix, six] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5649, 129)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features = np.hstack([ages.reshape(-1, 1), country_mat, gender_mat, subscribe_mat])\n",
    "user_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User attributes in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_users = {u for _, u in test_playlists}\n",
    "test_users = sorted(test_users - (test_users - set(all_users.index)))\n",
    "test_user2index = {u: uix for uix, u in enumerate(test_users)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(test_users) - set(all_users.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2420, 8)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_users_df = all_users.loc[test_users]\n",
    "test_users_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `#Playlists`\n",
    "#num_playlists_test = np.log10(test_users_df['#Playlists'])\n",
    "#num_playlists_test = (num_playlists_test - num_playlists_mean) / num_playlists_std\n",
    "\n",
    "# Age\n",
    "ages_test = np.array([0 if np.isnan(x) or x < 1 else x for x in test_users_df['Age']])\n",
    "ages_test = (ages_test - ages_mean) / ages_std\n",
    "\n",
    "# Country\n",
    "country_mat_test = np.zeros((len(test_users), len(countries)))\n",
    "for uix, u in enumerate(test_users):\n",
    "    c = test_users_df.loc[u, 'Country']\n",
    "    if c in country2index:\n",
    "        cix = country2index[c]\n",
    "        country_mat_test[uix, cix] = 1\n",
    "\n",
    "# Gender\n",
    "gender_mat_test = np.zeros((len(test_users), len(genders)))\n",
    "for uix, u in enumerate(test_users):\n",
    "    g = test_users_df.loc[u, 'Gender']\n",
    "    if g in gender2index:\n",
    "        gix = gender2index[g]\n",
    "        gender_mat_test[uix, gix] = 1\n",
    "    \n",
    "# Playcount\n",
    "#playcounts_test = np.array([0 if np.isnan(x) or x < 1 else np.log10(x) for x in test_users_df['Playcount']])\n",
    "#playcounts_test = (playcounts_test - playcounts_mean) / playcounts_std\n",
    "\n",
    "# Subscribertype\n",
    "subscribe_mat_test = np.zeros((len(test_users), len(subscribes)))\n",
    "for uix, u in enumerate(test_users):\n",
    "    s = test_users_df.loc[u, 'Subscribertype']\n",
    "    six = subscribe2index[s]\n",
    "    subscribe_mat_test[uix, six] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2420, 129)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features_test = np.hstack([ages_test.reshape(-1, 1), country_mat_test, gender_mat_test, subscribe_mat_test])\n",
    "user_features_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine similarity between test user features and train user features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2420, 5649)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_prod = np.dot(user_features_test, user_features.T)\n",
    "dot_prod.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2420, 5649)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_train = np.multiply(user_features, user_features).sum(axis=1).reshape(-1, 1)\n",
    "norm_test = np.multiply(user_features_test, user_features_test).sum(axis=1).reshape(-1, 1)\n",
    "norm_mat = np.dot(norm_test, norm_train.T)\n",
    "norm_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13670580 =? 13670580\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(norm_mat.ravel() > 0), '=?', np.prod(norm_mat.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarities = np.divide(dot_prod, norm_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump([train_user2index, test_user2index, cosine_similarities], gzip.open('%s/user_sim.pkl.gz' % data_dir, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the average factor of 100 nearest neighbours for a test user "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3300 / 3390\n",
      "3389 / 3390\n"
     ]
    }
   ],
   "source": [
    "k = 200\n",
    "rps_mf = []\n",
    "hitrates_mf = {top: [] for top in TOPs}\n",
    "aucs_mf = []\n",
    "spreads_mf = []\n",
    "novelties_mf = {top: dict() for top in TOPs}\n",
    "ptops_mf = []\n",
    "# artist_diversities_mf = {top: [] for top in TOPs}\n",
    "# genre_diversities_mf = {top: [] for top in TOPs}\n",
    "np.random.seed(0)\n",
    "npos = Y_test.sum(axis=0).A.reshape(-1)\n",
    "for j in range(Y_test.shape[1]):\n",
    "    if (j+1) % 100 == 0:\n",
    "        sys.stdout.write('\\r%d / %d' % (j+1, Y_test.shape[1]))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    assert npos[j] > 0\n",
    "    y_true = Y_test[:, j].A.reshape(-1)\n",
    "    \n",
    "    u = test_playlists[j][1]\n",
    "    if u not in test_users:\n",
    "        continue\n",
    "    \n",
    "    # average factor of 10 nearest neighbours\n",
    "    uix = test_user2index[u]\n",
    "    factor_ix = np.argpartition(cosine_similarities[uix, :].reshape(-1), -k)[-k:]\n",
    "    y_pred = torch.mm(S, V[factor_ix, :].mean(dim=0).reshape(D, 1)).reshape(-1).cpu().numpy()\n",
    "\n",
    "    rp, hr_dict, auc = calc_metrics(y_true, y_pred, tops=TOPs)\n",
    "    rps_mf.append(rp)\n",
    "    for top in TOPs:\n",
    "        hitrates_mf[top].append(hr_dict[top])\n",
    "    # auc = roc_auc_score(y_true, y_pred)\n",
    "    aucs_mf.append(auc)\n",
    "    \n",
    "    # spread\n",
    "    y_pred_prob = softmax(y_pred)\n",
    "    spreads_mf.append(-np.dot(y_pred_prob, np.log(y_pred_prob)))\n",
    "\n",
    "    # novelty\n",
    "    sortix = np.argsort(-y_pred)\n",
    "    for top in TOPs:\n",
    "        nov = np.mean([-np.log2(song2pop[index2song[ix]]) for ix in sortix[:top]])\n",
    "        try:\n",
    "            novelties_mf[top][u].append(nov)\n",
    "        except KeyError:\n",
    "            novelties_mf[top][u] = [nov]\n",
    "    \n",
    "    # PTop: (#pos ranked above the top-ranked negative) / #pos\n",
    "    assert y_true.dtype == np.bool\n",
    "    negIx = (1 - y_true).astype(np.bool)\n",
    "    negMax = y_pred[negIx].max()\n",
    "    pt = (y_pred[y_true] > negMax).sum() / npos[j]\n",
    "    ptops_mf.append(pt)\n",
    "    \n",
    "    # artist/genre diversity\n",
    "#     for top in TOPs:\n",
    "#         artist_vec = np.array([song2artist[index2song[ix]] if index2song[ix] in song2artist\n",
    "#                                else str(np.random.rand()) for ix in sortix[:top]])\n",
    "#         genre_vec = np.array([song2genre[index2song[ix]] if index2song[ix] in song2genre \\\n",
    "#                               else str(np.random.rand()) for ix in sortix[:top]])\n",
    "#         artist_diversities_mf[top].append( diversity(artist_vec) )\n",
    "#         genre_diversities_mf[top].append( diversity(genre_vec) )\n",
    "    \n",
    "print('\\n%d / %d' % (len(rps_mf), Y_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('AUC:', np.mean(aucs_mf))\n",
    "# print({top: np.mean(hitrates_mf[top]) for top in TOPs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R-Precision': 0.023643532856730952,\n",
       " 'Hit-Rate': {5: 0.011183730875065292,\n",
       "  10: 0.020073863889749695,\n",
       "  20: 0.03467224557213608,\n",
       "  30: 0.04667466656721038,\n",
       "  50: 0.06779320626913173,\n",
       "  100: 0.10818556329847187,\n",
       "  200: 0.17109838794580584,\n",
       "  300: 0.21805549618867073,\n",
       "  500: 0.28731175340501636,\n",
       "  700: 0.34238602739446583,\n",
       "  1000: 0.4050517861640513},\n",
       " 'AUC': 0.8677202254927863,\n",
       " 'Spread': 10.72455,\n",
       " 'Novelty': {5: -8.033787006566996,\n",
       "  10: -7.917739973769313,\n",
       "  20: -7.753288204961613,\n",
       "  30: -7.626889284885757,\n",
       "  50: -7.455813960637479,\n",
       "  100: -7.187429205948604,\n",
       "  200: -6.85386398170347,\n",
       "  300: -6.620386611483843,\n",
       "  500: -6.286775605109602,\n",
       "  700: -6.041158351980454,\n",
       "  1000: -5.75100264121414},\n",
       " 'PTop': 0.00317562697904186}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_mf = {dataset_name: {'Test': {'R-Precision': np.mean(rps_mf),\n",
    "                                'Hit-Rate': {top: np.mean(hitrates_mf[top]) for top in TOPs},\n",
    "                                'AUC': np.mean(aucs_mf),\n",
    "                                'Spread': np.mean(spreads_mf),\n",
    "                                'Novelty': {t: np.mean([np.mean(novelties_mf[t][u]) for u in novelties_mf[t]]) \n",
    "                                            for t in TOPs},\n",
    "                                'PTop': np.mean(ptops_mf),\n",
    "                                # 'Artist-Diversity': {top: np.mean(artist_diversities_mf[top]) for top in TOPs},\n",
    "                                # 'Genre-Diversity': {top: np.mean(genre_diversities_mf[top]) for top in TOPs}},\n",
    "                                  },\n",
    "                        'Test_All': {'R-Precision': rps_mf,\n",
    "                                    'Hit-Rate': {top: hitrates_mf[top] for top in TOPs},\n",
    "                                    'AUC': aucs_mf,\n",
    "                                    'Spread': spreads_mf,\n",
    "                                    'Novelty': novelties_mf,\n",
    "                                    'PTop': ptops_mf,\n",
    "                                    # 'Artist-Diversity': artist_diversities_mf,\n",
    "                                    # 'Genre-Diversity': genre_diversities_mf}}}\n",
    "                                    }}}\n",
    "perf_mf[dataset_name]['Test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R-Precision': 0.023643532856730952,\n",
       " 'Hit-Rate': {5: 0.011183730875065292,\n",
       "  10: 0.020073863889749695,\n",
       "  20: 0.03467224557213608,\n",
       "  30: 0.04667466656721038,\n",
       "  50: 0.06779320626913173,\n",
       "  100: 0.10818556329847187,\n",
       "  200: 0.17109838794580584,\n",
       "  300: 0.21805549618867073,\n",
       "  500: 0.28731175340501636,\n",
       "  700: 0.34238602739446583,\n",
       "  1000: 0.4050517861640513},\n",
       " 'AUC': 0.8677202254927863,\n",
       " 'Spread': 10.72455,\n",
       " 'Novelty': {5: -8.033787006566996,\n",
       "  10: -7.917739973769313,\n",
       "  20: -7.753288204961613,\n",
       "  30: -7.626889284885757,\n",
       "  50: -7.455813960637479,\n",
       "  100: -7.187429205948604,\n",
       "  200: -6.85386398170347,\n",
       "  300: -6.620386611483843,\n",
       "  500: -6.286775605109602,\n",
       "  700: -6.041158351980454,\n",
       "  1000: -5.75100264121414},\n",
       " 'PTop': 0.00317562697904186}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fperf_mf = os.path.join(data_dir, 'perf-mf.pkl')\n",
    "print(fperf_mf)\n",
    "pkl.dump(perf_mf, open(fperf_mf, 'wb'))\n",
    "pkl.load(open(fperf_mf, 'rb'))[dataset_name]['Test']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
