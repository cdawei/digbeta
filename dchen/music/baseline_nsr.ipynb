{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines - new song recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os, sys, time, gzip\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "from scipy.sparse import lil_matrix, issparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity, pairwise_distances\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tools import calc_RPrecision_HitRate\n",
    "from tools import calc_metrics, pairwise_distance_hamming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPs = [5, 10, 20, 30, 50, 100, 200, 300, 500, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['aotm2011', '30music']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aotm2011'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dix = 0\n",
    "dataset_name = datasets[dix]\n",
    "dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/%s/coldstart/setting1' % dataset_name\n",
    "Y_trndev = pkl.load(gzip.open(os.path.join(data_dir, 'Y_trndev.pkl.gz'), 'rb'))\n",
    "X_test = pkl.load(gzip.open(os.path.join(data_dir, 'X_test.pkl.gz'), 'rb'))\n",
    "Y_test = pkl.load(gzip.open(os.path.join(data_dir, 'Y_test.pkl.gz'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs1 = pkl.load(gzip.open(os.path.join(data_dir, 'songs_train_dev_test_s1.pkl.gz'), 'rb'))\n",
    "train_songs = songs1['train_song_set']\n",
    "dev_songs = songs1['dev_song_set']\n",
    "test_songs = songs1['test_song_set']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "song2index_trndev = {sid: ix for ix, (sid, _) in enumerate(train_songs + dev_songs)}\n",
    "song2index_test = {sid: ix for ix, (sid, _) in enumerate(test_songs)}\n",
    "index2song_test = {ix: sid for ix, (sid, _) in enumerate(test_songs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_song2artist = pkl.load(gzip.open('data/msd/song2artist.pkl.gz', 'rb'))\n",
    "song2artist = {sid: _song2artist[sid] for sid, _ in train_songs + dev_songs + test_songs if sid in _song2artist}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_playlists = pkl.load(gzip.open(os.path.join(data_dir, 'playlists_s1.pkl.gz'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist2pop = dict()\n",
    "test_songset = set(test_songs)\n",
    "\n",
    "for pl, _ in all_playlists:\n",
    "    for sid in [sid for sid in pl if sid not in test_songset]:\n",
    "        if sid in song2artist:\n",
    "            aid = song2artist[sid]\n",
    "            try:\n",
    "                artist2pop[aid] += 1\n",
    "            except KeyError:\n",
    "                artist2pop[aid] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cliques_all = pkl.load(gzip.open(os.path.join(data_dir, 'cliques_trndev.pkl.gz'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = len(cliques_all)\n",
    "pl2u = np.zeros(Y_test.shape[1], dtype=np.int32)\n",
    "for u in range(U):\n",
    "    clq = cliques_all[u]\n",
    "    pl2u[clq] = u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "song2pop = pkl.load(gzip.open(os.path.join(data_dir, 'song2pop.pkl.gz'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 63)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 84646)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csc.csc_matrix"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_csr = Y_test.tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `p XOR q = ( p AND NOT q )  OR  ( NOT p AND q )` from [here](https://math.stackexchange.com/questions/38473/is-xor-a-combination-of-and-and-not-operators),\n",
    "let $\\mathbf{p}, \\mathbf{q} \\in \\{0, 1\\}^{n}$, then\n",
    "  \n",
    "$\n",
    "\\begin{aligned}\n",
    "& \\text{Hamming_distance}(\\mathbf{p}, \\mathbf{q})  \\\\\n",
    "& = \\frac{1}{n} \\sum_{i=1}^n p_i \\ \\text{XOR} \\ q_i \\\\\n",
    "& = \\frac{1}{n} \\sum_{i=1}^n \\left( p_i (1 - q_i) + (1 - p_i) q_i \\right) \\\\\n",
    "& = \\frac{1}{n} \\left( \\sum_{i=1}^n p_i (1 - q_i) + \\sum_{i=1}^n (1 - p_i) q_i \\right) \\\\\n",
    "& = \\frac{1}{n} \\left( \\mathbf{p}^\\top (\\mathbf{1} - \\mathbf{q}) + (\\mathbf{1} - \\mathbf{p})^\\top \\mathbf{q} \\right) \\\\\n",
    "& = \\frac{1}{n} \\left( \\text{sum}(\\mathbf{p}) + \\text{sum}(\\mathbf{q}) - 2 \\mathbf{p}^\\top \\mathbf{q} \\right)\n",
    "\\end{aligned}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.990901080203748e-28\n",
      "4.990901080203748e-28\n"
     ]
    }
   ],
   "source": [
    "N, D = 1000, 200\n",
    "aa = np.zeros(N * D, dtype=np.int)\n",
    "idx = np.random.permutation(N * D)[:int(N * D * .3)]\n",
    "aa[idx] = 1\n",
    "aa = aa.reshape(N, D)\n",
    "d1 = pairwise_distances(aa, metric='hamming', n_jobs=2)\n",
    "d2 = (np.dot(aa, 1-aa.T) + np.dot(1-aa, aa.T)) / D\n",
    "sum_vec = aa.sum(axis=1, keepdims=True)\n",
    "d3 = (sum_vec + sum_vec.T - 2 * np.dot(aa, aa.T)) / D\n",
    "diff = (d1 - d2).ravel()\n",
    "print(np.dot(diff, diff))\n",
    "diff2 = (d1 - d3).ravel()\n",
    "print(np.dot(diff2, diff2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "aa = Y_test_csr[500, :]\n",
    "d1 = pairwise_distances(aa.A, metric='hamming', n_jobs=2)\n",
    "d2 = pairwise_distance_hamming(aa)\n",
    "diff = (d1 - d2).ravel()\n",
    "print(np.sqrt(np.dot(diff, diff)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity (of artist) based recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84600 / 84646\n",
      "19504 / 84646\n"
     ]
    }
   ],
   "source": [
    "rps_pop = []\n",
    "hitrates_pop = {top: [] for top in TOPs}\n",
    "aucs_pop = []\n",
    "novelty_pop = dict()\n",
    "diversities_pop = []\n",
    "\n",
    "y_pred = np.zeros(len(test_songs))\n",
    "for ix in range(len(test_songs)):\n",
    "    sid = index2song_test[ix]\n",
    "    if sid in song2artist:\n",
    "        aid = song2artist[sid]\n",
    "        if aid in artist2pop:\n",
    "            y_pred[ix] = artist2pop[aid]\n",
    "\n",
    "npos = Y_test.sum(axis=0).A.reshape(-1)\n",
    "assert Y_test.shape[0] == len(test_songs)\n",
    "for j in range(Y_test.shape[1]):\n",
    "    if (j+1) % 100 == 0:\n",
    "        sys.stdout.write('\\r%d / %d' % (j+1, Y_test.shape[1]))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    if npos[j] < 1:\n",
    "        continue\n",
    "        \n",
    "    y_true = Y_test[:, j].A.reshape(-1)\n",
    "\n",
    "    # rp, hr_dict = calc_RPrecision_HitRate(y_true, y_pred, tops=TOPs)\n",
    "    rp, hr_dict, auc = calc_metrics(y_true, y_pred, tops=TOPs)\n",
    "    rps_pop.append(rp)\n",
    "    for top in TOPs:\n",
    "        hitrates_pop[top].append(hr_dict[top])\n",
    "    aucs_pop.append(auc)\n",
    "    \n",
    "    # compute novelty@100\n",
    "    u = pl2u[j]\n",
    "    sortix = np.argsort(-y_pred)\n",
    "    nov = np.mean([-np.log2(song2pop[index2song_test[ix]]) for ix in sortix[:100]])\n",
    "    try:\n",
    "        novelty_pop[u].append(nov)\n",
    "    except KeyError:\n",
    "        novelty_pop[u] = [nov]\n",
    "\n",
    "    # compute diversity@100\n",
    "    # csd = 1. / cosine_similarity(X_test[sortix[:100], :])\n",
    "    # dist = pairwise_distances(Y_test_csr[sortix[:100], :].A, metric='hamming', n_jobs=4)\n",
    "    dist = pairwise_distance_hamming(Y_test_csr[sortix[:100], :])\n",
    "    diversities_pop.append((dist.sum() - np.trace(dist)) / (100 * 99))\n",
    "    \n",
    "print('\\n%d / %d' % (len(rps_pop), Y_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=[20, 5])\n",
    "# ax1 = plt.subplot(131)\n",
    "# ax1.hist(rps_pop, bins=100)\n",
    "# ax1.set_yscale('log')\n",
    "# ax1.set_title('R-Precision')\n",
    "# #ax.set_xlim(0, xmax)\n",
    "# ax2 = plt.subplot(132)\n",
    "# ax2.hist(aucs_pop, bins=100)\n",
    "# ax2.set_yscale('log')\n",
    "# ax2.set_title('AUC')\n",
    "# pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R-Precision': 0.00045846185932834824,\n",
       " 'Hit-Rate': {5: 0.0019463027743380492,\n",
       "  10: 0.008978570066680198,\n",
       "  20: 0.026329491607767857,\n",
       "  30: 0.034485467064040695,\n",
       "  50: 0.041645387039762755,\n",
       "  100: 0.0869623720184838,\n",
       "  200: 0.16780507689895133,\n",
       "  300: 0.21846529423276878,\n",
       "  500: 0.2880161152209812,\n",
       "  1000: 0.44232044414107435},\n",
       " 'AUC': 0.7651276089946246,\n",
       " 'Novelty': -2.3080483444860573,\n",
       " 'Diveristy': 0.0005110290581547344}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_perf = {dataset_name: {'Test': {'R-Precision': np.mean(rps_pop), \n",
    "                                    'Hit-Rate': {top: np.mean(hitrates_pop[top]) for top in TOPs},\n",
    "                                    'AUC': np.mean(aucs_pop),\n",
    "                                    'Novelty': np.mean([np.mean(novelty_pop[u]) for u in novelty_pop]),\n",
    "                                    'Diveristy': np.mean(diversities_pop)},\n",
    "                           'Test_All': {'R-Precision': rps_pop,\n",
    "                                        'Hit-Rate': {top: hitrates_pop[top] for top in TOPs},\n",
    "                                        'AUC': aucs_pop,\n",
    "                                        'Novelty': novelty_pop,\n",
    "                                        'Diversity': diversities_pop},\n",
    "                          }}\n",
    "pop_perf[dataset_name]['Test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/aotm2011/coldstart/setting1/perf-pop.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'R-Precision': 0.00045846185932834824,\n",
       " 'Hit-Rate': {5: 0.0019463027743380492,\n",
       "  10: 0.008978570066680198,\n",
       "  20: 0.026329491607767857,\n",
       "  30: 0.034485467064040695,\n",
       "  50: 0.041645387039762755,\n",
       "  100: 0.0869623720184838,\n",
       "  200: 0.16780507689895133,\n",
       "  300: 0.21846529423276878,\n",
       "  500: 0.2880161152209812,\n",
       "  1000: 0.44232044414107435},\n",
       " 'AUC': 0.7651276089946246,\n",
       " 'Novelty': -2.3080483444860573,\n",
       " 'Diveristy': 0.0005110290581547344}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fperf_pop = os.path.join(data_dir, 'perf-pop.pkl')\n",
    "print(fperf_pop)\n",
    "pkl.dump(pop_perf, open(fperf_pop, 'wb'))\n",
    "pkl.load(open(fperf_pop, 'rb'))[dataset_name]['Test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same Artists - Greatest Hits (SAGH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommend according to the popularity of artists in listening history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rps_sagh = []\n",
    "hitrates_sagh = {top: [] for top in TOPs}\n",
    "aucs_sagh = []\n",
    "novelty_sagh = dict()\n",
    "diversities_sagh = []\n",
    "\n",
    "npos = Y_test.sum(axis=0).A.reshape(-1)\n",
    "assert Y_test.shape[0] == len(test_songs)\n",
    "for j in range(Y_test.shape[1]):\n",
    "    if (j+1) % 100 == 0:\n",
    "        sys.stdout.write('\\r%d / %d' % (j+1, Y_test.shape[1]))\n",
    "        sys.stdout.flush()\n",
    "    if npos[j] < 1:\n",
    "        continue\n",
    "\n",
    "    y_true = Y_test[:, j].A.reshape(-1)\n",
    "    y_pred = np.zeros(y_true.shape)\n",
    "    \n",
    "    pl = all_playlists[j][0]\n",
    "    artists = set([song2artist[sid] for sid in pl if (sid not in test_songset) and (sid in song2artist)])\n",
    "    assert len(artists) > 0\n",
    "    \n",
    "    for ix in range(Y_test.shape[0]):\n",
    "        sid = index2song_test[ix]\n",
    "        if sid in song2artist:\n",
    "            aid = song2artist[sid]\n",
    "            if aid in artists and aid in artist2pop:\n",
    "                y_pred[ix] = artist2pop[aid]\n",
    "    \n",
    "    # rp, hr_dict = calc_RPrecision_HitRate(y_true, y_pred, tops=TOPs)\n",
    "    rp, hr_dict, auc = calc_metrics(y_true, y_pred, tops=TOPs)\n",
    "    rps_sagh.append(rp)\n",
    "    for top in TOPs:\n",
    "        hitrates_sagh[top].append(hr_dict[top])\n",
    "    aucs_sagh.append(auc)\n",
    "    \n",
    "    # compute novelty@100\n",
    "    u = pl2u[j]\n",
    "    sortix = np.argsort(-y_pred)\n",
    "    nov = np.mean([-np.log2(song2pop[index2song_test[ix]]) for ix in sortix[:100]])\n",
    "    try:\n",
    "        novelty_sagh[u].append(nov)\n",
    "    except KeyError:\n",
    "        novelty_sagh[u] = [nov]\n",
    "\n",
    "    # compute diversity@100\n",
    "    csd = 1. / cosine_similarity(X_test[sortix[:100], :])\n",
    "    diversities_sagh.append((csd.sum() - np.trace(csd)) / (100 * 99))\n",
    "    \n",
    "print('\\n%d / %d' % (len(rps_sagh), Y_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=[20, 5])\n",
    "# ax1 = plt.subplot(131)\n",
    "# ax1.hist(rps_sagh, bins=100)\n",
    "# ax1.set_yscale('log')\n",
    "# ax1.set_title('R-Precision')\n",
    "# #ax.set_xlim(0, xmax)\n",
    "# ax2 = plt.subplot(132)\n",
    "# ax2.hist(aucs_sagh, bins=100)\n",
    "# ax2.set_yscale('log')\n",
    "# ax2.set_title('AUC')\n",
    "# pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagh_perf = {dataset_name: {'Test': {'R-Precision': np.mean(rps_sagh), \n",
    "                                     'Hit-Rate': {top: np.mean(hitrates_sagh[top]) for top in hitrates_sagh},\n",
    "                                     'AUC': np.mean(aucs_sagh),\n",
    "                                     'Novelty': np.mean([np.mean(novelty_sagh[u]) for u in novelty_sagh]),\n",
    "                                     'Diveristy': np.mean(diversities_sagh)},\n",
    "                            'Test_All': {'R-Precision': rps_sagh,\n",
    "                                        'Hit-Rate': {top: hitrates_sagh[top] for top in TOPs},\n",
    "                                        'AUC': aucs_sagh,\n",
    "                                        'Novelty': novelty_sagh,\n",
    "                                        'Diversity': diversities_sagh},\n",
    "                           }}\n",
    "sagh_perf[dataset_name]['Test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fperf_sagh = os.path.join(data_dir, 'perf-sagh.pkl')\n",
    "print(fperf_sagh)\n",
    "pkl.dump(sagh_perf, open(fperf_sagh, 'wb'))\n",
    "pkl.load(open(fperf_sagh, 'rb'))[dataset_name]['Test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collocated Artists - Greatest Hits (CAGH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the similarity of two artist $a_1$ and $a_2$ given a set of playlist $P$:   \n",
    "$$\n",
    "\\text{sim}(a_1, a_2) \n",
    "= \\frac{\\sum_{p \\in P} \\delta(a_1, p) \\times \\delta(a_2, p)}\n",
    "       {\\sqrt{\\sum_{p \\in P} \\delta(a_1, p) \\times \\sum_{p \\in P} \\delta(a_2, p)}}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\delta(a, p) \n",
    "= \\begin{cases}\n",
    "1, \\ \\text{at least one song in playlist $p$ is from artist $a$}, \\\\\n",
    "0, \\ \\text{otherwise}.\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommend according to the popularity of songs, but weighted by similarity of (`artist in user's listening history`, `artist of song`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_artist_trndev = sorted(set([song2artist[sid] for pl, _ in all_playlists for sid in pl \\\n",
    "                                if (sid not in test_songset) and (sid in song2artist)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist2index = {aid: ix for ix, aid in enumerate(all_artist_trndev)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Na = len(all_artist_trndev)\n",
    "Np = len(all_playlists)\n",
    "Delta = lil_matrix((Na, Np), dtype=np.float)\n",
    "for j in range(Np):\n",
    "    pl_artist = sorted(set([song2artist[sid] for sid in all_playlists[j][0] \\\n",
    "                            if (sid not in test_songset) and (sid in song2artist)]))\n",
    "    ix = [artist2index[aid] for aid in pl_artist]\n",
    "    Delta[ix, j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Delta = Delta.tocsr()\n",
    "Dsum = Delta.sum(axis=1).A.reshape(-1)\n",
    "ColloMat = Delta.dot(Delta.T).A\n",
    "\n",
    "assert np.all(np.isclose(ColloMat.diagonal(), Dsum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(Dsum), len(all_artist_trndev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(ColloMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = 1. / np.sqrt(Dsum)\n",
    "NormMat = np.dot(T1.reshape(Na, 1), T1.reshape(1, Na))\n",
    "\n",
    "WeightMat = np.multiply(ColloMat, NormMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rps_cagh = []\n",
    "hitrates_cagh = {top: [] for top in TOPs}\n",
    "aucs_cagh = []\n",
    "novelty_cagh = dict()\n",
    "diversities_cagh = []\n",
    "\n",
    "npos = Y_test.sum(axis=0).A.reshape(-1)\n",
    "assert Y_test.shape[0] == len(test_songs)\n",
    "for j in range(Y_test.shape[1]):\n",
    "    if (j+1) % 10 == 0:\n",
    "        sys.stdout.write('\\r%d / %d' % (j+1, Y_test.shape[1]))\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    if npos[j] < 1:\n",
    "        continue\n",
    "    \n",
    "    y_true = Y_test[:, j].A.reshape(-1)\n",
    "    y_pred = np.zeros(y_true.shape)\n",
    "    \n",
    "    pl = all_playlists[j][0]\n",
    "    artists = set([song2artist[sid] for sid in pl if (sid not in test_songset) and (sid in song2artist)])\n",
    "    assert len(artists) > 0\n",
    "    artists_ix = [artist2index[aid] for aid in artists]\n",
    "    \n",
    "    for ix in range(Y_test.shape[0]):\n",
    "        sid = index2song_test[ix]\n",
    "        if sid in song2artist:\n",
    "            aid = song2artist[sid]\n",
    "            if aid in artist2pop:\n",
    "                aix = artist2index[aid]\n",
    "                y_pred[ix] = artist2pop[aid] * WeightMat[aix, artists_ix].sum()\n",
    "\n",
    "    # rp, hr_dict = calc_RPrecision_HitRate(y_true, y_pred, tops=TOPs)\n",
    "    rp, hr_dict, auc = calc_metrics(y_true, y_pred, tops=TOPs)\n",
    "    rps_cagh.append(rp)\n",
    "    for top in TOPs:\n",
    "        hitrates_cagh[top].append(hr_dict[top])\n",
    "    aucs_cagh.append(auc)\n",
    "    \n",
    "    # compute novelty@100\n",
    "    u = pl2u[j]\n",
    "    sortix = np.argsort(-y_pred)\n",
    "    nov = np.mean([-np.log2(song2pop[index2song_test[ix]]) for ix in sortix[:100]])\n",
    "    try:\n",
    "        novelty_cagh[u].append(nov)\n",
    "    except KeyError:\n",
    "        novelty_cagh[u] = [nov]\n",
    "\n",
    "    # compute diversity@100\n",
    "    csd = 1. / cosine_similarity(X_test[sortix[:100], :])\n",
    "    diversities_cagh.append((csd.sum() - np.trace(csd)) / (100 * 99))\n",
    "\n",
    "print('\\n%d / %d' % (len(rps_cagh), Y_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=[20, 5])\n",
    "# ax1 = plt.subplot(131)\n",
    "# ax1.hist(rps_cagh, bins=100)\n",
    "# ax1.set_yscale('log')\n",
    "# ax1.set_title('R-Precision')\n",
    "# #ax.set_xlim(0, xmax)\n",
    "# ax2 = plt.subplot(132)\n",
    "# ax2.hist(aucs_cagh, bins=100)\n",
    "# ax2.set_yscale('log')\n",
    "# ax2.set_title('AUC')\n",
    "# pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cagh_perf = {dataset_name: {'Test': {'R-Precision': np.mean(rps_cagh), \n",
    "                                     'Hit-Rate': {top: np.mean(hitrates_cagh[top]) for top in hitrates_cagh},\n",
    "                                     'AUC': np.mean(aucs_cagh),\n",
    "                                     'Novelty': np.mean([np.mean(novelty_cagh[u]) for u in novelty_cagh]),\n",
    "                                     'Diveristy': np.mean(diversities_cagh)},\n",
    "                            'Test_All': {'R-Precision': rps_cagh,\n",
    "                                        'Hit-Rate': {top: hitrates_cagh[top] for top in TOPs},\n",
    "                                        'AUC': aucs_cagh,\n",
    "                                        'Novelty': novelty_cagh,\n",
    "                                        'Diversity': diversities_cagh},\n",
    "                           }}\n",
    "cagh_perf[dataset_name]['Test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fperf_cagh = os.path.join(data_dir, 'perf-cagh.pkl')\n",
    "print(fperf_cagh)\n",
    "pkl.dump(cagh_perf, open(fperf_cagh, 'wb'))\n",
    "pkl.load(open(fperf_cagh, 'rb'))[dataset_name]['Test']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
