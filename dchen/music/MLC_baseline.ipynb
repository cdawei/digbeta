{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple example of  multilabel learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os, sys, time\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.io import arff\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "yeast_ftrain = os.path.join(data_dir, 'yeast/yeast-train.arff')\n",
    "yeast_ftest  = os.path.join(data_dir, 'yeast/yeast-test.arff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load yeast dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train, meta_train = arff.loadarff(yeast_ftrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_test, meta_test = arff.loadarff(yeast_ftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(data_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#features: 103\n"
     ]
    }
   ],
   "source": [
    "nFeatures = np.array(list(data_train[0])[:-14], dtype=np.float).shape[0]\n",
    "print('#features:', nFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.array(list(data_train[0])[:-14], dtype=np.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#labels: 14\n"
     ]
    }
   ],
   "source": [
    "nLabels = np.array(list(data_train[0])[-14:], dtype=np.int).shape[0]\n",
    "print('#labels:', nLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(data_train[0])[-14:], dtype=np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#training examples: 1500\n"
     ]
    }
   ],
   "source": [
    "print('#training examples:', len(data_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#test examples: 917\n"
     ]
    }
   ],
   "source": [
    "print('#test examples:', len(data_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram of #positive labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nPositives = [np.sum(np.array(list(data_train[ix])[-14:], dtype=np.int)) for ix in range(len(data_train))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f3da4a6d080>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3da4f00048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(nPositives).hist(bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataset(label_ix, data):\n",
    "    \"\"\"\n",
    "        Create the labelled dataset for a given label index\n",
    "        \n",
    "        Input:\n",
    "            - label_ix: label index, number in { 0, ..., # labels }\n",
    "            - data: original data with features + labels\n",
    "            \n",
    "        Output:\n",
    "            - (Feature, Label) pair (X, y)\n",
    "              X comprises the features for each example\n",
    "              y comprises the labels of the corresponding example\n",
    "    \"\"\"\n",
    "\n",
    "    assert(label_ix >= 0)\n",
    "    assert(label_ix < nLabels)\n",
    "\n",
    "    N = len(data)\n",
    "    d = nFeatures\n",
    "    \n",
    "    magic = -14\n",
    "\n",
    "    X = np.zeros((N, d), dtype = np.float)\n",
    "    y = np.zeros(N, dtype = np.int)\n",
    "       \n",
    "    for i in range(N):\n",
    "        X[i, :] = list(data[i])[:magic]\n",
    "        y[i]    = list(data[i])[magic:][label_ix]\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataset_v2(data):\n",
    "    \"\"\"\n",
    "        Create the labelled dataset for a given label index\n",
    "        \n",
    "        Input:\n",
    "            - data: original data with features + labels\n",
    "            \n",
    "        Output:\n",
    "            - (Feature, Label) pair (X, y)\n",
    "              X comprises the features for each example\n",
    "              Y comprises the labels of the corresponding example\n",
    "    \"\"\"\n",
    "\n",
    "    N = len(data)\n",
    "    D = nFeatures\n",
    "    L = nLabels\n",
    "\n",
    "    magic = -14\n",
    "\n",
    "    X = np.zeros((N, D), dtype = np.float)\n",
    "    Y = np.zeros((N, L), dtype = np.int)\n",
    "       \n",
    "    for i in range(N):\n",
    "        X[i, :] = list(data[i])[:magic]\n",
    "        Y[i, :] = list(data[i])[magic:]\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss between a ground truth and a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evalPred(truth, pred, lossType = 'Hamming'):\n",
    "    \"\"\"\n",
    "        Compute loss given ground truth and prediction\n",
    "        \n",
    "        Input:\n",
    "            - truth:    binary array of true labels\n",
    "            - pred:     real-valued array of predictions\n",
    "            - lossType: can be subset 0-1, Hamming, ranking, and Precision@K where K = # positive labels.\n",
    "    \"\"\"\n",
    "\n",
    "    assert(len(truth) == len(pred))\n",
    "    L = len(truth)\n",
    "    nPos = np.sum(truth)\n",
    "    \n",
    "    predBin = np.array((pred > 0), dtype=np.int)\n",
    "    \n",
    "    if lossType == 'Subset01':\n",
    "        return 1 - int(np.all(truth == predBin))\n",
    "    \n",
    "    elif lossType == 'Hamming':\n",
    "        return np.sum(truth != predBin) / L\n",
    "    \n",
    "    elif lossType == 'Ranking':\n",
    "        loss = 0\n",
    "        for i in range(L-1):\n",
    "            for j in range(i+1, L):\n",
    "                if truth[i] > truth[j]:\n",
    "                    if pred[i] < pred[j]: \n",
    "                        loss += 1\n",
    "                    if pred[i] == pred[j]:\n",
    "                        loss += 0.5\n",
    "        #return loss / (nPos * (L-nPos))\n",
    "        return loss\n",
    "        \n",
    "    elif lossType == 'Precision@K':\n",
    "        # sorted indices of the labels most likely to be +'ve\n",
    "        idx = np.argsort(pred)[::-1]\n",
    "        \n",
    "        # true labels according to the sorted order\n",
    "        y = truth[idx]\n",
    "        \n",
    "        # fraction of +'ves in the top K predictions\n",
    "        return np.mean(y[:nPos])if nPos > 0 else 0\n",
    "    \n",
    "    elif lossType == 'Precision@3':\n",
    "        # sorted indices of the labels most likely to be +'ve\n",
    "        idx = np.argsort(pred)[::-1]\n",
    "        \n",
    "        # true labels according to the sorted order\n",
    "        y = truth[idx]\n",
    "        \n",
    "        # fraction of +'ves in the top K predictions\n",
    "        return np.mean(y[:3])\n",
    "    \n",
    "    elif lossType == 'Precision@5':\n",
    "        # sorted indices of the labels most likely to be +'ve\n",
    "        idx = np.argsort(pred)[::-1]\n",
    "        \n",
    "        # true labels according to the sorted order\n",
    "        y = truth[idx]\n",
    "        \n",
    "        # fraction of +'ves in the top K predictions\n",
    "        return np.mean(y[:5])\n",
    "    \n",
    "    else:\n",
    "        assert(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printEvaluation(allTruths, allPreds):\n",
    "    \n",
    "    N = allTruths.shape[0]\n",
    "    #print(N)\n",
    "\n",
    "    for lossType in ['Precision@K']: \n",
    "        # ['Subset01', 'Hamming', 'Ranking', 'Precision@K', 'Precision@3', 'Precision@5']:\n",
    "        losses = [ ]\n",
    "        for i in range(allPreds.shape[0]):\n",
    "            pred  = allPreds[i, :]\n",
    "            truth = allTruths[i, :]\n",
    "            losses.append(evalPred(truth, pred, lossType))\n",
    "\n",
    "            #print(allPreds[i])\n",
    "            #print(pred)\n",
    "            #print(truth)\n",
    "            #break\n",
    "\n",
    "        #print('%24s: %1.4f' % ('Average %s Loss' % lossType, np.mean(losses)))\n",
    "        print('%s: %1.4f, %.3f' % ('Average %s' % lossType, np.mean(losses), np.std(losses) / np.sqrt(N)))\n",
    "        #plt.hist(aucs, bins = 10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avgPrecisionK(allTruths, allPreds):\n",
    "    losses = []\n",
    "    lossType = 'Precision@K'\n",
    "    for i in range(allPreds.shape[0]):\n",
    "        pred  = allPreds[i, :]\n",
    "        truth = allTruths[i, :]\n",
    "        losses.append(evalPred(truth, pred, lossType))\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary relevance baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a logistic regression model for each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for Label 1\n",
      "Best parameters set found on development set:\n",
      "{'C': 1}\n",
      "\n",
      "Training for Label 2\n",
      "Best parameters set found on development set:\n",
      "{'C': 100}\n",
      "\n",
      "Training for Label 3\n",
      "Best parameters set found on development set:\n",
      "{'C': 1}\n",
      "\n",
      "Training for Label 4\n",
      "Best parameters set found on development set:\n",
      "{'C': 1}\n",
      "\n",
      "Training for Label 5\n",
      "Best parameters set found on development set:\n",
      "{'C': 1}\n",
      "\n",
      "Training for Label 6\n",
      "Best parameters set found on development set:\n",
      "{'C': 10}\n",
      "\n",
      "Training for Label 7\n",
      "Best parameters set found on development set:\n",
      "{'C': 1000}\n",
      "\n",
      "Training for Label 8\n",
      "Best parameters set found on development set:\n",
      "{'C': 1}\n",
      "\n",
      "Training for Label 9\n",
      "Best parameters set found on development set:\n",
      "{'C': 10}\n",
      "\n",
      "Training for Label 10\n",
      "Best parameters set found on development set:\n",
      "{'C': 100}\n",
      "\n",
      "Training for Label 11\n",
      "Best parameters set found on development set:\n",
      "{'C': 100}\n",
      "\n",
      "Training for Label 12\n",
      "Best parameters set found on development set:\n",
      "{'C': 100}\n",
      "\n",
      "Training for Label 13\n",
      "Best parameters set found on development set:\n",
      "{'C': 100}\n",
      "\n",
      "Training for Label 14\n",
      "Best parameters set found on development set:\n",
      "{'C': 1000}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "allPreds_train  = [ ]\n",
    "allPreds_test  = [ ]\n",
    "allTruths_train = [ ]\n",
    "allTruths_test = [ ]\n",
    "coefMat = [ ]\n",
    "labelIndices = [ ]\n",
    "\n",
    "parameters = [{'C': [0.01, 0.1, 1, 10, 100, 1000]}]\n",
    "scoring = 'accuracy' #'precision_macro' # 'average_precision'\n",
    "\n",
    "for label_ix in range(nLabels):\n",
    "    print('Training for Label %d' % (label_ix+1))\n",
    "    X_train, y_train = create_dataset(label_ix, data = data_train)\n",
    "    X_test, y_test   = create_dataset(label_ix, data = data_test)\n",
    "    \n",
    "    allTruths_train.append(y_train)\n",
    "    allTruths_test.append(y_test) \n",
    "    \n",
    "    assert( (not np.all(y_train == 0)) and (not np.all(y_train == 1)) )\n",
    "    \n",
    "    clf = GridSearchCV(LogisticRegression(class_weight='balanced'), parameters, cv=10, scoring=scoring)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    \n",
    "    allPreds_train.append(clf.decision_function(X_train))\n",
    "    allPreds_test.append(clf.decision_function(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(917, 14)\n",
      "(917, 14)\n"
     ]
    }
   ],
   "source": [
    "allTruths_train = np.array(allTruths_train).T\n",
    "allTruths_test = np.array(allTruths_test).T\n",
    "\n",
    "allPreds_train  = np.array(allPreds_train).T\n",
    "allPreds_test  = np.array(allPreds_test).T\n",
    "\n",
    "print(allPreds_test.shape)\n",
    "print(allTruths_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allPreds_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "Average Precision@K: 0.5938, 0.008\n",
      "\n",
      "Test set:\n",
      "Average Precision@K: 0.5077, 0.010\n"
     ]
    }
   ],
   "source": [
    "print('Training set:')\n",
    "printEvaluation(allTruths_train, allPreds_train)\n",
    "print()\n",
    "print('Test set:')\n",
    "printEvaluation(allTruths_test, allPreds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coefficient matrix `(#Genres, #Songs)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coefMat = np.array(coefMat).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefMat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sns.heatmap(coefMat[:, :30])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
