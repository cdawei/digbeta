{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pickle as pkl\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('src')\n",
    "from datasets import dataset_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "algos = ['tp', 'lr']\n",
    "algo_names = ['TP-MLC', 'LR-CV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics = ['Precision@3', 'Precision@5', 'Precision@K']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = pd.MultiIndex.from_product([dataset_names, algo_names], names=['Dataset', 'Method'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(index=indices, columns=metrics)\n",
    "df_test  = pd.DataFrame(index=indices, columns=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.path.join(data_dir, 'prec-tp.pkl')\n",
    "records = pkl.load(open(fname, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bibtex': {'Test': {'Precision@3': (0.39310801855533467,\n",
       "    0.0056420225028509163),\n",
       "   'Precision@5': (0.28827037773359843, 0.004089129789854499),\n",
       "   'Precision@K': (0.50436113383751091, 0.0077660577802836561)},\n",
       "  'Train': {'Precision@3': (0.6430327868852459, 0.0041116973534355552),\n",
       "   'Precision@5': (0.44204918032786883, 0.0036432300240666396),\n",
       "   'Precision@K': (0.96465342887986327, 0.0020177837505827136)}},\n",
       " 'scene': {'Test': {'Precision@3': (0.3455964325529543, 0.0030066931859594973),\n",
       "   'Precision@5': (0.21672240802675585, 0.0016523803574544961),\n",
       "   'Precision@K': (0.73662207357859533, 0.012444886193761868)},\n",
       "  'Train': {'Precision@3': (0.34957335535370221, 0.0023698369533023717),\n",
       "   'Precision@5': (0.2122213047068538, 0.0014156792365537137),\n",
       "   'Precision@K': (0.88521882741535918, 0.0089718173224213119)}},\n",
       " 'yeast': {'Test': {'Precision@3': (0.53871319520174477, 0.010565917513821665),\n",
       "   'Precision@5': (0.45343511450381679, 0.0083494869890093151),\n",
       "   'Precision@K': (0.50936542555953679, 0.009843428271229469)},\n",
       "  'Train': {'Precision@3': (0.60199999999999998, 0.008118097447853129),\n",
       "   'Precision@5': (0.50626666666666664, 0.0065612022385241877),\n",
       "   'Precision@K': (0.56898540163540168, 0.0076074067624799227)}}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in dataset_names:\n",
    "    if ds in records:\n",
    "        for metric in metrics:\n",
    "            df_train.loc[(ds, 'TP-MLC'), metric] = records[ds]['Train'][metric][0]\n",
    "            df_test.loc [(ds, 'TP-MLC'), metric] = records[ds]['Test' ][metric][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "       &       & Precision@3 & Precision@5 & Precision@K & F1 \\\\\n",
      "Dataset & Method &             &             &             &    \\\\\n",
      "\\midrule\n",
      "\\multirow{2}{*}{yeast} & TP-MLC &      0.6020 &      0.5063 &      0.5690 &  - \\\\\n",
      "       & LR-CV &           - &           - &           - &  - \\\\\n",
      "\\cline{1-6}\n",
      "\\multirow{2}{*}{scene} & TP-MLC &      0.3496 &      0.2122 &      0.8852 &  - \\\\\n",
      "       & LR-CV &           - &           - &           - &  - \\\\\n",
      "\\cline{1-6}\n",
      "\\multirow{2}{*}{bibtex} & TP-MLC &      0.6430 &      0.4420 &      0.9647 &  - \\\\\n",
      "       & LR-CV &           - &           - &           - &  - \\\\\n",
      "\\cline{1-6}\n",
      "\\multirow{2}{*}{bookmarks} & TP-MLC &           - &           - &           - &  - \\\\\n",
      "       & LR-CV &           - &           - &           - &  - \\\\\n",
      "\\cline{1-6}\n",
      "\\multirow{2}{*}{delicious} & TP-MLC &           - &           - &           - &  - \\\\\n",
      "       & LR-CV &           - &           - &           - &  - \\\\\n",
      "\\cline{1-6}\n",
      "\\multirow{2}{*}{mediamill} & TP-MLC &           - &           - &           - &  - \\\\\n",
      "       & LR-CV &           - &           - &           - &  - \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tab_train = df_train.to_latex(float_format=lambda x: '%.4f' % x, na_rep='-', multirow=True)\n",
    "print(tab_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasets = ['yeast', 'scene', 'bibtex', 'bookmarks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split = 'Train'\n",
    "split = 'Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load perf records\n",
    "perf_files = [os.path.join(data_dir, 'perf-' + algo + '.pkl') for algo in algos]\n",
    "perf_dicts = [pkl.load(open(fname, 'rb')) for fname in perf_files]\n",
    "\n",
    "def perfstr(perftuple):\n",
    "    return '$%.4f \\\\pm  %.3f$' % (perftuple[0], perftuple[1])\n",
    "\n",
    "for metric in metrics:\n",
    "    tabstr = []\n",
    "    tabstr.append('\\\\begin{table}[!h]')\n",
    "    tabstr.append('\\centering')\n",
    "    tabstr.append('\\\\caption{Performance in terms of average %s (%s)}' % (metric, split))\n",
    "    tabstr.append('\\\\begin{tabular}{lcccc} \\\\\\\\ \\\\hline \\\\hline')\n",
    "    tabstr.append(' & ' + ' & '.join([ds for ds in datasets]) + ' \\\\\\\\')\n",
    "    for j in range(len(algos)):\n",
    "        tabstr.append(algo_names[j] + ' & '\n",
    "                      + ' & '.join([perfstr(perf_dicts[j][ds][split][metric]) \\\n",
    "                                    if ds in perf_dicts[j] else '-' for ds in datasets ])\n",
    "                      + ' \\\\\\\\')\n",
    "    tabstr.append('\\\\hline')\n",
    "    tabstr.append('\\\\end{tabular}')\n",
    "    tabstr.append('\\\\end{table}')\n",
    "    print('\\n'.join(tabstr))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
