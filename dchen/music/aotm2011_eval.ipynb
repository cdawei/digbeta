{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Playlist generation / augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys, time, gzip\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, average_precision_score\n",
    "from scipy.sparse import lil_matrix, issparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('src')\n",
    "from PCMLC import PCMLC as PClassificationMLC\n",
    "from PCMLC import obj_pclassification\n",
    "from BinaryRelevance import BinaryRelevance\n",
    "from evaluate import f1_score_nowarn, calc_F1, calc_precisionK, evaluate_minibatch, evalPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/aotm-2011/setting1'\n",
    "fxtrain = os.path.join(data_dir, 'X_train.pkl.gz')\n",
    "fytrain = os.path.join(data_dir, 'Y_train.pkl.gz')\n",
    "fxdev   = os.path.join(data_dir, 'X_dev.pkl.gz')\n",
    "fydev   = os.path.join(data_dir, 'Y_dev.pkl.gz')\n",
    "fxtest  = os.path.join(data_dir, 'X_test.pkl.gz')\n",
    "fytest  = os.path.join(data_dir, 'Y_test.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPs = [5, 10, 20, 30, 50, 100, 200, 300, 500, 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pkl.load(gzip.open(fxtrain, 'rb'))\n",
    "Y_train = pkl.load(gzip.open(fytrain, 'rb'))\n",
    "X_dev   = pkl.load(gzip.open(fxdev,   'rb'))\n",
    "Y_dev   = pkl.load(gzip.open(fydev,   'rb'))\n",
    "X_test  = pkl.load(gzip.open(fxtest,  'rb'))\n",
    "Y_test  = pkl.load(gzip.open(fytest,  'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:    (80100, 217)  (80100, 84710)\n",
      "Dev  :    (11442, 217)  (11442, 84710)\n",
      "Test :    (22886, 217)  (22886, 84710)\n"
     ]
    }
   ],
   "source": [
    "print('Train: %15s %15s' % (X_train.shape, Y_train.shape))\n",
    "print('Dev  : %15s %15s' % (X_dev.shape,   Y_dev.shape))\n",
    "print('Test : %15s %15s' % (X_test.shape,  Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_auc_hitrate(estimator, X, Y, top=100, useLoop=False):\n",
    "    N, D = X.shape\n",
    "    K = Y.shape[1]\n",
    "    assert Y.shape[0] == N\n",
    "    assert top <= N\n",
    "    if issparse(Y):\n",
    "        #Y = Y.tocsc().astype(np.bool)\n",
    "        npos = np.array(Y.sum(axis=0))[0]  # be careful with sparse matrix\n",
    "    else:\n",
    "        npos = np.sum(Y, axis=0)\n",
    "    nzcol = np.nonzero(npos)[0]  # need columns with at least one True\n",
    "    if useLoop is False:\n",
    "        Y_pred = estimator.predict(X)\n",
    "        auc = roc_auc_score(Y[:, nzcol], Y_pred[:, nzcol], average='macro')\n",
    "        topix = np.argsort(-Y_pred, axis=0)[:top, :]\n",
    "        hitrate = np.mean([np.sum(Y[topix[:, col], col]) / npos[col] for col in nzcol])\n",
    "        return auc, hitrate\n",
    "    else:\n",
    "        W = estimator.W\n",
    "        b = estimator.b\n",
    "        assert W.shape == (K, D)\n",
    "        aucs = []\n",
    "        hitrates = []\n",
    "        for col in nzcol:\n",
    "            if (col+1) % 100 == 0:\n",
    "                sys.stdout.write('\\r{:,} / {:,}'.format(col+1, nzcol[-1]))\n",
    "                sys.stdout.flush()\n",
    "            pred = np.dot(X, W[col, :]) + b\n",
    "            #aucs.append(roc_auc_score(Y[:, col], pred))  # TypeError: len() of unsized object\n",
    "            y_true = Y[:, col].toarray()\n",
    "            aucs.append(roc_auc_score(y_true, pred))\n",
    "            topix = np.argsort(-pred)[:top]\n",
    "            hitrates.append(np.sum(Y[topix, col]) / npos[col])\n",
    "        return np.mean(aucs), np.mean(hitrates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_auc(results):\n",
    "    assert type(results) == list\n",
    "    aucs = np.array([t[0] for t in results])\n",
    "    nums = np.array([t[1] for t in results])\n",
    "    return np.sum(aucs * nums) / np.sum(nums)\n",
    "\n",
    "def calc_hitrate_pl(Y_true, Y_pred, top=100):\n",
    "    assert Y_true.shape == Y_pred.shape\n",
    "    assert top <= Y_true.shape[0]\n",
    "    nzcol = np.nonzero(np.sum(Y_true, axis=0))[0]  # columns with at least one True\n",
    "    topix = np.argsort(-Y_pred, axis=0)[:top, :]\n",
    "    npos = np.sum(Y_true, axis=0)\n",
    "    return np.array([np.sum(Y_true[topix[:, col], col]) / npos[col] for col in nzcol])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_pl(Y_true, Y_pred, top=100, useLoop=False):\n",
    "    if useLoop is False:\n",
    "        assert Y_true.shape == Y_pred.shape\n",
    "        assert top <= Y_true.shape[0]\n",
    "        nzcol = np.nonzero(np.sum(Y_true, axis=0))[0]  # columns with at least one True\n",
    "        ncols = len(nzcol)\n",
    "        topix = np.argsort(-Y_pred, axis=0)[:top, :]\n",
    "        npos = np.sum(Y_true, axis=0)\n",
    "        hr = np.mean([np.sum(Y_true[topix[:, j], j]) / npos[j] for j in nzcol])\n",
    "        paks, valid_indices = calc_precisionK(Y_true.T, Y_pred.T)\n",
    "        pak = np.mean(paks[valid_indices])\n",
    "        auc = roc_auc_score(Y_true[:, nzcol], Y_pred[:, nzcol], average='macro')\n",
    "        ap  = average_precision_score(Y_true[:, nzcol], Y_pred[:, nzcol], average='macro')\n",
    "        nrr = mean_normalised_reciprocal_rank(Y_true, Y_pred)\n",
    "    else:\n",
    "        assert type(Y_true) == list\n",
    "        assert type(Y_pred) == list\n",
    "        assert len(Y_true) == len(Y_pred)\n",
    "        hitrates, paks, aucs, aps, nrrs = [], [], [], [], []\n",
    "        for j in range(len(Y_true)):\n",
    "            if np.sum(Y_true[j]) < 1: continue   # filtering out cases where all ground truths are negative.\n",
    "            gt = Y_true[j].reshape(-1)\n",
    "            pred = Y_pred[j].reshape(-1)\n",
    "            assert gt.shape == pred.shape\n",
    "            assert top <= gt.shape[0]\n",
    "            topix = np.argsort(-pred)[:top]\n",
    "            hitrates.append(np.sum(gt[topix]) / np.sum(gt))\n",
    "            #paks.append(calc_precisionK(gt.reshape(1,-1), pred.reshape(1,-1)))  # incorrect\n",
    "            paks.append(evalPred(gt, pred, metricType='Precision@K'))\n",
    "            aucs.append(roc_auc_score(gt, pred))\n",
    "            aps.append(average_precision_score(gt, pred))\n",
    "            nrrs.append(mean_normalised_reciprocal_rank(gt.reshape(-1,1), pred.reshape(-1,1)))\n",
    "        hr, pak, auc, ap, nrr = [np.mean(x) for x in [hitrates, paks, aucs, aps, nrrs]]\n",
    "        ncols = len(paks)\n",
    "      \n",
    "    print('Average over %d columns' % ncols)\n",
    "    print('%-20s %.4f' % ('Mean HitRate@100:', hr))\n",
    "    print('%-20s %.4f' % ('Mean P@K:', pak))\n",
    "    print('%-20s %.4f' % ('Mean AUC:', auc))\n",
    "    print('%-20s %.4f' % ('MAP:', ap))\n",
    "    print('%-20s %.4f' % ('Mean NRR:', nrr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_auc_pl(Y_true, Y_pred, useLoop=False):\n",
    "    if useLoop is False:\n",
    "        assert Y_true.shape == Y_pred.shape\n",
    "        npos = np.asarray(np.sum(Y_true, axis=0)).reshape(-1)  # 1D array, works for both sparse and dense matrix\n",
    "        nzcol = np.nonzero(npos)[0]  # columns with at least one True\n",
    "        Y_part = Y_true[:, nzcol]\n",
    "        if issparse(Y_part):\n",
    "            Y_part = Y_part.toarray()\n",
    "        auc = roc_auc_score(Y_part, Y_pred[:, nzcol], average='macro')\n",
    "        return (auc, len(nzcol))\n",
    "    else:\n",
    "        assert type(Y_true) == list\n",
    "        assert type(Y_pred) == list\n",
    "        assert len(Y_true) == len(Y_pred)\n",
    "        aucs = []\n",
    "        for j in range(len(Y_true)):\n",
    "            if np.sum(Y_true[j]) < 1: continue   # filtering out cases where all ground truths are negative.\n",
    "            gt = Y_true[j].reshape(-1)\n",
    "            pred = Y_pred[j].reshape(-1)\n",
    "            assert gt.shape == pred.shape\n",
    "            aucs.append(roc_auc_score(gt, pred))\n",
    "        return (np.mean(aucs), len(aucs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_hitrate_pl(Y_true, Y_pred, tops=[100], useLoop=False):\n",
    "    \"\"\"\n",
    "        Compute hitrate at top-N.\n",
    "    \"\"\"\n",
    "    if useLoop is False:\n",
    "        assert Y_true.shape == Y_pred.shape\n",
    "        assert type(tops) == list\n",
    "        hitrates = []\n",
    "        sortix = np.argsort(-Y_pred, axis=0)\n",
    "        npos = np.asarray(np.sum(Y_true, axis=0)).reshape(-1)  # 1D array, works for both sparse and dense matrix\n",
    "        nzcol = np.nonzero(npos)[0]  # columns with at least one True\n",
    "        for top in tops:\n",
    "            assert 0 < top <= Y_true.shape[0]\n",
    "            topix = sortix[:top, :]\n",
    "            hr = np.mean([np.sum(Y_true[topix[:, col], col]) / npos[col] for col in nzcol])\n",
    "            hitrates.append(hr)\n",
    "        return (hitrates, len(nzcol))\n",
    "    else:\n",
    "        assert type(Y_true) == list\n",
    "        assert type(Y_pred) == list\n",
    "        assert len(Y_true) == len(Y_pred)\n",
    "        assert type(tops) == list\n",
    "        top_dict = {top: [] for top in tops}\n",
    "        for j in range(len(Y_true)):\n",
    "            if np.sum(Y_true[j]) < 1: continue   # filtering out cases where all ground truths are negative.\n",
    "            gt = Y_true[j].reshape(-1)\n",
    "            pred = Y_pred[j].reshape(-1)\n",
    "            sortix = np.argsort(-pred)\n",
    "            assert gt.shape == pred.shape\n",
    "            for top in tops:\n",
    "                assert 0 < top <= gt.shape[0]\n",
    "                topix = sortix[:top]\n",
    "                top_dict[top].append(np.sum(gt[topix]) / np.sum(gt))\n",
    "        ncols = len(top_dict[tops[0]])\n",
    "        for top in tops:\n",
    "            assert ncols == len(top_dict[top])\n",
    "        return ([np.mean(top_dict[top]) for top in tops], ncols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLR on dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1 = [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100, 300, 1000, 3000]\n",
    "C2 = [0.01, 0.1, 0.2, 0.4, 0.6, 0.8, 1, 3, 10, 30, 100, 300, 1000]\n",
    "C3 = [0.01, 0.1, 0.3, 1, 2, 4, 6, 8, 10, 20, 30, 100, 300, 1000]\n",
    "P = [1, 2, 3, 4, 5, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%script false\n",
    "for c1 in C1:\n",
    "    for c2 in C2:\n",
    "        for c3 in C3:\n",
    "            for p in P:\n",
    "                fname = os.path.join(data_dir, 'mlr-aotm2011-C-%g-%g-%g-p-%g.pkl' % (c1, c2, c3, p))\n",
    "                if os.path.exists(fname):\n",
    "                    clf = pkl.load(open(fname, 'rb'))\n",
    "                    print(clf)\n",
    "                    auc_dev, hr_dev = calc_auc_hitrate(clf, X_dev, Y_dev, useLoop=True)\n",
    "                    print('{:10s}: AUC = {:.4f}, HitRate@100 = {:.4f}'.format('Dev set', auc_dev, hr_dev))\n",
    "                    auc_test, hr_test = calc_auc_hitrate(clf, X_test, Y_test, useLoop=True)\n",
    "                    print('{:10s}: AUC = {:.4f}, HitRate@100 = {:.4f}'.format('Test set', auc_test, hr_test))\n",
    "                    print('-'*50, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_auc_w(W, b, X, Y):\n",
    "    aucs = []\n",
    "    for j in range(Y.shape[1]):\n",
    "        if (j+1) % 100 == 0:\n",
    "            sys.stdout.write('\\r%d / %d' % (j+1, Y.shape[1]))\n",
    "            sys.stdout.flush()\n",
    "        y_true = Y[:, j]\n",
    "        if issparse(Y):\n",
    "            y_true = y_true.toarray().reshape(-1)\n",
    "        if np.sum(y_true) < 1: continue\n",
    "        y_pred = np.dot(X, W[j, :]) + b\n",
    "        aucs.append(roc_auc_score(y_true, y_pred))\n",
    "    return aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84700 / 84710\n",
      "0.6662, 37886 / 84710\n"
     ]
    }
   ],
   "source": [
    "w = np.load('data/aotm-2011/setting1/mlr_lineareg/both-1000-0.01-30-5-latest.npy')\n",
    "aucs1 = calc_auc_w(W=w[1:].reshape(K, D), b=w[0], X=X_dev, Y=Y_dev)\n",
    "print('\\n%.4f, %d / %d' % (np.mean(aucs1), len(aucs1), Y_dev.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84700 / 84710\n",
      "0.6724, 52797 / 84710\n"
     ]
    }
   ],
   "source": [
    "w = np.load('data/aotm-2011/setting1/mlr_lineareg/both-1000-0.01-30-5-latest.npy')\n",
    "aucs2 = calc_auc_w(W=w[1:].reshape(K, D), b=w[0], X=X_test, Y=Y_test)\n",
    "print('\\n%.4f, %d / %d' % (np.mean(aucs2), len(aucs2), Y_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/aotm-2011/setting1/mlr_samples/mlr-aotm2011-samples-C-0.1-1-1-p-1.pkl\n",
      "84700 / 84710\n",
      "0.6031, 52797 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-aotm2011-samples-C-0.1-1-1-p-2.pkl\n",
      "84700 / 84710\n",
      "0.6099, 52797 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-aotm2011-samples-C-0.1-1-1-p-3.pkl\n",
      "84700 / 84710\n",
      "0.6161, 52797 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-aotm2011-samples-C-0.1-1-1-p-4.pkl\n",
      "84700 / 84710\n",
      "0.6102, 52797 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-aotm2011-samples-C-0.1-1-1-p-5.pkl\n",
      "84700 / 84710\n",
      "0.6133, 52797 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-aotm2011-samples-C-0.3-1-1-p-1.pkl\n",
      "84700 / 84710\n",
      "0.6423, 52797 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-aotm2011-samples-C-0.3-1-1-p-2.pkl\n",
      "84700 / 84710\n",
      "0.6414, 52797 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-aotm2011-samples-C-0.3-1-1-p-3.pkl\n",
      "84700 / 84710\n",
      "0.6441, 52797 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-aotm2011-samples-C-0.3-1-1-p-4.pkl\n",
      "84700 / 84710\n",
      "0.6422, 52797 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-aotm2011-samples-C-0.3-1-1-p-5.pkl\n",
      "84700 / 84710\n",
      "0.6413, 52797 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-aotm2011-samples-C-1-1-1-p-1.pkl\n",
      "84700 / 84710\n",
      "0.6564, 52797 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-aotm2011-samples-C-1-1-1-p-2.pkl\n",
      "84700 / 84710\n",
      "0.6572, 52797 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-aotm2011-samples-C-1-1-1-p-3.pkl\n",
      "84700 / 84710\n",
      "0.6571, 52797 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-aotm2011-samples-C-3-1-1-p-2.pkl\n",
      "84700 / 84710\n",
      "0.6579, 52797 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-aotm2011-samples-C-3-1-1-p-3.pkl\n",
      "84700 / 84710\n",
      "0.6583, 52797 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-aotm2011-samples-C-3-1-1-p-4.pkl\n",
      "84700 / 84710\n",
      "0.6576, 52797 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-aotm2011-samples-C-30-1-1-p-3.pkl\n",
      "84700 / 84710\n",
      "0.6579, 52797 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-aotm2011-samples-C-30-1-1-p-4.pkl\n",
      "84700 / 84710\n",
      "0.6585, 52797 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-aotm2011-samples-C-100-1-1-p-1.pkl\n",
      "84700 / 84710\n",
      "0.6585, 52797 / 84710\n"
     ]
    }
   ],
   "source": [
    "for c1 in C1:\n",
    "    if c1 == 0.03: continue\n",
    "    for p in P:\n",
    "        fname = os.path.join(data_dir, 'mlr_samples/mlr-aotm2011-samples-C-%g-1-1-p-%d.pkl' % (c1, p))\n",
    "        if not os.path.exists(fname):continue\n",
    "        print(fname)\n",
    "        mlr = pkl.load(open(fname, 'rb'))\n",
    "        aucs_mlr = calc_auc_w(W=mlr.W, b=mlr.b, X=X_test, Y=Y_test)\n",
    "        print('\\n%.5f, %d / %d' % (np.mean(aucs_mlr), len(aucs_mlr), Y_test.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss: sample weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-0.01-1-1-1-latest.npy\n",
      "84700 / 84710\n",
      "0.5104, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-0.01-1-1-2-latest.npy\n",
      "84700 / 84710\n",
      "0.4827, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-0.01-1-1-3-latest.npy\n",
      "84700 / 84710\n",
      "0.4734, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-0.01-1-1-4-latest.npy\n",
      "84700 / 84710\n",
      "0.4866, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-0.01-1-1-5-latest.npy\n",
      "84700 / 84710\n",
      "0.4948, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-0.01-1-1-6-latest.npy\n",
      "84700 / 84710\n",
      "0.4815, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-0.03-1-1-1-latest.npy\n",
      "84700 / 84710\n",
      "0.5480, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-0.03-1-1-2-latest.npy\n",
      "84700 / 84710\n",
      "0.5836, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-0.03-1-1-3-latest.npy\n",
      "84700 / 84710\n",
      "0.5859, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-0.03-1-1-4-latest.npy\n",
      "84700 / 84710\n",
      "0.5838, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-0.03-1-1-5-latest.npy\n",
      "84700 / 84710\n",
      "0.5915, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-0.03-1-1-6-latest.npy\n",
      "84700 / 84710\n",
      "0.5951, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-0.1-1-1-1-latest.npy\n",
      "84700 / 84710\n",
      "0.6066, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-0.1-1-1-2-latest.npy\n",
      "84700 / 84710\n",
      "0.5992, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-0.1-1-1-3-latest.npy\n",
      "84700 / 84710\n",
      "0.6021, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-0.1-1-1-4-latest.npy\n",
      "84700 / 84710\n",
      "0.5980, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-0.1-1-1-5-latest.npy\n",
      "84700 / 84710\n",
      "0.5999, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-0.1-1-1-6-latest.npy\n",
      "84700 / 84710\n",
      "0.6048, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-0.3-1-1-1-latest.npy\n",
      "84700 / 84710\n",
      "0.6374, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-0.3-1-1-2-latest.npy\n",
      "84700 / 84710\n",
      "0.6357, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-0.3-1-1-3-latest.npy\n",
      "84700 / 84710\n",
      "0.6355, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-0.3-1-1-4-latest.npy\n",
      "84700 / 84710\n",
      "0.6371, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-0.3-1-1-5-latest.npy\n",
      "84700 / 84710\n",
      "0.6361, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-0.3-1-1-6-latest.npy\n",
      "84700 / 84710\n",
      "0.6342, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-1-1-1-1-latest.npy\n",
      "84700 / 84710\n",
      "0.6493, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-1-1-1-2-latest.npy\n",
      "84700 / 84710\n",
      "0.6499, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-1-1-1-3-latest.npy\n",
      "84700 / 84710\n",
      "0.6488, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-1-1-1-4-latest.npy\n",
      "84700 / 84710\n",
      "0.6490, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-1-1-1-5-latest.npy\n",
      "84700 / 84710\n",
      "0.6491, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-1-1-1-6-latest.npy\n",
      "84700 / 84710\n",
      "0.6488, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-3-1-1-1-latest.npy\n",
      "84700 / 84710\n",
      "0.6506, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-3-1-1-2-latest.npy\n",
      "84700 / 84710\n",
      "0.6503, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-3-1-1-3-latest.npy\n",
      "84700 / 84710\n",
      "0.6495, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-3-1-1-4-latest.npy\n",
      "84700 / 84710\n",
      "0.6504, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-3-1-1-5-latest.npy\n",
      "84700 / 84710\n",
      "0.6496, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-3-1-1-6-latest.npy\n",
      "84700 / 84710\n",
      "0.6504, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-10-1-1-1-latest.npy\n",
      "84700 / 84710\n",
      "0.6504, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-10-1-1-2-latest.npy\n",
      "84700 / 84710\n",
      "0.6507, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-10-1-1-3-latest.npy\n",
      "84700 / 84710\n",
      "0.6510, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-10-1-1-4-latest.npy\n",
      "84700 / 84710\n",
      "0.6507, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-10-1-1-5-latest.npy\n",
      "84700 / 84710\n",
      "0.6506, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-10-1-1-6-latest.npy\n",
      "84700 / 84710\n",
      "0.6506, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-30-1-1-1-latest.npy\n",
      "84700 / 84710\n",
      "0.6510, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-30-1-1-2-latest.npy\n",
      "84700 / 84710\n",
      "0.6506, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-30-1-1-3-latest.npy\n",
      "84700 / 84710\n",
      "0.6508, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-30-1-1-4-latest.npy\n",
      "84700 / 84710\n",
      "0.6506, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-30-1-1-5-latest.npy\n",
      "84700 / 84710\n",
      "0.6502, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-30-1-1-6-latest.npy\n",
      "84700 / 84710\n",
      "0.6502, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-100-1-1-1-latest.npy\n",
      "84700 / 84710\n",
      "0.6506, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-100-1-1-2-latest.npy\n",
      "84700 / 84710\n",
      "0.6503, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-100-1-1-3-latest.npy\n",
      "84700 / 84710\n",
      "0.6509, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-100-1-1-4-latest.npy\n",
      "84700 / 84710\n",
      "0.6510, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-100-1-1-5-latest.npy\n",
      "84700 / 84710\n",
      "0.6499, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-100-1-1-6-latest.npy\n",
      "84700 / 84710\n",
      "0.6511, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-300-1-1-1-latest.npy\n",
      "84700 / 84710\n",
      "0.6503, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-300-1-1-2-latest.npy\n",
      "84700 / 84710\n",
      "0.6500, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-300-1-1-3-latest.npy\n",
      "84700 / 84710\n",
      "0.6502, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-300-1-1-4-latest.npy\n",
      "84700 / 84710\n",
      "0.6505, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-300-1-1-5-latest.npy\n",
      "84700 / 84710\n",
      "0.6512, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-300-1-1-6-latest.npy\n",
      "84700 / 84710\n",
      "0.6507, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-1000-1-1-1-latest.npy\n",
      "84700 / 84710\n",
      "0.6505, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-1000-1-1-2-latest.npy\n",
      "84700 / 84710\n",
      "0.6507, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-1000-1-1-3-latest.npy\n",
      "84700 / 84710\n",
      "0.6507, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-1000-1-1-4-latest.npy\n",
      "84700 / 84710\n",
      "0.6506, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-1000-1-1-5-latest.npy\n",
      "84700 / 84710\n",
      "0.6510, 37886 / 84710\n",
      "data/aotm-2011/setting1/mlr_samples/mlr-N-samples-1000-1-1-6-latest.npy\n",
      "84700 / 84710\n",
      "0.6502, 37886 / 84710\n"
     ]
    }
   ],
   "source": [
    "D = X_train.shape[1]\n",
    "K = Y_train.shape[1]\n",
    "for c1 in C1:\n",
    "    for p in P:\n",
    "        fname = os.path.join(data_dir, 'mlr_samples/mlr-N-samples-%g-1-1-%d-latest.npy' % (c1, p))\n",
    "        if not os.path.exists(fname):continue\n",
    "        print(fname)\n",
    "        w = np.load(fname)\n",
    "        aucs = calc_auc_w(W=w[1:].reshape(K, D), b=w[0], X=X_dev, Y=Y_dev)\n",
    "        print('\\n%.5f, %d / %d\\n' % (np.mean(aucs), len(aucs), Y_dev.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose: mlr_samples/mlr-N-samples-30-1-1-1-latest.npy\n"
     ]
    }
   ],
   "source": [
    "print('Choose: mlr_samples/mlr-N-samples-30-1-1-1-latest.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss: labels weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-0.01-1-1-1-latest.npy\n",
      "84700 / 84710\n",
      "0.50917, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-0.01-1-1-2-latest.npy\n",
      "84700 / 84710\n",
      "0.52261, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-0.01-1-1-3-latest.npy\n",
      "84700 / 84710\n",
      "0.51337, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-0.01-1-1-4-latest.npy\n",
      "84700 / 84710\n",
      "0.47382, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-0.01-1-1-5-latest.npy\n",
      "84700 / 84710\n",
      "0.51257, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-0.01-1-1-6-latest.npy\n",
      "84700 / 84710\n",
      "0.51712, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-0.03-1-1-1-latest.npy\n",
      "84700 / 84710\n",
      "0.54490, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-0.03-1-1-2-latest.npy\n",
      "84700 / 84710\n",
      "0.59225, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-0.03-1-1-3-latest.npy\n",
      "84700 / 84710\n",
      "0.59218, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-0.03-1-1-4-latest.npy\n",
      "84700 / 84710\n",
      "0.59361, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-0.03-1-1-5-latest.npy\n",
      "84700 / 84710\n",
      "0.59466, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-0.03-1-1-6-latest.npy\n",
      "84700 / 84710\n",
      "0.59130, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-0.1-1-1-1-latest.npy\n",
      "84700 / 84710\n",
      "0.60103, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-0.1-1-1-2-latest.npy\n",
      "84700 / 84710\n",
      "0.60204, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-0.1-1-1-3-latest.npy\n",
      "84700 / 84710\n",
      "0.59542, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-0.1-1-1-4-latest.npy\n",
      "84700 / 84710\n",
      "0.60101, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-0.1-1-1-5-latest.npy\n",
      "84700 / 84710\n",
      "0.59957, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-0.1-1-1-6-latest.npy\n",
      "84700 / 84710\n",
      "0.59970, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-0.3-1-1-1-latest.npy\n",
      "84700 / 84710\n",
      "0.62892, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-0.3-1-1-2-latest.npy\n",
      "84700 / 84710\n",
      "0.62884, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-0.3-1-1-3-latest.npy\n",
      "84700 / 84710\n",
      "0.62898, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-0.3-1-1-4-latest.npy\n",
      "84700 / 84710\n",
      "0.62875, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-0.3-1-1-5-latest.npy\n",
      "84700 / 84710\n",
      "0.62980, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-0.3-1-1-6-latest.npy\n",
      "84700 / 84710\n",
      "0.62477, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-1-1-1-1-latest.npy\n",
      "84700 / 84710\n",
      "0.63456, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-1-1-1-2-latest.npy\n",
      "84700 / 84710\n",
      "0.63457, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-1-1-1-3-latest.npy\n",
      "84700 / 84710\n",
      "0.63490, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-1-1-1-4-latest.npy\n",
      "84700 / 84710\n",
      "0.63483, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-1-1-1-5-latest.npy\n",
      "84700 / 84710\n",
      "0.63389, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-1-1-1-6-latest.npy\n",
      "84700 / 84710\n",
      "0.63432, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-3-1-1-1-latest.npy\n",
      "84700 / 84710\n",
      "0.63488, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-3-1-1-2-latest.npy\n",
      "84700 / 84710\n",
      "0.63441, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-3-1-1-3-latest.npy\n",
      "84700 / 84710\n",
      "0.63500, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-3-1-1-4-latest.npy\n",
      "84700 / 84710\n",
      "0.63469, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-3-1-1-5-latest.npy\n",
      "84700 / 84710\n",
      "0.63513, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-3-1-1-6-latest.npy\n",
      "84700 / 84710\n",
      "0.63440, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-10-1-1-1-latest.npy\n",
      "84700 / 84710\n",
      "0.63488, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-10-1-1-2-latest.npy\n",
      "84700 / 84710\n",
      "0.63451, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-10-1-1-3-latest.npy\n",
      "84700 / 84710\n",
      "0.63434, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-10-1-1-4-latest.npy\n",
      "84700 / 84710\n",
      "0.63535, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-10-1-1-5-latest.npy\n",
      "84700 / 84710\n",
      "0.63497, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-10-1-1-6-latest.npy\n",
      "84700 / 84710\n",
      "0.63469, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-30-1-1-1-latest.npy\n",
      "84700 / 84710\n",
      "0.63404, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-30-1-1-2-latest.npy\n",
      "84700 / 84710\n",
      "0.63504, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-30-1-1-3-latest.npy\n",
      "84700 / 84710\n",
      "0.63553, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-30-1-1-4-latest.npy\n",
      "84700 / 84710\n",
      "0.63519, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-30-1-1-5-latest.npy\n",
      "84700 / 84710\n",
      "0.63490, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-30-1-1-6-latest.npy\n",
      "84700 / 84710\n",
      "0.63469, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-100-1-1-1-latest.npy\n",
      "84700 / 84710\n",
      "0.63485, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-100-1-1-2-latest.npy\n",
      "84700 / 84710\n",
      "0.63430, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-100-1-1-3-latest.npy\n",
      "84700 / 84710\n",
      "0.63434, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-100-1-1-4-latest.npy\n",
      "84700 / 84710\n",
      "0.63495, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-100-1-1-5-latest.npy\n",
      "84700 / 84710\n",
      "0.63460, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-100-1-1-6-latest.npy\n",
      "84700 / 84710\n",
      "0.63497, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-300-1-1-1-latest.npy\n",
      "84700 / 84710\n",
      "0.63504, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-300-1-1-2-latest.npy\n",
      "84700 / 84710\n",
      "0.63535, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-300-1-1-3-latest.npy\n",
      "84700 / 84710\n",
      "0.63482, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-300-1-1-4-latest.npy\n",
      "84700 / 84710\n",
      "0.63515, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-300-1-1-5-latest.npy\n",
      "84700 / 84710\n",
      "0.63479, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-300-1-1-6-latest.npy\n",
      "84700 / 84710\n",
      "0.63400, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-1000-1-1-1-latest.npy\n",
      "84700 / 84710\n",
      "0.63438, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-1000-1-1-2-latest.npy\n",
      "84700 / 84710\n",
      "0.63542, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-1000-1-1-3-latest.npy\n",
      "84700 / 84710\n",
      "0.63420, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-1000-1-1-4-latest.npy\n",
      "84700 / 84710\n",
      "0.63459, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-1000-1-1-5-latest.npy\n",
      "84700 / 84710\n",
      "0.63465, 37886 / 84710\n",
      "\n",
      "data/aotm-2011/setting1/mlr_labels/mlr-N-labels-1000-1-1-6-latest.npy\n",
      "84700 / 84710\n",
      "0.63513, 37886 / 84710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "D = X_train.shape[1]\n",
    "K = Y_train.shape[1]\n",
    "for c1 in C1:\n",
    "    for p in P:\n",
    "        fname = os.path.join(data_dir, 'mlr_labels/mlr-N-labels-%g-1-1-%d-latest.npy' % (c1, p))\n",
    "        if not os.path.exists(fname):continue\n",
    "        print(fname)\n",
    "        w = np.load(fname)\n",
    "        aucs = calc_auc_w(W=w[1:].reshape(K, D), b=w[0], X=X_dev, Y=Y_dev)\n",
    "        print('\\n%.5f, %d / %d\\n' % (np.mean(aucs), len(aucs), Y_dev.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose: data/aotm-2011/setting1/mlr_labels/mlr-N-labels-30-1-1-3-latest.npy\n"
     ]
    }
   ],
   "source": [
    "print('Choose:', 'data/aotm-2011/setting1/mlr_labels/mlr-N-labels-30-1-1-3-latest.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BR for new song recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'data/aotm-2011/setting1'\n",
    "br_name = 'br1'\n",
    "br_dir = os.path.join(base_dir, br_name)\n",
    "fsplit = os.path.join(br_dir, br_name + '.split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test  = pkl.load(gzip.open(os.path.join(base_dir, 'X_test.pkl.gz'), 'rb'))\n",
    "Y_test  = pkl.load(gzip.open(os.path.join(base_dir, 'Y_test.pkl.gz'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aucs = []\n",
    "with open(fsplit, 'r') as fd:\n",
    "    for line in fd:\n",
    "        start, end = line.strip().split(' ')\n",
    "        print(start, end)\n",
    "        fname = os.path.join(br_dir, 'br1-aotm2011-%s-%s.pkl' % (start, end))\n",
    "        #print(fname)\n",
    "        #break\n",
    "        br = pkl.load(open(fname, 'rb'))\n",
    "        pred = br.predict(X_test)\n",
    "        Y_part = Y_test[:, int(start):int(end)]\n",
    "        nzcol = np.nonzero(np.sum(Y_part, axis=0))[1]\n",
    "        #print(np.sum(Y_part, axis=0))\n",
    "        #print('-'*20)\n",
    "        #print(nzcol)\n",
    "        auc, npl = calc_auc_pl(Y_part[:, nzcol].toarray(), pred[:, nzcol])\n",
    "        aucs.append((auc, npl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_auc = np.sum([np.prod(t) for t in aucs]) / np.sum([t[1] for t in aucs])\n",
    "print(mean_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hit rate curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hitrates = []  # [(hitrates, ncols)]\n",
    "with open(fsplit, 'r') as fd:\n",
    "    for line in fd:\n",
    "        start, end = line.strip().split(' ')\n",
    "        print(start, end)\n",
    "        fname = os.path.join(br_dir, 'br1-aotm2011-%s-%s.pkl' % (start, end))\n",
    "        br = pkl.load(open(fname, 'rb'))\n",
    "        pred = br.predict(X_test)\n",
    "        Y_part = Y_test[:, int(start):int(end)]\n",
    "        hitrates.append(calc_hitrate_pl(Y_part, pred, tops=TOPs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_hitrate_dict = dict()\n",
    "denom = np.sum([t[1] for t in hitrates])\n",
    "for i in range(len(tops)):\n",
    "    mean_hitrate_dict[tops[i]] = np.sum([t[0][i] * t[1] for t in hitrates]) / denom\n",
    "#print(mean_hitrate_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = sorted(mean_hitrate_dict.keys())\n",
    "yy = [mean_hitrate_dict[top] for top in xx]\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(xx, yy, ls='--', marker='o')\n",
    "ax.set_xlabel('Top-N')\n",
    "ax.set_ylabel('Hit Rate')\n",
    "ax.set_xscale('log')\n",
    "#ax.set_xlim(0, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br1_perf = {'aotm2011': {'Test': {'AUC': mean_auc, 'HitRate': mean_hitrate_dict}}}\n",
    "br1_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aotm2011': {'Test': {'AUC': 0.6126755471495918,\n",
       "   'HitRate': {5: 0.0014351505245874243,\n",
       "    10: 0.0032520941954716606,\n",
       "    20: 0.005910632368811811,\n",
       "    30: 0.008263519625670885,\n",
       "    50: 0.012301003887173556,\n",
       "    100: 0.02061297801493865,\n",
       "    200: 0.03507022705138029,\n",
       "    300: 0.04729167496261769,\n",
       "    500: 0.0699152500877554,\n",
       "    1000: 0.113767123918867,\n",
       "    3000: 0.25071657862090035,\n",
       "    10000: 0.5947338565933447,\n",
       "    22886: 1.0}}}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fperf = os.path.join(base_dir, 'perf-' + br_name + '.pkl')\n",
    "#pkl.dump(br1_perf, open(fperf, 'wb'))\n",
    "pkl.load(open(fperf, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BR for playlist augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'data/aotm-2011/setting2'\n",
    "br_name = 'br2'\n",
    "br_dir = os.path.join(base_dir, br_name)\n",
    "fsplit = os.path.join(br_dir, br_name + '.split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pkl.load(gzip.open(os.path.join(base_dir, 'X_train.pkl.gz'), 'rb'))\n",
    "Y = pkl.load(gzip.open(os.path.join(base_dir, 'Y.pkl.gz'), 'rb'))\n",
    "PU_test = pkl.load(gzip.open(os.path.join(base_dir, 'PU_test.pkl.gz'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114428, 84710)\n",
      "(114428, 16942)\n"
     ]
    }
   ],
   "source": [
    "print(Y.shape)\n",
    "print(PU_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[3, 5, 3, ..., 6, 6, 5]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(PU_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114428, 16942)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[ 6, 10,  6, ..., 12, 11, 10]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test = Y[:, -PU_test.shape[1]:]\n",
    "print(Y_test.shape)\n",
    "Y_test.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(PU_test[:,0:10].toarray()[:,0] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aucs_pla = []\n",
    "hitrates_pla = {top: [] for top in TOPs}\n",
    "with open(fsplit, 'r') as fd:\n",
    "    for line in fd:\n",
    "        start, end = line.strip().split(' ')\n",
    "        print(start, end)\n",
    "        fname = os.path.join(br_dir, br_name + '-aotm2011-%s-%s.pkl' % (start, end))\n",
    "        br = pkl.load(open(fname, 'rb'))\n",
    "        Y_pred = br.predict(X)\n",
    "        Y_part = Y_test[:, int(start):int(end)]\n",
    "        PU_part = PU_test[:, int(start):int(end)]\n",
    "        assert Y_part.shape == PU_part.shape == Y_pred.shape\n",
    "        if issparse(Y_part):\n",
    "            Y_part = Y_part.toarray()\n",
    "        if issparse(PU_part):\n",
    "            PU_part = PU_part.toarray()\n",
    "        for j in range(Y_part.shape[1]):\n",
    "            indices = np.where(0 == PU_part[:, j])[0]\n",
    "            y_true = Y_part[indices, j].reshape(-1)\n",
    "            y_pred = Y_pred[indices, j].reshape(-1)\n",
    "            #print(y_true.shape)\n",
    "            #print(y_pred.shape)\n",
    "            \n",
    "            # auc\n",
    "            aucs_pla.append(roc_auc_score(y_true, y_pred))\n",
    "            \n",
    "            # hitrates\n",
    "            sortix = np.argsort(-y_pred)\n",
    "            npos = np.sum(y_true)\n",
    "            for top in TOPs:\n",
    "                topix = sortix[:top]\n",
    "                hitrates_pla[top].append(np.sum(y_true[topix]) / npos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_auc_pla = np.mean(aucs_pla)\n",
    "print(mean_auc_pla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aucs_pla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hitrates_pla.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_hitrates = {top: np.mean(hitrates_pla[top]) for top in hitrates_pla}\n",
    "#mean_hitrates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br2_perf = {'aotm2011': {'Test': {'AUC': mean_auc_pla, 'HitRate': mean_hitrates}}}\n",
    "br2_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/aotm-2011/setting2/perf-br2.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'aotm2011': {'Test': {'AUC': 0.627090999140205,\n",
       "   'HitRate': {5: 0.001587976034357113,\n",
       "    10: 0.0027657937111123417,\n",
       "    20: 0.004221387003560786,\n",
       "    30: 0.005599440245325515,\n",
       "    50: 0.007675543780819913,\n",
       "    100: 0.011617975430715435,\n",
       "    200: 0.018224322755395896,\n",
       "    300: 0.02354979472537126,\n",
       "    500: 0.03311129557353699,\n",
       "    1000: 0.05200617868578454,\n",
       "    3000: 0.10121437974550149,\n",
       "    10000: 0.21445432546668075,\n",
       "    114428: 1.0}}}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fperf_pla = os.path.join(base_dir, 'perf-' + br_name + '.pkl')\n",
    "print(fperf_pla)\n",
    "#pkl.dump(br2_perf, open(fperf_pla, 'wb'))\n",
    "pkl.load(open(fperf_pla, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popularity based recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists2 = pkl.load(gzip.open(os.path.join(base_dir, 'playlists_train_dev_test_s2.pkl.gz'), 'rb'))\n",
    "song2pop = pkl.load(gzip.open('data/aotm-2011/song2pop.pkl.gz', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_songs = pkl.load(gzip.open('data/aotm-2011/all_songs.pkl.gz', 'rb'))\n",
    "index2song = {ix: sid for ix, sid in enumerate(all_songs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song2pop_test = song2pop.copy()\n",
    "for ppl in playlists2['test_playlists_held']:\n",
    "    for sid in ppl:\n",
    "        song2pop_test[sid] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs_pop = []\n",
    "hitrates_pop = {top: [] for top in TOPs}\n",
    "\n",
    "assert Y_test.shape == PU_test.shape\n",
    "for j in range(Y_test.shape[1]):\n",
    "    if (j+1) % 10 == 0:\n",
    "        sys.stdout.write('\\r%d / %d' % (j+1, Y_test.shape[1]))\n",
    "        sys.stdout.flush()\n",
    "    y1 = Y_test[:, j].toarray().reshape(-1)\n",
    "    y2 = PU_test[:, j].toarray().reshape(-1)\n",
    "    indices = np.where(0 == y2)[0]\n",
    "    y_true = y1[indices]\n",
    "    y_pred = np.array([song2pop_test[index2song[ix]] for ix in indices])\n",
    "    \n",
    "    # auc\n",
    "    aucs_pop.append(roc_auc_score(y_true, y_pred))\n",
    "    \n",
    "    # hitrates\n",
    "    sortix = np.argsort(-y_pred)\n",
    "    npos = np.sum(y_true)\n",
    "    for top in TOPs:\n",
    "        topix = sortix[:top]\n",
    "        hitrates_pop[top].append(np.sum(y_true[topix]) / npos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_perf = {'aotm2011': {'Test': {'AUC': np.mean(aucs_pop), \n",
    "                                  'HitRate': {top: np.mean(hitrates_pop[top]) for top in hitrates_pop}}}}\n",
    "pop_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fperf_pop = os.path.join(base_dir, 'perf-pop.pkl')\n",
    "print(fperf_pop)\n",
    "pkl.dump(pop_perf, open(fperf_pop, 'wb'))\n",
    "pkl.load(open(fperf_pop, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pkl.load(gzip.open(os.path.join(base_dir, 'X_train.pkl.gz'), 'rb'))\n",
    "Y_train_dev = pkl.load(gzip.open(os.path.join(base_dir, 'Y_train_dev.pkl.gz'), 'rb'))\n",
    "PU_dev = pkl.load(gzip.open(os.path.join(base_dir, 'PU_dev.pkl.gz'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114428, 8471)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[ 7,  7,  5, ..., 12, 11, 10]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_dev = Y[:, -PU_dev.shape[1]:]\n",
    "print(Y_dev.shape)\n",
    "Y_dev.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCMLC(C1=0.03, C2=0.1, C3=0.1, p=3.0,\n",
      "   similarMat=<84710x84710 sparse matrix of type '<class 'numpy.bool_'>'\n",
      "\twith 5111348 stored elements in Compressed Sparse Row format>,\n",
      "   userwiseReg=True, weighting='both')\n",
      "8470 / 84710.5029424167707581 8471\n",
      "PCMLC(C1=0.03, C2=30.0, C3=3.0, p=3.0,\n",
      "   similarMat=<84710x84710 sparse matrix of type '<class 'numpy.bool_'>'\n",
      "\twith 5111348 stored elements in Compressed Sparse Row format>,\n",
      "   userwiseReg=True, weighting='both')\n",
      "8470 / 84710.502459353179211 8471\n",
      "PCMLC(C1=0.1, C2=0.3, C3=300.0, p=2.0,\n",
      "   similarMat=<84710x84710 sparse matrix of type '<class 'numpy.bool_'>'\n",
      "\twith 5111348 stored elements in Compressed Sparse Row format>,\n",
      "   userwiseReg=True, weighting='both')\n",
      "8470 / 84710.5035719254047036 8471\n",
      "PCMLC(C1=0.1, C2=30.0, C3=0.03, p=6.0,\n",
      "   similarMat=<84710x84710 sparse matrix of type '<class 'numpy.bool_'>'\n",
      "\twith 5111348 stored elements in Compressed Sparse Row format>,\n",
      "   userwiseReg=True, weighting='both')\n",
      "8470 / 84710.4984555290566592 8471\n",
      "PCMLC(C1=0.3, C2=0.03, C3=0.1, p=5.0,\n",
      "   similarMat=<84710x84710 sparse matrix of type '<class 'numpy.bool_'>'\n",
      "\twith 5111348 stored elements in Compressed Sparse Row format>,\n",
      "   userwiseReg=True, weighting='both')\n",
      "8470 / 84710.5047973022147543 8471\n",
      "PCMLC(C1=0.3, C2=30.0, C3=0.3, p=2.0,\n",
      "   similarMat=<84710x84710 sparse matrix of type '<class 'numpy.bool_'>'\n",
      "\twith 5111348 stored elements in Compressed Sparse Row format>,\n",
      "   userwiseReg=True, weighting='both')\n",
      "8470 / 84710.5027027963348707 8471\n",
      "PCMLC(C1=1.0, C2=0.03, C3=3.0, p=1.0,\n",
      "   similarMat=<84710x84710 sparse matrix of type '<class 'numpy.bool_'>'\n",
      "\twith 5111348 stored elements in Compressed Sparse Row format>,\n",
      "   userwiseReg=True, weighting='both')\n",
      "8470 / 84710.5093990555489393 8471\n",
      "PCMLC(C1=3.0, C2=10.0, C3=100.0, p=1.0,\n",
      "   similarMat=<84710x84710 sparse matrix of type '<class 'numpy.bool_'>'\n",
      "\twith 5111348 stored elements in Compressed Sparse Row format>,\n",
      "   userwiseReg=True, weighting='both')\n",
      "8470 / 84710.506131690938176 8471\n",
      "PCMLC(C1=3.0, C2=10.0, C3=300.0, p=1.0,\n",
      "   similarMat=<84710x84710 sparse matrix of type '<class 'numpy.bool_'>'\n",
      "\twith 5111348 stored elements in Compressed Sparse Row format>,\n",
      "   userwiseReg=True, weighting='both')\n",
      "8470 / 84710.505768349081465 8471\n",
      "PCMLC(C1=3.0, C2=100.0, C3=3.0, p=5.0,\n",
      "   similarMat=<84710x84710 sparse matrix of type '<class 'numpy.bool_'>'\n",
      "\twith 5111348 stored elements in Compressed Sparse Row format>,\n",
      "   userwiseReg=True, weighting='both')\n",
      "8470 / 84710.5052751219255063 8471\n",
      "PCMLC(C1=10.0, C2=0.03, C3=0.3, p=2.0,\n",
      "   similarMat=<84710x84710 sparse matrix of type '<class 'numpy.bool_'>'\n",
      "\twith 5111348 stored elements in Compressed Sparse Row format>,\n",
      "   userwiseReg=True, weighting='both')\n",
      "8470 / 84710.5116172608315307 8471\n",
      "PCMLC(C1=10.0, C2=1.0, C3=0.03, p=6.0,\n",
      "   similarMat=<84710x84710 sparse matrix of type '<class 'numpy.bool_'>'\n",
      "\twith 5111348 stored elements in Compressed Sparse Row format>,\n",
      "   userwiseReg=True, weighting='both')\n",
      "8470 / 84710.5013831667033799 8471\n",
      "PCMLC(C1=30.0, C2=0.01, C3=0.1, p=4.0,\n",
      "   similarMat=<84710x84710 sparse matrix of type '<class 'numpy.bool_'>'\n",
      "\twith 5111348 stored elements in Compressed Sparse Row format>,\n",
      "   userwiseReg=True, weighting='both')\n",
      "8470 / 84710.5132504988791505 8471\n",
      "PCMLC(C1=30.0, C2=0.1, C3=30.0, p=6.0,\n",
      "   similarMat=<84710x84710 sparse matrix of type '<class 'numpy.bool_'>'\n",
      "\twith 5111348 stored elements in Compressed Sparse Row format>,\n",
      "   userwiseReg=True, weighting='both')\n",
      "8470 / 84710.5087143785703871 8471\n",
      "PCMLC(C1=30.0, C2=0.3, C3=1.0, p=1.0,\n",
      "   similarMat=<84710x84710 sparse matrix of type '<class 'numpy.bool_'>'\n",
      "\twith 5111348 stored elements in Compressed Sparse Row format>,\n",
      "   userwiseReg=True, weighting='both')\n",
      "8470 / 84710.5061929721876771 8471\n",
      "PCMLC(C1=30.0, C2=1.0, C3=0.03, p=1.0,\n",
      "   similarMat=<84710x84710 sparse matrix of type '<class 'numpy.bool_'>'\n",
      "\twith 5111348 stored elements in Compressed Sparse Row format>,\n",
      "   userwiseReg=True, weighting='both')\n",
      "8470 / 84710.49815681963656727 8471\n",
      "PCMLC(C1=30.0, C2=100.0, C3=3.0, p=4.0,\n",
      "   similarMat=<84710x84710 sparse matrix of type '<class 'numpy.bool_'>'\n",
      "\twith 5111348 stored elements in Compressed Sparse Row format>,\n",
      "   userwiseReg=True, weighting='both')\n",
      "8470 / 84710.5034530213853349 8471\n",
      "PCMLC(C1=100.0, C2=0.1, C3=3.0, p=6.0,\n",
      "   similarMat=<84710x84710 sparse matrix of type '<class 'numpy.bool_'>'\n",
      "\twith 5111348 stored elements in Compressed Sparse Row format>,\n",
      "   userwiseReg=True, weighting='both')\n",
      "8470 / 84710.5087769807733808 8471\n",
      "PCMLC(C1=100.0, C2=0.3, C3=300.0, p=1.0,\n",
      "   similarMat=<84710x84710 sparse matrix of type '<class 'numpy.bool_'>'\n",
      "\twith 5111348 stored elements in Compressed Sparse Row format>,\n",
      "   userwiseReg=True, weighting='both')\n",
      "8470 / 84710.5069560061507581 8471\n",
      "PCMLC(C1=100.0, C2=3.0, C3=1000.0, p=2.0,\n",
      "   similarMat=<84710x84710 sparse matrix of type '<class 'numpy.bool_'>'\n",
      "\twith 5111348 stored elements in Compressed Sparse Row format>,\n",
      "   userwiseReg=True, weighting='both')\n",
      "8470 / 84710.505822100331194 8471\n",
      "PCMLC(C1=300.0, C2=10.0, C3=10.0, p=3.0,\n",
      "   similarMat=<84710x84710 sparse matrix of type '<class 'numpy.bool_'>'\n",
      "\twith 5111348 stored elements in Compressed Sparse Row format>,\n",
      "   userwiseReg=True, weighting='both')\n",
      "8470 / 84710.5044825221131157 8471\n",
      "PCMLC(C1=300.0, C2=30.0, C3=3.0, p=2.0,\n",
      "   similarMat=<84710x84710 sparse matrix of type '<class 'numpy.bool_'>'\n",
      "\twith 5111348 stored elements in Compressed Sparse Row format>,\n",
      "   userwiseReg=True, weighting='both')\n",
      "8470 / 84710.5032582324318519 8471\n",
      "PCMLC(C1=300.0, C2=30.0, C3=100.0, p=5.0,\n",
      "   similarMat=<84710x84710 sparse matrix of type '<class 'numpy.bool_'>'\n",
      "\twith 5111348 stored elements in Compressed Sparse Row format>,\n",
      "   userwiseReg=True, weighting='both')\n",
      "8470 / 84710.5058775786221787 8471\n",
      "PCMLC(C1=1000.0, C2=30.0, C3=100.0, p=3.0,\n",
      "   similarMat=<84710x84710 sparse matrix of type '<class 'numpy.bool_'>'\n",
      "\twith 5111348 stored elements in Compressed Sparse Row format>,\n",
      "   userwiseReg=True, weighting='both')\n",
      "8470 / 84710.5058941273236517 8471\n"
     ]
    }
   ],
   "source": [
    "C1 = [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100, 300, 1000]\n",
    "C2 = [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100]\n",
    "C3 = [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100, 300, 1000]\n",
    "P = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "offset = Y_train_dev.shape[1] - PU_dev.shape[1]\n",
    "for c1 in C1:\n",
    "    for c2 in C2:\n",
    "        for c3 in C3:\n",
    "            for p in P:\n",
    "                fname = os.path.join(base_dir, 'pla-aotm2011-C-%g-%g-%g-p-%d.pkl' % (c1, c2, c3, p))\n",
    "                if not os.path.exists(fname): continue\n",
    "                pla = pkl.load(open(fname, 'rb'))\n",
    "                W = pla.W\n",
    "                b = pla.b\n",
    "                print(pla)\n",
    "                aucs = []\n",
    "                for j in range(Y_dev.shape[1]):\n",
    "                    if (j+1) % 10 == 0:\n",
    "                        sys.stdout.write('\\r%d / %d' % (j+1, Y_dev.shape[1]))\n",
    "                        sys.stdout.flush()\n",
    "                    y1 = Y_dev[:, j].toarray().reshape(-1)\n",
    "                    y2 = PU_dev[:, j].toarray().reshape(-1)\n",
    "                    indices = np.where(0 == y2)[0]\n",
    "                    y_true = y1[indices]\n",
    "                    wj = W[j + offset, :].reshape(-1)\n",
    "                    y_pred = (np.dot(X, wj) + b)[indices]\n",
    "                    aucs.append(roc_auc_score(y_true, y_pred))\n",
    "                print(np.mean(aucs), len(aucs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCMLC(C1=0.1, C2=0.01, C3=1000.0, p=4.0,\n",
      "   similarMat=<84710x84710 sparse matrix of type '<class 'numpy.bool_'>'\n",
      "\twith 5111348 stored elements in Compressed Sparse Row format>,\n",
      "   userwiseReg=False, weighting='both')\n",
      "8470 / 8471\n",
      "0.50469, 8471\n",
      "PCMLC(C1=1.0, C2=0.01, C3=1000.0, p=3.0,\n",
      "   similarMat=<84710x84710 sparse matrix of type '<class 'numpy.bool_'>'\n",
      "\twith 5111348 stored elements in Compressed Sparse Row format>,\n",
      "   userwiseReg=False, weighting='both')\n",
      "8470 / 8471\n",
      "0.50751, 8471\n",
      "PCMLC(C1=10.0, C2=10.0, C3=1000.0, p=6.0,\n",
      "   similarMat=<84710x84710 sparse matrix of type '<class 'numpy.bool_'>'\n",
      "\twith 5111348 stored elements in Compressed Sparse Row format>,\n",
      "   userwiseReg=False, weighting='both')\n",
      "8470 / 8471\n",
      "0.50449, 8471\n",
      "PCMLC(C1=30.0, C2=0.1, C3=30.0, p=5.0,\n",
      "   similarMat=<84710x84710 sparse matrix of type '<class 'numpy.bool_'>'\n",
      "\twith 5111348 stored elements in Compressed Sparse Row format>,\n",
      "   userwiseReg=False, weighting='both')\n",
      "8470 / 8471\n",
      "0.50867, 8471\n",
      "PCMLC(C1=30.0, C2=300.0, C3=1000.0, p=3.0,\n",
      "   similarMat=<84710x84710 sparse matrix of type '<class 'numpy.bool_'>'\n",
      "\twith 5111348 stored elements in Compressed Sparse Row format>,\n",
      "   userwiseReg=False, weighting='both')\n",
      "8470 / 8471\n",
      "0.50398, 8471\n",
      "PCMLC(C1=1000.0, C2=10.0, C3=100.0, p=2.0,\n",
      "   similarMat=<84710x84710 sparse matrix of type '<class 'numpy.bool_'>'\n",
      "\twith 5111348 stored elements in Compressed Sparse Row format>,\n",
      "   userwiseReg=False, weighting='both')\n",
      "6650 / 8471"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-bda2a9f6c359>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m                     \u001b[0mwj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                     \u001b[0maucs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n%.5f, %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maucs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maucs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/miniconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m    275\u001b[0m     return _average_binary_score(\n\u001b[1;32m    276\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/miniconda3/lib/python3.6/site-packages/sklearn/metrics/base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/miniconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         fpr, tpr, tresholds = roc_curve(y_true, y_score,\n\u001b[0;32m--> 272\u001b[0;31m                                         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreorder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/miniconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    532\u001b[0m     \"\"\"\n\u001b[1;32m    533\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 534\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/miniconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;31m# sort scores and corresponding truth values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m     \u001b[0mdesc_score_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mergesort\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdesc_score_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdesc_score_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/miniconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margsort\u001b[0;34m(a, axis, kind, order)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m     \"\"\"\n\u001b[0;32m--> 940\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argsort'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/miniconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "offset = Y_train_dev.shape[1] - PU_dev.shape[1]\n",
    "for c1 in C1:\n",
    "    for c2 in C2:\n",
    "        for c3 in C3:\n",
    "            for p in P:\n",
    "                fname = os.path.join(base_dir, 'pla_reg/pla-aotm2011-C-%g-%g-%g-p-%d.pkl' % (c1, c2, c3, p))\n",
    "                if not os.path.exists(fname): continue\n",
    "                pla = pkl.load(open(fname, 'rb'))\n",
    "                W = pla.W\n",
    "                b = pla.b\n",
    "                print(pla)\n",
    "                aucs = []\n",
    "                for j in range(Y_dev.shape[1]):\n",
    "                    if (j+1) % 10 == 0:\n",
    "                        sys.stdout.write('\\r%d / %d' % (j+1, Y_dev.shape[1]))\n",
    "                        sys.stdout.flush()\n",
    "                    y1 = Y_dev[:, j].toarray().reshape(-1)\n",
    "                    y2 = PU_dev[:, j].toarray().reshape(-1)\n",
    "                    indices = np.where(0 == y2)[0]\n",
    "                    y_true = y1[indices]\n",
    "                    wj = W[j + offset, :].reshape(-1)\n",
    "                    y_pred = (np.dot(X, wj) + b)[indices]\n",
    "                    aucs.append(roc_auc_score(y_true, y_pred))\n",
    "                print('\\n%.5f, %d' % (np.mean(aucs), len(aucs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'data/aotm-2011/setting2'\n",
    "Y_train_dev = pkl.load(gzip.open(os.path.join(base_dir, 'Y_train_dev.pkl.gz'), 'rb'))\n",
    "PU_test = pkl.load(gzip.open(os.path.join(base_dir, 'PU_test.pkl.gz'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftrain1 = os.path.join(base_dir, 'mf-train_p1.csv')\n",
    "ftest  = os.path.join(base_dir, 'mf-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PU_test.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "\n",
    "for i in range(PU_test.shape[0]):\n",
    "    if (i+1) % 1000 == 0:\n",
    "        sys.stdout.write('\\r%d / %d' % (i+1, PU_test.shape[0])); sys.stdout.flush()\n",
    "    nzcol = PU_test[i, :].nonzero()[0]\n",
    "    lines += [','.join([ustrs[i], istrs2[j], '5\\n']) for j in nzcol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ftrain1, 'w') as fd:\n",
    "    fd.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ustrs = ['U%d' % i for i in range(Y_train_dev.shape[0])]\n",
    "istrs1 = ['P%d' % j for j in range(Y_train_dev.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "\n",
    "for i in range(Y_train_dev.shape[0]):\n",
    "    if (i+1) % 10 == 0:\n",
    "        sys.stdout.write('\\r%d / %d' % (i+1, Y_train_dev.shape[0])); sys.stdout.flush()\n",
    "    # convert True to rating 5 and False to 1\n",
    "    lines += [','.join([ustrs[i], istrs1[j], '5\\n']) if Y_train_dev[i, j] is True else \\\n",
    "              ','.join([ustrs[i], istrs1[j], '1\\n']) for j in range(Y_train_dev.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ftrain, 'w') as fd:\n",
    "    for i in range(Y_train_dev.shape[0]):\n",
    "        sys.stdout.write('\\r%d / %d' % (i+1, Y_train_dev.shape[0])); sys.stdout.flush()\n",
    "        istr = 'U%d' % i\n",
    "        for j in range(Y_train_dev.shape[1]):\n",
    "            #print(Y_train[i, j])\n",
    "            jstr = 'P%d' % j\n",
    "            v = Y_train_dev[i, j]\n",
    "            rating = 1   # convert False to rating 1\n",
    "            if v is True:\n",
    "                rating = 5   # convert True to rating 5\n",
    "            line = '%s,%s,%d\\n' % (istr, jstr, rating)\n",
    "            #print(line)\n",
    "            fd.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on dev set --BR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = ['LR', 'PC', 'LR-2017']\n",
    "cols = ['F1', 'Precision@K']\n",
    "df = pd.DataFrame(index=rows, columns=cols)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1\n",
    "#fname = os.path.join('data', 'aotm2011-params-br/br-aotm2011-C-%s.pkl' % str(C))\n",
    "fname = os.path.join(data_dir, 'br-aotm2011-C-%g.pkl' % C)\n",
    "br = pkl.load(open(fname, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate F1: threshold for logistic regression is 0 for logits, 0.5 for probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "F1 = evaluate_minibatch(br, calc_F1, X_dev, Y_dev, threshold=0, batch_size=1500, verbose=1)\n",
    "avgF1 = np.mean(F1)\n",
    "F1_all.append(avgF1)\n",
    "print('\\nF1: %g' % avgF1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`C: 0.1, Threshold: 0.05, F1: 0.00254648`  \n",
    "`C:   1, Threshold: 0.05, F1: 0.0121401`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Precision@K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pak = evaluate_minibatch(br, calc_precisionK, X_dev, Y_dev, threshold=None, batch_size=1500, verbose=1)\n",
    "print('\\nPrecision@K: %g' % np.mean(pak))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`C: 0.1, Precision@K: 0.0884917`  \n",
    "`C:   1, Precision@K: 0.0943461`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on test set -- BR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_C = 1\n",
    "best_TH = 0.05\n",
    "fname = os.path.join('data', 'aotm2011-params-br/br-aotm2011-C-%s.pkl' % str(best_C))\n",
    "best_br = pkl.load(open(fname, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_test_br = evaluate_minibatch(best_br, calc_F1, X_test, Y_test, threshold=best_TH, batch_size=1500, verbose=1)\n",
    "print('\\nTest F1: %g' % np.mean(F1_test_br))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pak_test_br = evaluate_minibatch(best_br, calc_precisionK, X_test, Y_test,threshold=None,batch_size=1500,verbose=1)\n",
    "print('\\nTest Precision@K: %g' % np.mean(pak_test_br))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['LR', 'F1'] = np.mean(F1_test_br)\n",
    "df.loc['LR', 'Precision@K'] = np.mean(pak_test_br)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on dev set -- PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "C_set = [0.1, 0.3, 1, 3, 10, 30, 100, 300, 1000, 3000, 10000, 30000]\n",
    "p_set = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "metrics_pc = [ ]\n",
    "print('%15s %15s %15s %15s %15s' % ('C', 'p', 'Threshold', 'F1', 'Precision@K'))\n",
    "for C in C_set:\n",
    "    for p in p_set:\n",
    "        #fname = os.path.join('data', 'aotm2011-params-pc/pc-aotm2011-C-%g-p-%g.pkl' % (C, p))\n",
    "        fname = os.path.join(data_dir, 'pc-aotm2011-C-%g-p-%g.pkl' % (C, p))\n",
    "        if not os.path.exists(fname): continue\n",
    "        pc_dict = pkl.load(open(fname, 'rb'))\n",
    "        print('%15s %15s %15s %15s %15s' % ('%g'%pc_dict['C'], '%g'%pc_dict['p'], \\\n",
    "                                            '%g'%pc_dict['Threshold'], '%g'%pc_dict['F1'], \\\n",
    "                                            '%g'%pc_dict['Precision@K']))\n",
    "        metrics_pc.append((pc_dict['C'], pc_dict['p'], pc_dict['Threshold'],pc_dict['F1'],pc_dict['Precision@K']))\n",
    "        clf = PClassificationMLC()\n",
    "        clf.load_params(fname)\n",
    "        th = pc_dict['Threshold']\n",
    "        F1 = evaluate_minibatch(clf, calc_F1, X_test, Y_test, threshold=th, batch_size=1500, verbose=1)\n",
    "        print('\\nTest F1: %g' % np.mean(F1))\n",
    "        pak = evaluate_minibatch(clf, calc_precisionK, X_test, Y_test, threshold=None, batch_size=1500, verbose=1)\n",
    "        print('\\nTest Precision@K: %g' % np.mean(pak))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyix = 3  # F1\n",
    "sorted_metrics_pc = sorted(metrics_pc, key=lambda x: x[keyix], reverse=True)\n",
    "print('Best hyper-param:\\n(C, p, Threshold, F1, Precision@K):', sorted_metrics_pc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on test set -- PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_C = 30000 #10000 #300   #3000\n",
    "best_p = 2 #2 #3     #6\n",
    "best_TH = 0.1 #0.15 #0.1\n",
    "#fname = os.path.join('data', 'aotm2011-params-pc/pc-aotm2011-C-%g-p-%g.pkl' % (best_C, best_p))\n",
    "fname = os.path.join(data_dir, 'pc-aotm2011-C-%g-p-%g.pkl' % (best_C, best_p))\n",
    "best_pc = PClassificationMLC()\n",
    "best_pc.load_params(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestdict = pkl.load(open(fname, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(bestdict['cost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_test_pc = evaluate_minibatch(best_pc, calc_F1, X_test, Y_test, threshold=best_TH, batch_size=1500, verbose=1)\n",
    "print('\\nTest F1: %g' % np.mean(F1_test_pc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pak = evaluate_minibatch(best_pc, calc_precisionK, X_train, Y_train, threshold=None, batch_size=1500, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nTrain P@K: %g' % np.mean(pak))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = best_pc.decision_function(X_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ex_idx = 2\n",
    "\n",
    "plt.hist(preds[test_ex_idx], bins=50)\n",
    "\n",
    "y_true = Y_train[test_ex_idx].toarray()\n",
    "\n",
    "pos_idx = np.where(y_true)[1]\n",
    "print('prediction of true positives')\n",
    "print(preds[test_ex_idx][pos_idx])\n",
    "print('top predictions')\n",
    "np.sort(preds[test_ex_idx])[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pak_test_pc = evaluate_minibatch(best_pc, calc_precisionK, X_test, Y_test,threshold=None,batch_size=1500,verbose=1)\n",
    "print('\\nTest Precision@K: %g' % np.mean(pak_test_pc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['PC', 'F1'] = np.mean(F1_test_pc)\n",
    "df.loc['PC', 'Precision@K'] = np.mean(pak_test_pc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['LR-2017', 'F1'] = 0.031"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_str = df.to_latex(float_format=lambda x: '$%.4f$' % x, na_rep='-', multirow=False, escape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\\\begin{table}[!h]')\n",
    "print('\\centering')\n",
    "print('\\\\caption{Performance on test set}')\n",
    "print('\\\\label{tab:perf}')    \n",
    "print(tab_str)\n",
    "print('\\\\end{table}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
