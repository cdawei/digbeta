{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-label classification -- p-classification loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys, time\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.io import arff\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import check_grad\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('src')\n",
    "from evaluate import avgPrecision, avgPrecisionK, printEvaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "yeast_ftrain = os.path.join(data_dir, 'yeast/yeast-train.arff')\n",
    "yeast_ftest  = os.path.join(data_dir, 'yeast/yeast-test.arff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEED = 123456789"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load yeast dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train, meta_train = arff.loadarff(yeast_ftrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_test, meta_test = arff.loadarff(yeast_ftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(data_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(data_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#features: 103\n"
     ]
    }
   ],
   "source": [
    "nFeatures = np.array(list(data_train[0])[:-14], dtype=np.float).shape[0]\n",
    "print('#features:', nFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.array(list(data_train[0])[:-14], dtype=np.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#labels: 14\n"
     ]
    }
   ],
   "source": [
    "nLabels = np.array(list(data_train[0])[-14:], dtype=np.int).shape[0]\n",
    "print('#labels:', nLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.array(list(data_train[0])[-14:], dtype=np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#training examples: 1500\n"
     ]
    }
   ],
   "source": [
    "print('#training examples:', len(data_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#test examples: 917\n"
     ]
    }
   ],
   "source": [
    "print('#test examples:', len(data_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram of #positive labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nPositives = [np.sum(np.array(list(data_train[ix])[-14:], dtype=np.int)) for ix in range(len(data_train))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9586a4c630>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9586a48f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(nPositives).hist(bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataset(data):\n",
    "    \"\"\"\n",
    "        Create the labelled dataset for a given label index\n",
    "        \n",
    "        Input:\n",
    "            - data: original data with features + labels\n",
    "            \n",
    "        Output:\n",
    "            - (Feature, Label) pair (X, y)\n",
    "              X comprises the features for each example\n",
    "              Y comprises the labels of the corresponding example\n",
    "    \"\"\"\n",
    "\n",
    "    N = len(data)\n",
    "    D = nFeatures\n",
    "    L = nLabels\n",
    "\n",
    "    magic = -14\n",
    "\n",
    "    X = np.zeros((N, D), dtype = np.float)\n",
    "    Y = np.zeros((N, L), dtype = np.int)\n",
    "       \n",
    "    for i in range(N):\n",
    "        X[i, :] = list(data[i])[:magic]\n",
    "        Y[i, :] = list(data[i])[magic:]\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss between a ground truth and a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evalPred(truth, pred, lossType = 'Hamming'):\n",
    "    \"\"\"\n",
    "        Compute loss given ground truth and prediction\n",
    "        \n",
    "        Input:\n",
    "            - truth:    binary array of true labels\n",
    "            - pred:     real-valued array of predictions\n",
    "            - lossType: can be subset 0-1, Hamming, ranking, and Precision@K where K = # positive labels.\n",
    "    \"\"\"\n",
    "\n",
    "    assert(len(truth) == len(pred))\n",
    "    L = len(truth)\n",
    "    nPos = np.sum(truth)\n",
    "    \n",
    "    predBin = np.array((pred > 0), dtype=np.int)\n",
    "    \n",
    "    if lossType == 'Subset01':\n",
    "        return 1 - int(np.all(truth == predBin))\n",
    "    \n",
    "    elif lossType == 'Hamming':\n",
    "        return np.sum(truth != predBin) / L\n",
    "    \n",
    "    elif lossType == 'Ranking':\n",
    "        loss = 0\n",
    "        for i in range(L-1):\n",
    "            for j in range(i+1, L):\n",
    "                if truth[i] > truth[j]:\n",
    "                    if pred[i] < pred[j]: \n",
    "                        loss += 1\n",
    "                    if pred[i] == pred[j]:\n",
    "                        loss += 0.5\n",
    "        #return loss / (nPos * (L-nPos))\n",
    "        return loss\n",
    "        \n",
    "    elif lossType == 'Precision@K':\n",
    "        # sorted indices of the labels most likely to be +'ve\n",
    "        idx = np.argsort(pred)[::-1]\n",
    "        \n",
    "        # true labels according to the sorted order\n",
    "        y = truth[idx]\n",
    "        \n",
    "        # fraction of +'ves in the top K predictions\n",
    "        return np.mean(y[:nPos])if nPos > 0 else 0\n",
    "    \n",
    "    elif lossType == 'Precision@3':\n",
    "        # sorted indices of the labels most likely to be +'ve\n",
    "        idx = np.argsort(pred)[::-1]\n",
    "        \n",
    "        # true labels according to the sorted order\n",
    "        y = truth[idx]\n",
    "        \n",
    "        # fraction of +'ves in the top K predictions\n",
    "        return np.mean(y[:3])\n",
    "    \n",
    "    elif lossType == 'Precision@5':\n",
    "        # sorted indices of the labels most likely to be +'ve\n",
    "        idx = np.argsort(pred)[::-1]\n",
    "        \n",
    "        # true labels according to the sorted order\n",
    "        y = truth[idx]\n",
    "        \n",
    "        # fraction of +'ves in the top K predictions\n",
    "        return np.mean(y[:5])\n",
    "    \n",
    "    else:\n",
    "        assert(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avgPrecisionK(allTruths, allPreds):\n",
    "    losses = []\n",
    "    lossType = 'Precision@K'\n",
    "    for i in range(allPreds.shape[0]):\n",
    "        pred  = allPreds[i, :]\n",
    "        truth = allTruths[i, :]\n",
    "        losses.append(evalPred(truth, pred, lossType))\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printEvaluation(allTruths, allPreds):\n",
    "    \n",
    "    N = allTruths.shape[0]\n",
    "    #print(N)\n",
    "\n",
    "    for lossType in ['Precision@K']: \n",
    "        # ['Subset01', 'Hamming', 'Ranking', 'Precision@K', 'Precision@3', 'Precision@5']:\n",
    "        losses = [ ]\n",
    "        for i in range(allPreds.shape[0]):\n",
    "            pred  = allPreds[i, :]\n",
    "            truth = allTruths[i, :]\n",
    "            losses.append(evalPred(truth, pred, lossType))\n",
    "\n",
    "        #print('%24s: %1.4f' % ('Average %s Loss' % lossType, np.mean(losses)))\n",
    "        print('%s: %1.4f, %.3f' % ('Average %s' % lossType, np.mean(losses), np.std(losses) / np.sqrt(N)))\n",
    "        #plt.hist(aucs, bins = 10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## p-classification loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-label learning with p-norm push loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def obj_pnorm_push(w, X, Y, p, C):\n",
    "    \"\"\"\n",
    "        Objective with L2 regularisation and p-classification push loss\n",
    "        \n",
    "        Input:\n",
    "            - w: current weight vector, flattened L x D\n",
    "            - X: feature matrix, N x D\n",
    "            - Y: label matrix,   N x L\n",
    "            - p: constant for p-classification push loss\n",
    "            - C: regularisation constant, is consistent with scikit-learn C = 1 / (N * \\lambda)\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "    L = Y.shape[1]\n",
    "    assert(w.shape[0] == L * D)\n",
    "    assert(p >= 1)\n",
    "    assert(C > 0)\n",
    "    \n",
    "    W = w.reshape(L, D)  # reshape weight matrix\n",
    "    \n",
    "    J = 0.0  # cost\n",
    "    G = np.zeros_like(W)  # gradient matrix\n",
    "    nPosAll = np.sum(Y, axis=1)  # number of positive labels for each example, N by 1\n",
    "    nNegAll = L - nPosAll        # number of negative labels for each example, N by 1\n",
    "    \n",
    "    for k in range(nLabels):\n",
    "        wk = W[k, :]\n",
    "        Yk = Y[:, k]\n",
    "        sPosVec = np.dot(X[Yk == 1, :], wk)      # Nk+ by 1\n",
    "        sNegVec = np.dot(X[Yk == 0, :], wk)      # NK- by 1\n",
    "        nPosVec = nPosAll[Yk == 1]               # Nk+ by 1\n",
    "        nNegVec = nNegAll[Yk == 0]               # NK- by 1\n",
    "        \n",
    "        #nPosVec = np.sum(Y[Yk == 1, :], axis=1)  # Nk+ by 1\n",
    "        #nNegVec = np.sum(Y[Yk == 0, :], axis=1)  # NK- by 1\n",
    "        #nPosVec = np.sum(Y[Yk == 1, :], axis=1) + 0.01 # Nk+ by 1 with smoothing\n",
    "        #nNegVec = np.sum(Y[Yk == 0, :], axis=1) + 0.01 # NK- by 1 with smoothing\n",
    "        \n",
    "        #nPosVec = np.ones_like(sPosVec) * N\n",
    "        #nNegVec = np.ones_like(sNegVec) * N\n",
    "        lossPos = np.divide(np.exp(-sPosVec), nPosVec)     # NK+ by 1\n",
    "        lossNeg = np.divide(np.exp(p * sNegVec), nNegVec)  # NK- by 1\n",
    "        \n",
    "        J += np.sum(lossPos) + np.sum(lossNeg) / p\n",
    "        \n",
    "        GradPos = -X[Yk == 1, :] * lossPos[:, None]\n",
    "        GradNeg =  X[Yk == 0, :] * lossNeg[:, None]\n",
    "        \n",
    "        G[k, :] = np.sum(GradPos, axis=0) + np.sum(GradNeg, axis=0)\n",
    "                \n",
    "    #J = 0.5 * C * np.dot(w, w) + J / N\n",
    "    #G = C * W + G / N\n",
    "    \n",
    "    # be consistent with scikit-learn C = 1 / (N * \\lambda)\n",
    "    J = 0.5 * np.dot(w, w) + C * J\n",
    "    G = W + C * G\n",
    "    \n",
    "    return (J, G.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, Y_train = create_dataset(data = data_train)\n",
    "X_test,  Y_test  = create_dataset(data = data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.6159169246469862e-05"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%script false\n",
    "#C = 1  # if C is lambda\n",
    "C = 1/X_train.shape[0]\n",
    "p = 1\n",
    "w0 = np.random.rand(nFeatures * nLabels)\n",
    "check_grad(lambda w: obj_pnorm_push(w, X_train, Y_train, p, C)[0], \\\n",
    "           lambda w: obj_pnorm_push(w, X_train, Y_train, p, C)[1], w0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MLC_pclassification(BaseEstimator):\n",
    "    \"\"\"All methods are necessary for a scikit-learn estimator\"\"\"\n",
    "    \n",
    "    def __init__(self, p=1, C=1):\n",
    "        \"\"\"Initialisation\"\"\"\n",
    "        \n",
    "        assert C >= 0\n",
    "        assert p >= 1\n",
    "        self.C = C\n",
    "        self.p = p\n",
    "        self.trained = False\n",
    "        \n",
    "    def fit(self, X_train, Y_train):\n",
    "        \"\"\"Model fitting by optimising the objective\"\"\"\n",
    "        \n",
    "        opt_method = 'BFGS' #'Newton-CG'\n",
    "        options = {'disp': True}\n",
    "        if options['disp']: \n",
    "            print('\\nC: %g, p: %g' % (self.C, self.p))\n",
    "            \n",
    "        D = X_train.shape[1]\n",
    "        L = Y_train.shape[1]\n",
    "        w0 = np.random.rand(L * D)  # initial guess\n",
    "        opt = minimize(obj_pnorm_push, w0, args=(X_train, Y_train, self.p, self.C), \\\n",
    "                       method=opt_method, jac=True, options=options)\n",
    "        if opt.success is True:\n",
    "            self.w = opt.x\n",
    "            self.trained = True\n",
    "        else:\n",
    "            sys.stderr.write('Optimisation failed')\n",
    "            self.trained = False\n",
    "    \n",
    "            \n",
    "    def decision_function(self, X_test):\n",
    "        \"\"\"Make predictions (score is real number)\"\"\"\n",
    "        \n",
    "        assert self.trained is True, \"Can't make prediction before training\"\n",
    "        D = X_test.shape[1]\n",
    "        return np.dot(X_test, self.w.reshape(-1, D).T)\n",
    "        \n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"Make predictions (score is boolean)\"\"\"\n",
    "        \n",
    "        preds = self.decision_function(X_test)\n",
    "        return (preds > 0)\n",
    "    \n",
    "    \n",
    "    def score(self, X, Y):\n",
    "        \"\"\"Compute scoring metric\"\"\"\n",
    "        \n",
    "        allPreds = self.decision_function(X)\n",
    "        return avgPrecisionK(Y, allPreds)\n",
    "    \n",
    "    # inherit from BaseEstimator instead of re-implement\n",
    "    #\n",
    "    #def get_params(self, deep = True):\n",
    "    #def set_params(self, **params):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C: 1e-06, p: 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.002400\n",
      "         Iterations: 3\n",
      "         Function evaluations: 5\n",
      "         Gradient evaluations: 5\n",
      "\n",
      "C: 1e-06, p: 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.002400\n",
      "         Iterations: 3\n",
      "         Function evaluations: 5\n",
      "         Gradient evaluations: 5\n",
      "\n",
      "C: 1e-06, p: 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.002400\n",
      "         Iterations: 3\n",
      "         Function evaluations: 5\n",
      "         Gradient evaluations: 5\n",
      "\n",
      "C: 1e-06, p: 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.002400\n",
      "         Iterations: 3\n",
      "         Function evaluations: 5\n",
      "         Gradient evaluations: 5\n",
      "\n",
      "C: 1e-06, p: 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.002400\n",
      "         Iterations: 3\n",
      "         Function evaluations: 5\n",
      "         Gradient evaluations: 5\n",
      "\n",
      "C: 1e-06, p: 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.001600\n",
      "         Iterations: 3\n",
      "         Function evaluations: 5\n",
      "         Gradient evaluations: 5\n",
      "\n",
      "C: 1e-06, p: 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.001600\n",
      "         Iterations: 4\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "\n",
      "C: 1e-06, p: 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.001600\n",
      "         Iterations: 3\n",
      "         Function evaluations: 5\n",
      "         Gradient evaluations: 5\n",
      "\n",
      "C: 1e-06, p: 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.001600\n",
      "         Iterations: 4\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "\n",
      "C: 1e-06, p: 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.001600\n",
      "         Iterations: 3\n",
      "         Function evaluations: 5\n",
      "         Gradient evaluations: 5\n",
      "\n",
      "C: 1e-06, p: 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.001320\n",
      "         Iterations: 6\n",
      "         Function evaluations: 8\n",
      "         Gradient evaluations: 8\n",
      "\n",
      "C: 1e-06, p: 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.001320\n",
      "         Iterations: 26\n",
      "         Function evaluations: 30\n",
      "         Gradient evaluations: 30\n",
      "\n",
      "C: 1e-06, p: 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.001320\n",
      "         Iterations: 8\n",
      "         Function evaluations: 11\n",
      "         Gradient evaluations: 11\n",
      "\n",
      "C: 1e-06, p: 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.001320\n",
      "         Iterations: 26\n",
      "         Function evaluations: 29\n",
      "         Gradient evaluations: 29\n",
      "\n",
      "C: 1e-06, p: 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.001320\n",
      "         Iterations: 8\n",
      "         Function evaluations: 11\n",
      "         Gradient evaluations: 11\n",
      "\n",
      "C: 1e-05, p: 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024000\n",
      "         Iterations: 3\n",
      "         Function evaluations: 5\n",
      "         Gradient evaluations: 5\n",
      "\n",
      "C: 1e-05, p: 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024000\n",
      "         Iterations: 3\n",
      "         Function evaluations: 5\n",
      "         Gradient evaluations: 5\n",
      "\n",
      "C: 1e-05, p: 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024000\n",
      "         Iterations: 3\n",
      "         Function evaluations: 5\n",
      "         Gradient evaluations: 5\n",
      "\n",
      "C: 1e-05, p: 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024000\n",
      "         Iterations: 3\n",
      "         Function evaluations: 5\n",
      "         Gradient evaluations: 5\n",
      "\n",
      "C: 1e-05, p: 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.024000\n",
      "         Iterations: 3\n",
      "         Function evaluations: 5\n",
      "         Gradient evaluations: 5\n",
      "\n",
      "C: 1e-05, p: 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016000\n",
      "         Iterations: 4\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "\n",
      "C: 1e-05, p: 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016000\n",
      "         Iterations: 4\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "\n",
      "C: 1e-05, p: 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016000\n",
      "         Iterations: 4\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "\n",
      "C: 1e-05, p: 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016000\n",
      "         Iterations: 4\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "\n",
      "C: 1e-05, p: 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.016000\n",
      "         Iterations: 4\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "\n",
      "C: 1e-05, p: 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.013200\n",
      "         Iterations: 29\n",
      "         Function evaluations: 32\n",
      "         Gradient evaluations: 32\n",
      "\n",
      "C: 1e-05, p: 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.013200\n",
      "         Iterations: 100\n",
      "         Function evaluations: 104\n",
      "         Gradient evaluations: 104\n",
      "\n",
      "C: 1e-05, p: 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.013200\n",
      "         Iterations: 29\n",
      "         Function evaluations: 31\n",
      "         Gradient evaluations: 31\n",
      "\n",
      "C: 1e-05, p: 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.013200\n",
      "         Iterations: 53\n",
      "         Function evaluations: 56\n",
      "         Gradient evaluations: 56\n",
      "\n",
      "C: 1e-05, p: 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.013200\n",
      "         Iterations: 110\n",
      "         Function evaluations: 114\n",
      "         Gradient evaluations: 114\n",
      "\n",
      "C: 0.0001, p: 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.239984\n",
      "         Iterations: 4\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "\n",
      "C: 0.0001, p: 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.239983\n",
      "         Iterations: 4\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "\n",
      "C: 0.0001, p: 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.239984\n",
      "         Iterations: 4\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "\n",
      "C: 0.0001, p: 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.239982\n",
      "         Iterations: 4\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "\n",
      "C: 0.0001, p: 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.239984\n",
      "         Iterations: 4\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "\n",
      "C: 0.0001, p: 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.159984\n",
      "         Iterations: 4\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "\n",
      "C: 0.0001, p: 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.159983\n",
      "         Iterations: 4\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "\n",
      "C: 0.0001, p: 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.159984\n",
      "         Iterations: 4\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "\n",
      "C: 0.0001, p: 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.159982\n",
      "         Iterations: 4\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "\n",
      "C: 0.0001, p: 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.159984\n",
      "         Iterations: 4\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "\n",
      "C: 0.0001, p: 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.131984\n",
      "         Iterations: 99\n",
      "         Function evaluations: 105\n",
      "         Gradient evaluations: 105\n",
      "\n",
      "C: 0.0001, p: 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.131983\n",
      "         Iterations: 30\n",
      "         Function evaluations: 32\n",
      "         Gradient evaluations: 32\n",
      "\n",
      "C: 0.0001, p: 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.131984\n",
      "         Iterations: 101\n",
      "         Function evaluations: 108\n",
      "         Gradient evaluations: 108\n",
      "\n",
      "C: 0.0001, p: 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.131982\n",
      "         Iterations: 49\n",
      "         Function evaluations: 54\n",
      "         Gradient evaluations: 54\n",
      "\n",
      "C: 0.0001, p: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.131984\n",
      "         Iterations: 57\n",
      "         Function evaluations: 62\n",
      "         Gradient evaluations: 62\n",
      "\n",
      "C: 0.001, p: 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.398444\n",
      "         Iterations: 4\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "\n",
      "C: 0.001, p: 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.398319\n",
      "         Iterations: 4\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "\n",
      "C: 0.001, p: 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.398385\n",
      "         Iterations: 4\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "\n",
      "C: 0.001, p: 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.398218\n",
      "         Iterations: 4\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "\n",
      "C: 0.001, p: 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.398435\n",
      "         Iterations: 4\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "\n",
      "C: 0.001, p: 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.598457\n",
      "         Iterations: 5\n",
      "         Function evaluations: 7\n",
      "         Gradient evaluations: 7\n",
      "\n",
      "C: 0.001, p: 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.598333\n",
      "         Iterations: 5\n",
      "         Function evaluations: 7\n",
      "         Gradient evaluations: 7\n",
      "\n",
      "C: 0.001, p: 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.598398\n",
      "         Iterations: 5\n",
      "         Function evaluations: 7\n",
      "         Gradient evaluations: 7\n",
      "\n",
      "C: 0.001, p: 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.598233\n",
      "         Iterations: 5\n",
      "         Function evaluations: 7\n",
      "         Gradient evaluations: 7\n",
      "\n",
      "C: 0.001, p: 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.598447\n",
      "         Iterations: 5\n",
      "         Function evaluations: 7\n",
      "         Gradient evaluations: 7\n",
      "\n",
      "C: 0.001, p: 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.318499\n",
      "         Iterations: 268\n",
      "         Function evaluations: 272\n",
      "         Gradient evaluations: 272\n",
      "\n",
      "C: 0.001, p: 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.318380\n",
      "         Iterations: 254\n",
      "         Function evaluations: 262\n",
      "         Gradient evaluations: 262\n",
      "\n",
      "C: 0.001, p: 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.318442\n",
      "         Iterations: 227\n",
      "         Function evaluations: 233\n",
      "         Gradient evaluations: 233\n",
      "\n",
      "C: 0.001, p: 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.318284\n",
      "         Iterations: 193\n",
      "         Function evaluations: 201\n",
      "         Gradient evaluations: 201\n",
      "\n",
      "C: 0.001, p: 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.318489\n",
      "         Iterations: 171\n",
      "         Function evaluations: 177\n",
      "         Gradient evaluations: 177\n",
      "\n",
      "C: 0.01, p: 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 23.860042\n",
      "         Iterations: 6\n",
      "         Function evaluations: 8\n",
      "         Gradient evaluations: 8\n",
      "\n",
      "C: 0.01, p: 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 23.849554\n",
      "         Iterations: 6\n",
      "         Function evaluations: 8\n",
      "         Gradient evaluations: 8\n",
      "\n",
      "C: 0.01, p: 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 23.854991\n",
      "         Iterations: 6\n",
      "         Function evaluations: 8\n",
      "         Gradient evaluations: 8\n",
      "\n",
      "C: 0.01, p: 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 23.841564\n",
      "         Iterations: 6\n",
      "         Function evaluations: 8\n",
      "         Gradient evaluations: 8\n",
      "\n",
      "C: 0.01, p: 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 23.858866\n",
      "         Iterations: 6\n",
      "         Function evaluations: 8\n",
      "         Gradient evaluations: 8\n",
      "\n",
      "C: 0.01, p: 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 15.868965\n",
      "         Iterations: 10\n",
      "         Function evaluations: 13\n",
      "         Gradient evaluations: 13\n",
      "\n",
      "C: 0.01, p: 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 15.859174\n",
      "         Iterations: 11\n",
      "         Function evaluations: 14\n",
      "         Gradient evaluations: 14\n",
      "\n",
      "C: 0.01, p: 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 15.864263\n",
      "         Iterations: 18\n",
      "         Function evaluations: 21\n",
      "         Gradient evaluations: 21\n",
      "\n",
      "C: 0.01, p: 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 15.851961\n",
      "         Iterations: 10\n",
      "         Function evaluations: 13\n",
      "         Gradient evaluations: 13\n",
      "\n",
      "C: 0.01, p: 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 15.867645\n",
      "         Iterations: 10\n",
      "         Function evaluations: 13\n",
      "         Gradient evaluations: 13\n",
      "\n",
      "C: 0.01, p: 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 13.090113\n",
      "         Iterations: 496\n",
      "         Function evaluations: 501\n",
      "         Gradient evaluations: 501\n",
      "\n",
      "C: 0.01, p: 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 13.081890\n",
      "         Iterations: 384\n",
      "         Function evaluations: 388\n",
      "         Gradient evaluations: 388\n",
      "\n",
      "C: 0.01, p: 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 13.086260\n",
      "         Iterations: 395\n",
      "         Function evaluations: 401\n",
      "         Gradient evaluations: 401\n",
      "\n",
      "C: 0.01, p: 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 13.076213\n",
      "         Iterations: 181\n",
      "         Function evaluations: 187\n",
      "         Gradient evaluations: 187\n",
      "\n",
      "C: 0.01, p: 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 13.088664\n",
      "         Iterations: 288\n",
      "         Function evaluations: 292\n",
      "         Gradient evaluations: 292\n",
      "\n",
      "C: 0.1, p: 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 232.174952\n",
      "         Iterations: 20\n",
      "         Function evaluations: 24\n",
      "         Gradient evaluations: 24\n",
      "\n",
      "C: 0.1, p: 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 231.683049\n",
      "         Iterations: 24\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "\n",
      "C: 0.1, p: 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 231.939537\n",
      "         Iterations: 21\n",
      "         Function evaluations: 25\n",
      "         Gradient evaluations: 25\n",
      "\n",
      "C: 0.1, p: 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 231.470181\n",
      "         Iterations: 19\n",
      "         Function evaluations: 23\n",
      "         Gradient evaluations: 23\n",
      "\n",
      "C: 0.1, p: 1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 232.030572\n",
      "         Iterations: 21\n",
      "         Function evaluations: 23\n",
      "         Gradient evaluations: 23\n",
      "\n",
      "C: 0.1, p: 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 153.863915\n",
      "         Iterations: 53\n",
      "         Function evaluations: 60\n",
      "         Gradient evaluations: 60\n",
      "\n",
      "C: 0.1, p: 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 153.463948\n",
      "         Iterations: 46\n",
      "         Function evaluations: 52\n",
      "         Gradient evaluations: 52\n",
      "\n",
      "C: 0.1, p: 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 153.689330\n",
      "         Iterations: 50\n",
      "         Function evaluations: 56\n",
      "         Gradient evaluations: 56\n",
      "\n",
      "C: 0.1, p: 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 153.311706\n",
      "         Iterations: 40\n",
      "         Function evaluations: 51\n",
      "         Gradient evaluations: 51\n",
      "\n",
      "C: 0.1, p: 3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 153.735544\n",
      "         Iterations: 42\n",
      "         Function evaluations: 48\n",
      "         Gradient evaluations: 48\n",
      "\n",
      "C: 0.1, p: 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 128.128772\n",
      "         Iterations: 437\n",
      "         Function evaluations: 442\n",
      "         Gradient evaluations: 442\n",
      "\n",
      "C: 0.1, p: 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 127.858283\n",
      "         Iterations: 1027\n",
      "         Function evaluations: 1031\n",
      "         Gradient evaluations: 1031\n",
      "\n",
      "C: 0.1, p: 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 128.030690\n",
      "         Iterations: 546\n",
      "         Function evaluations: 553\n",
      "         Gradient evaluations: 553\n",
      "\n",
      "C: 0.1, p: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 127.761140\n",
      "         Iterations: 1177\n",
      "         Function evaluations: 1184\n",
      "         Gradient evaluations: 1184\n",
      "\n",
      "C: 0.1, p: 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 128.053599\n",
      "         Iterations: 824\n",
      "         Function evaluations: 832\n",
      "         Gradient evaluations: 832\n",
      "\n",
      "C: 0.1, p: 10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 159.844600\n",
      "         Iterations: 765\n",
      "         Function evaluations: 778\n",
      "         Gradient evaluations: 778\n",
      "\n",
      "Best parameters set found on development set:\n",
      "{'C': 0.1, 'p': 10}\n"
     ]
    }
   ],
   "source": [
    "parameters = [{'C': [10**(e) for e in range(-6,0)], 'p': [1, 3, 10]}]\n",
    "\n",
    "clf = GridSearchCV(MLC_pclassification(), parameters, cv=5)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "print(\"\\nBest parameters set found on development set:\")\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.486 (+/-0.036) for {'C': 1e-06, 'p': 1}\n",
      "0.450 (+/-0.050) for {'C': 1e-06, 'p': 3}\n",
      "0.475 (+/-0.069) for {'C': 1e-06, 'p': 10}\n",
      "0.486 (+/-0.036) for {'C': 1e-05, 'p': 1}\n",
      "0.488 (+/-0.037) for {'C': 1e-05, 'p': 3}\n",
      "0.486 (+/-0.041) for {'C': 1e-05, 'p': 10}\n",
      "0.488 (+/-0.037) for {'C': 0.0001, 'p': 1}\n",
      "0.488 (+/-0.037) for {'C': 0.0001, 'p': 3}\n",
      "0.488 (+/-0.037) for {'C': 0.0001, 'p': 10}\n",
      "0.488 (+/-0.037) for {'C': 0.001, 'p': 1}\n",
      "0.489 (+/-0.035) for {'C': 0.001, 'p': 3}\n",
      "0.489 (+/-0.036) for {'C': 0.001, 'p': 10}\n",
      "0.488 (+/-0.034) for {'C': 0.01, 'p': 1}\n",
      "0.492 (+/-0.038) for {'C': 0.01, 'p': 3}\n",
      "0.495 (+/-0.033) for {'C': 0.01, 'p': 10}\n",
      "0.491 (+/-0.022) for {'C': 0.1, 'p': 1}\n",
      "0.499 (+/-0.021) for {'C': 0.1, 'p': 3}\n",
      "0.507 (+/-0.026) for {'C': 0.1, 'p': 10}\n"
     ]
    }
   ],
   "source": [
    "for mean, std, params in zip(clf.cv_results_['mean_test_score'], clf.cv_results_['std_test_score'], \\\n",
    "                             clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_train = clf.decision_function(X_train)\n",
    "preds_test  = clf.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "Average Precision@K: 0.5723, 0.008\n",
      "\n",
      "Test set:\n",
      "Average Precision@K: 0.5050, 0.010\n"
     ]
    }
   ],
   "source": [
    "print('Training set:')\n",
    "printEvaluation(Y_train, preds_train)\n",
    "print()\n",
    "print('Test set:')\n",
    "printEvaluation(Y_test, preds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precisions_train = [avgPrecision(Y_train, preds_train, k) for k in range(1, nLabels+1)]\n",
    "precisions_test  = [avgPrecision(Y_test,  preds_test,  k) for k in range(1, nLabels+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precisionK_train = avgPrecisionK(Y_train, preds_train)\n",
    "precisionK_test  = avgPrecisionK(Y_test,  preds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f9550793710>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAFACAYAAAASxGABAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9550861a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[10,5])\n",
    "plt.plot(precisions_train, ls='--', c='r', label='Train')\n",
    "plt.plot(precisions_test,  ls='-',  c='g', label='Test')\n",
    "plt.plot([precisionK_train for k in range(nLabels)], ls='-', c='r', label='Train, Precision@K')\n",
    "plt.plot([precisionK_test  for k in range(nLabels)], ls='-', c='g', label='Test, Precision@K')\n",
    "plt.xticks(np.arange(nLabels), np.arange(1,nLabels+1))\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Precision@k')\n",
    "plt.legend(loc='best')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
