{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A representative subset of AotM-2011 Playlists with MSD Audio Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "import gzip\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from scipy.sparse import lil_matrix, issparse\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('src')\n",
    "from BinaryRelevance import BinaryRelevance\n",
    "from PClassificationMLC import PClassificationMLC\n",
    "from evaluate import calc_F1, calc_precisionK, f1_score_nowarn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/aotm-2011'\n",
    "#faotm = os.path.join(data_dir, 'aotm2011-subset.pkl')\n",
    "faotm = os.path.join(data_dir, 'aotm2011-user-playlist.pkl')\n",
    "ffeature = 'data/msd/songID2Features.pkl.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load playlists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load playlists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_playlists = pkl.load(open(faotm, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#user    : 14182\n",
      "#playlist: 84710\n"
     ]
    }
   ],
   "source": [
    "print('#user    :', len(user_playlists))\n",
    "print('#playlist:', np.sum([len(user_playlists[u]) for u in user_playlists]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average playlist length: 10.1\n"
     ]
    }
   ],
   "source": [
    "pl_lengths = [len(pl) for u in user_playlists for pl in user_playlists[u]]\n",
    "#plt.hist(pl_lengths, bins=100)\n",
    "print('Average playlist length: %.1f' % np.mean(pl_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = sorted(user_playlists.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_user = {u: {sid for pl in user_playlists[u] for sid in pl} for u in users}  # user: a set of songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the number of playlists per user, and the number of songs covered by the user's playlists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf = pd.DataFrame(index=users, columns=['#playlist', '#song'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf['#playlist'] = [len(user_playlists[u]) for u in users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf['#song'] = [len(songs_user[u]) for u in users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff57a8f5048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.subplot(111)\n",
    "udf['#playlist'].hist(bins=200, ax=ax)\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_subset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#playlist</th>\n",
       "      <th>#song</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(921243600.0, McDermott)</th>\n",
       "      <td>10</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(923925600.0, W.12)</th>\n",
       "      <td>10</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(934120800.0, The J-Dogg)</th>\n",
       "      <td>10</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(937663200.0, Wemple)</th>\n",
       "      <td>10</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(942498000.0, Lang1)</th>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           #playlist  #song\n",
       "(921243600.0, McDermott)          10     79\n",
       "(923925600.0, W.12)               10     82\n",
       "(934120800.0, The J-Dogg)         10     93\n",
       "(937663200.0, Wemple)             10    102\n",
       "(942498000.0, Lang1)              10    115"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "udf_subset = udf[ udf['#playlist'] == 10]\n",
    "udf_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_subset.append(udf_subset.index[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#playlist</th>\n",
       "      <th>#song</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(965311200.0, radiozilla)</th>\n",
       "      <td>30</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(966261600.0, Em)</th>\n",
       "      <td>30</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(967986000.0, zwirnm)</th>\n",
       "      <td>30</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(985615200.0, agnamaracs)</th>\n",
       "      <td>30</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(993045600.0, kgp.)</th>\n",
       "      <td>30</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           #playlist  #song\n",
       "(965311200.0, radiozilla)         30    181\n",
       "(966261600.0, Em)                 30    266\n",
       "(967986000.0, zwirnm)             30    218\n",
       "(985615200.0, agnamaracs)         30    325\n",
       "(993045600.0, kgp.)               30    227"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "udf_subset = udf[ udf['#playlist'] == 30]\n",
    "udf_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_subset.append(udf_subset.index[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#playlist</th>\n",
       "      <th>#song</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(958572000.0, Lorentz)</th>\n",
       "      <td>98</td>\n",
       "      <td>1042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(1036846800.0, Slack-a-gogo)</th>\n",
       "      <td>98</td>\n",
       "      <td>935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(1046005200.0, Shiki)</th>\n",
       "      <td>98</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(1077022800.0, spunk these)</th>\n",
       "      <td>98</td>\n",
       "      <td>658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              #playlist  #song\n",
       "(958572000.0, Lorentz)               98   1042\n",
       "(1036846800.0, Slack-a-gogo)         98    935\n",
       "(1046005200.0, Shiki)                98    777\n",
       "(1077022800.0, spunk these)          98    658"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "udf_subset = udf[ udf['#playlist'] == 98]\n",
    "udf_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_subset.append(udf_subset.index[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#udf.sort_values(by=['#playlist'], ascending=False).iloc[100:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(937663200.0, 'Wemple'), (966261600.0, 'Em'), (1036846800.0, 'Slack-a-gogo')]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uid_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#udf[uid_subset]  # tuple are used as multiindex in pandas\n",
    "#udf[[uid_subset]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user whose playlists cover a *proper number of playlists*, e.g. 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists_subset = [pl for u in uid_subset for pl in user_playlists[u]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_set = sorted({sid for u in uid_subset for sid in songs_user[u]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1285"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(song_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#song_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load song features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `song_id` --> `feature array` mapping: map a song to the audio features of one of its corresponding tracks in MSD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "song2Features = pkl.load(gzip.open(ffeature, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The set of songs, which is the set of labels in this formulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split song-playlist matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Songs as rows, playlists as columns, split rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dataset_subset(playlists, song_set, features_MSD):\n",
    "    \"\"\"\n",
    "    Create labelled dataset: rows are songs, columns are users.\n",
    "    \n",
    "    Input:\n",
    "        - playlists: a set of playlists\n",
    "        - song_set: a set of songIDs\n",
    "        - features_MSD: dictionary that maps songIDs to features from MSD\n",
    "    Output:\n",
    "        - (Feature, Label) pair (X, Y)\n",
    "          X: #songs by #features\n",
    "          Y: #songs by #users\n",
    "    \"\"\"\n",
    "    song_indices = {sid: ix for ix, sid in enumerate(song_set)}\n",
    "    N = len(song_set)\n",
    "    K = len(playlists)\n",
    "    \n",
    "    X = np.array([features_MSD[sid] for sid in song_set])\n",
    "    Y = np.zeros((N, K), dtype=np.bool)\n",
    "    \n",
    "    for k in range(K):\n",
    "        pl = playlists[k]\n",
    "        indices = [song_indices[sid] for sid in pl]\n",
    "        Y[indices, k] = True\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = gen_dataset_subset(playlists=playlists_subset, song_set=song_set, features_MSD=song2Features)\n",
    "\n",
    "# data split: approximately 80/20 for training/dev\n",
    "X_train, X_dev, Y_train, Y_dev = train_test_split(X, Y, test_size=0.2, random_state=8976321)\n",
    "\n",
    "# feature normalisation\n",
    "X_train_mean = np.mean(X_train, axis=0).reshape((1, -1))\n",
    "X_train_std = 100 * np.std(X_train, axis=0).reshape((1, -1)) + 10 ** (-6)\n",
    "X_train -= X_train_mean\n",
    "X_train /= X_train_std\n",
    "X_dev   -= X_train_mean\n",
    "X_dev   /= X_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:     (1028, 202)     (1028, 138)\n",
      "Dev  :      (257, 202)      (257, 138)\n"
     ]
    }
   ],
   "source": [
    "print('Train: %15s %15s' % (X_train.shape, Y_train.shape))\n",
    "print('Dev  : %15s %15s' % (X_dev.shape,   Y_dev.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.34576114974e-18\n",
      "-0.000297031551481\n",
      "-5.67389855057e-05\n",
      "0.000249339240116\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(np.mean(X_train, axis=0)))\n",
    "print(np.mean( np.std(X_train, axis=0)) - 0.01)\n",
    "print(np.mean(np.mean(X_dev, axis=0)))\n",
    "print(np.mean( np.std(X_dev, axis=0)) - 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BR - Independent logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Independent logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "br = BinaryRelevance(n_jobs=4)\n",
    "br.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_br = br.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16414768806073154"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(calc_precisionK(Y_dev.T, Y_br.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score_nowarn(Y_dev.ravel(), (Y_br>=0).ravel(), average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0, 0.0, None)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(Y_dev.ravel(), (Y_br>=0).ravel(), average='binary', warn_for=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.mean(calc_F1(Y_train, br.predict(X_train) >= 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false\n",
    "min_pos_score = []\n",
    "for col in range(Y_dev.shape[1]):\n",
    "    val = Y_br[:,col][Y_dev[:,col]]\n",
    "    if len(val) > 0:\n",
    "        min_pos_score.append(np.min(val))\n",
    "    else:\n",
    "        min_pos_score.append(np.nan)\n",
    "print(np.array(min_pos_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false\n",
    "max_neg_score = []\n",
    "for col in range(Y_dev.shape[1]):\n",
    "    val = Y_br[:,col][np.logical_not(Y_dev[:,col])]\n",
    "    if len(val) > 0:\n",
    "        max_neg_score.append(np.max(val))\n",
    "print(np.array(max_neg_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.array(min_pos_score)-np.array(max_neg_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PC - Multilabel p-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P-Classification ~ P-norm push ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C: 1, p: 1, weighting: True\n"
     ]
    }
   ],
   "source": [
    "pc1 = PClassificationMLC(C=1, weighting=True, verticalWeighting=True)\n",
    "pc1.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_dev\n",
    "Y_test = Y_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 4, 0, 2, 2, 1, 3, 2, 3, 4, 3, 2, 3, 0, 0, 3, 3, 1, 4, 2, 1, 5,\n",
       "       6, 4, 4, 7, 3, 5, 3, 1, 3, 0, 4, 1, 0, 8, 4, 3, 3, 5, 2, 2, 2, 1, 3,\n",
       "       2, 3, 1, 5, 1, 4, 1, 1, 2, 1, 0, 1, 1, 0, 0, 1, 1, 4, 2, 0, 3, 4, 2,\n",
       "       1, 0, 2, 1, 0, 5, 1, 1, 2, 1, 1, 1, 0, 5, 3, 2, 0, 3, 1, 2, 5, 0, 3,\n",
       "       4, 1, 1, 1, 4, 2, 0, 2, 2, 1, 3, 3, 1, 3, 3, 0, 1, 1, 1, 3, 1, 2, 3,\n",
       "       1, 2, 4, 3, 4, 4, 3, 1, 1, 0, 0, 5, 1, 2, 4, 2, 1, 3, 1, 2, 1, 1, 2])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Y_dev, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pc = pc1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16414768806073154"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(calc_precisionK(Y_test.T, Y_pc.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.021719659650694133, 0.32441471571906355, 0.040713536201469051, None)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(Y_dev.ravel(), (Y_pc>=0).ravel(), average='binary', warn_for=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.mean(calc_F1(Y_dev, Y_pc >= 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.mean(calc_F1(Y_train, pc.predict(X_train) >= 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_pos_score = []\n",
    "for col in range(Y_test.shape[1]):\n",
    "    val = Y_pc[:,col][Y_test[:,col]]\n",
    "    if len(val) > 0:\n",
    "        min_pos_score.append(np.min(val))\n",
    "    else:\n",
    "        min_pos_score.append(np.nan)\n",
    "#plt.hist((np.array(min_pos_score)))\n",
    "#plt.hist((np.nan_to_num(min_pos_score)), bins=30)\n",
    "#print(np.array(min_pos_score))\n",
    "#print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_neg_score = []\n",
    "for col in range(Y_test.shape[1]):\n",
    "    val = Y_pc[:,col][np.logical_not(Y_test[:,col])]\n",
    "    if len(val) > 0:\n",
    "        max_neg_score.append(np.max(val))\n",
    "#plt.hist(np.array(max_neg_score), bins=30)\n",
    "#print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(np.nan_to_num(min_pos_score)-np.array(max_neg_score), bins=30)\n",
    "#print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilabel p-classification with unknows in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, K = Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_nan = Y.copy().astype(np.float)\n",
    "np.random.seed(8967321)\n",
    "rand_num = int(0.2 * N)\n",
    "ones = 0\n",
    "for k in range(K):\n",
    "    randix = np.random.permutation(np.arange(N))[:rand_num]\n",
    "    Y_nan[randix, k] = np.nan\n",
    "    ones += Y[randix, k].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.sum(Y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.nansum(Y_nan, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.sum(Y, axis=0) - np.nansum(Y_nan, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ones  # number of positive entries selected to be masked as NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_nan.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of NaN entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35466"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isnan(Y_nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.sum(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train: *keep running util no overflow warning occurred*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C: 1, p: 1, weighting: True\n",
      "J: 0.214785992218\n",
      "J: 6.36113460143e+245\n",
      "J: 1.38807130597e+79\n",
      "J: 5.33063012377e+23\n",
      "J: 242128.662034\n",
      "J: 0.551712181378\n",
      "J: 0.211225405554\n",
      "J: 0.207650141065\n",
      "J: 0.205182069412\n",
      "J: 0.202772293121\n",
      "J: 0.199746631232\n",
      "J: 0.195279375789\n",
      "J: 0.191344585106\n",
      "J: 0.188397775893\n",
      "J: 0.185760032793\n",
      "J: 0.184108651849\n",
      "J: 0.181354623225\n",
      "J: 0.181138422759\n",
      "J: 0.179595338381\n",
      "J: 0.177916861047\n",
      "J: 0.17674074268\n",
      "J: 0.17538347649\n",
      "J: 0.173742360014\n",
      "J: 0.171877736237\n",
      "J: 0.169636642184\n",
      "J: 0.168189957215\n",
      "J: 0.168377986119\n",
      "J: 0.166824886343\n",
      "J: 0.165366676886\n",
      "J: 0.164487879363\n",
      "J: 0.163765265903\n",
      "J: 0.162694500449\n",
      "J: 0.161787369452\n",
      "J: 0.160751225081\n",
      "J: 0.159871678331\n",
      "J: 0.159002221173\n",
      "J: 0.158496136294\n",
      "J: 0.157138304732\n",
      "J: 0.157384304412\n",
      "J: 0.156552633148\n",
      "J: 0.155871059442\n",
      "J: 0.155026947679\n",
      "J: 0.154537230832\n",
      "J: 0.154103248287\n",
      "J: 0.153651191007\n",
      "J: 0.153193019583\n",
      "J: 0.152688320539\n",
      "J: 0.152112341167\n",
      "J: 0.15153600484\n",
      "J: 0.151077674879\n",
      "J: 0.150716046988\n",
      "J: 0.150393310302\n",
      "J: 0.150074110576\n",
      "J: 0.149699198083\n",
      "J: 0.149399885521\n",
      "J: 0.149138476703\n",
      "J: 0.148967629104\n",
      "J: 0.148778939762\n",
      "J: 0.148553116344\n",
      "J: 0.148307810116\n",
      "J: 0.148067814429\n",
      "J: 0.147863152038\n",
      "J: 0.147667613695\n",
      "J: 0.147474551817\n",
      "J: 0.147298199529\n",
      "J: 0.147151255707\n",
      "J: 0.147043406038\n",
      "J: 0.146905498485\n",
      "J: 0.146849363641\n",
      "J: 0.14677217926\n",
      "J: 0.146687811442\n",
      "J: 0.146628918672\n",
      "J: 0.14651119076\n",
      "J: 0.146606547282\n",
      "J: 0.146440125077\n",
      "J: 0.146355494094\n",
      "J: 0.146278790631\n",
      "J: 0.146213868161\n",
      "J: 0.146147527903\n",
      "J: 0.146079402337\n",
      "J: 0.146011581186\n",
      "J: 0.145944857497\n",
      "J: 0.145878983283\n",
      "J: 0.145825586508\n",
      "J: 0.145762797676\n",
      "J: 0.145723250879\n",
      "J: 0.145658937704\n",
      "J: 0.145662022864\n",
      "J: 0.145632681537\n",
      "J: 0.145603578165\n",
      "J: 0.145561945253\n",
      "J: 0.145528346299\n",
      "J: 0.145484297085\n",
      "J: 0.145429190885\n",
      "J: 0.145406393597\n",
      "J: 0.145367114246\n",
      "J: 0.145353470112\n",
      "J: 0.145336856955\n",
      "J: 0.145322808406\n",
      "J: 0.145304769355\n",
      "J: 0.145287303875\n",
      "J: 0.145270758175\n",
      "J: 0.145250466826\n",
      "J: 0.145229854963\n",
      "J: 0.145218762832\n",
      "J: 0.145208657653\n",
      "J: 0.14520068197\n",
      "J: 0.145192436531\n",
      "J: 0.145180241553\n",
      "J: 0.145175305112\n",
      "J: 0.145170040902\n",
      "J: 0.145162672334\n",
      "J: 0.145158002482\n",
      "J: 0.145153768926\n",
      "J: 0.145140687086\n",
      "J: 0.145136596208\n",
      "J: 0.145132250774\n",
      "J: 0.145128347032\n",
      "J: 0.145124891992\n",
      "J: 0.145123265809\n",
      "J: 0.145120925656\n",
      "J: 0.145117947082\n",
      "J: 0.145113090156\n",
      "J: 0.145108741324\n",
      "J: 0.145105040473\n",
      "J: 0.145102051644\n",
      "J: 0.145100336758\n",
      "J: 0.145098832541\n",
      "J: 0.145097490325\n",
      "J: 0.145096545415\n",
      "J: 0.145094553404\n",
      "J: 0.145093409535\n",
      "J: 0.145091577467\n",
      "J: 0.14509049158\n",
      "J: 0.145089583312\n",
      "J: 0.145088379725\n",
      "J: 0.145087078384\n",
      "J: 0.145086405175\n",
      "J: 0.145085346751\n",
      "J: 0.145084811948\n",
      "J: 0.145083937542\n",
      "J: 0.145083176065\n",
      "J: 0.145082680068\n",
      "J: 0.145081575051\n",
      "J: 0.145081501717\n",
      "J: 0.145080916126\n",
      "J: 0.145080367917\n",
      "J: 0.145079871294\n",
      "J: 0.14507944136\n",
      "J: 0.145078993252\n",
      "J: 0.1450786481\n",
      "J: 0.145078376704\n",
      "J: 0.145078077653\n",
      "J: 0.145077738071\n",
      "J: 0.145077446364\n",
      "J: 0.145077428382\n",
      "J: 0.145077225829\n",
      "J: 0.145076990759\n",
      "J: 0.145076749202\n",
      "J: 0.145076563667\n",
      "J: 0.145076338729\n",
      "J: 0.145076134596\n",
      "J: 0.145075918482\n",
      "J: 0.145075755406\n",
      "J: 0.145075615104\n",
      "J: 0.145075475158\n",
      "J: 0.145075309772\n",
      "J: 0.14507524949\n",
      "J: 0.145075114462\n",
      "J: 0.145075112178\n",
      "J: 0.145075046482\n",
      "J: 0.145074974282\n",
      "J: 0.145074830343\n",
      "J: 0.145074802978\n",
      "J: 0.145074726838\n",
      "J: 0.145074674283\n",
      "J: 0.145074616761\n",
      "J: 0.145074535414\n",
      "J: 0.145074611505\n",
      "J: 0.145074477871\n",
      "J: 0.145074365756\n",
      "J: 0.145074302511\n",
      "J: 0.14507425405\n",
      "J: 0.145074214121\n",
      "J: 0.145074185231\n",
      "J: 0.145074128734\n",
      "J: 0.145074095566\n",
      "J: 0.145074061225\n",
      "J: 0.145074006446\n",
      "J: 0.145073976883\n",
      "J: 0.145073934177\n",
      "J: 0.145073908035\n",
      "J: 0.14507388493\n",
      "J: 0.145073853263\n",
      "J: 0.145073840985\n",
      "J: 0.145073819293\n",
      "J: 0.145073807079\n",
      "J: 0.145073795226\n",
      "J: 0.145073772654\n",
      "J: 0.145073762172\n",
      "J: 0.145073733937\n",
      "J: 0.145073720795\n",
      "J: 0.145073707262\n",
      "J: 0.145073697698\n",
      "J: 0.145073682682\n",
      "J: 0.145073676328\n",
      "J: 0.145073667092\n",
      "J: 0.145073652583\n",
      "J: 0.14507366096\n",
      "J: 0.145073643779\n",
      "J: 0.145073632098\n",
      "J: 0.145073623625\n",
      "J: 0.145073613817\n",
      "J: 0.14507360561\n",
      "J: 0.14507359851\n",
      "J: 0.145073592997\n",
      "J: 0.145073589543\n",
      "J: 0.145073582963\n",
      "J: 0.145073583458\n",
      "J: 0.145073578474\n",
      "J: 0.145073571512\n",
      "J: 0.145073566035\n",
      "J: 0.145073559784\n",
      "J: 0.145073554257\n",
      "J: 0.145073547392\n",
      "J: 0.145073540391\n",
      "J: 0.14507353456\n",
      "J: 0.145073529975\n",
      "J: 0.145073521357\n",
      "J: 0.145073517343\n",
      "J: 0.145073511577\n",
      "J: 0.145073503695\n",
      "J: 0.145073494166\n",
      "J: 0.145073486037\n",
      "J: 0.145073479645\n",
      "J: 0.145073474584\n",
      "J: 0.145073471254\n",
      "J: 0.145073464903\n",
      "J: 0.145073461952\n",
      "J: 0.145073456823\n",
      "J: 0.145073449015\n",
      "J: 0.145073442718\n",
      "J: 0.145073430068\n",
      "J: 0.145073472444\n",
      "J: 0.145073425584\n",
      "J: 0.145073414549\n",
      "J: 0.1450734066\n",
      "J: 0.145073393941\n",
      "J: 0.145073388976\n",
      "J: 0.145073377508\n",
      "J: 0.145073367922\n",
      "J: 0.145073359656\n",
      "J: 0.145073346481\n",
      "J: 0.145073370635\n",
      "J: 0.14507333937\n",
      "J: 0.145073327986\n",
      "J: 0.145073318442\n",
      "J: 0.14507330723\n",
      "J: 0.145073295461\n",
      "J: 0.145073283011\n",
      "J: 0.145073267166\n",
      "J: 0.145073256625\n",
      "J: 0.145073240058\n",
      "J: 0.145073226138\n",
      "J: 0.145073206591\n",
      "J: 0.145073189555\n",
      "J: 0.145073170051\n",
      "J: 0.145073158753\n",
      "J: 0.145073130072\n",
      "J: 0.145073117672\n",
      "J: 0.14507309814\n",
      "J: 0.145073067134\n",
      "J: 0.145073048098\n",
      "J: 0.145072990179\n",
      "J: 0.145072965925\n",
      "J: 0.145072937596\n",
      "J: 0.145072893787\n",
      "J: 0.145072870429\n",
      "J: 0.145072808372\n",
      "J: 0.145072781501\n",
      "J: 0.145072745261\n",
      "J: 0.145072686943\n",
      "J: 0.14507261982\n",
      "J: 0.145072565959\n",
      "J: 0.145072490252\n",
      "J: 0.145072429575\n",
      "J: 0.145072353082\n",
      "J: 0.145072240416\n",
      "J: 0.145072172695\n",
      "J: 0.145072112071\n",
      "J: 0.145071969052\n",
      "J: 0.145071921865\n",
      "J: 0.14507183554\n",
      "J: 0.145071746093\n",
      "J: 0.145071626764\n",
      "J: 0.145071451373\n",
      "J: 0.145071847889\n",
      "J: 0.145071355271\n",
      "J: 0.145071149598\n",
      "J: 0.145070971984\n",
      "J: 0.145070731721\n",
      "J: 0.145070647067\n",
      "J: 0.145070423881\n",
      "J: 0.145070279414\n",
      "J: 0.145070108797\n",
      "J: 0.145069862891\n",
      "J: 0.145069558217\n",
      "J: 0.145069290507\n",
      "J: 0.145069001269\n",
      "J: 0.145068705991\n",
      "J: 0.145068483\n",
      "J: 0.145068006006\n",
      "J: 0.145067607637\n",
      "J: 0.145067215004\n",
      "J: 0.145066772065\n",
      "J: 0.145066514951\n",
      "J: 0.145066048377\n",
      "J: 0.145065738686\n",
      "J: 0.145064855699\n",
      "J: 0.14506435962\n",
      "J: 0.145063922911\n",
      "J: 0.145063184019\n",
      "J: 0.145063052302\n",
      "J: 0.145061736006\n",
      "J: 0.145061365058\n",
      "J: 0.145060649687\n",
      "J: 0.145060460919\n",
      "J: 0.145059457249\n",
      "J: 0.145059021953\n",
      "J: 0.145058473396\n",
      "J: 0.145057505295\n",
      "J: 0.145058305131\n",
      "J: 0.145056808653\n",
      "J: 0.145055501647\n",
      "J: 0.145054547523\n",
      "J: 0.145053503484\n",
      "J: 0.145052649438\n",
      "J: 0.145051927053\n",
      "J: 0.145050873691\n",
      "J: 0.145050197283\n",
      "J: 0.145049345731\n",
      "J: 0.145048336126\n",
      "J: 0.145046129789\n",
      "J: 0.145045454641\n",
      "J: 0.145043767857\n",
      "J: 0.145043429866\n",
      "J: 0.145041884018\n",
      "J: 0.145041109122\n",
      "J: 0.145040202652\n",
      "J: 0.145038902842\n",
      "J: 0.145040184332\n",
      "J: 0.145037869238\n",
      "J: 0.145036141771\n",
      "J: 0.145035063098\n",
      "J: 0.14503423477\n",
      "J: 0.145033456516\n",
      "J: 0.145033071558\n",
      "J: 0.145032316063\n",
      "J: 0.145031873007\n",
      "J: 0.145031118093\n",
      "J: 0.145029952252\n",
      "J: 0.145029127959\n",
      "J: 0.145028111603\n",
      "J: 0.145027135482\n",
      "J: 0.145026769992\n",
      "J: 0.145026250707\n",
      "J: 0.145025874529\n",
      "J: 0.145025354986\n",
      "J: 0.145024648749\n",
      "J: 0.145024256395\n",
      "J: 0.14502324702\n",
      "J: 0.145022496534\n",
      "J: 0.145022018464\n",
      "J: 0.145021646496\n",
      "J: 0.14502126984\n",
      "J: 0.14502078354\n",
      "J: 0.145020389796\n",
      "J: 0.145020063147\n",
      "J: 0.145019756916\n",
      "J: 0.145019327377\n",
      "J: 0.145018865378\n",
      "J: 0.145018614354\n",
      "J: 0.145018179746\n",
      "J: 0.145018054821\n",
      "J: 0.145017777621\n",
      "J: 0.145017637952\n",
      "J: 0.145017481939\n",
      "J: 0.145017219586\n",
      "J: 0.145016955361\n",
      "J: 0.145016733707\n",
      "J: 0.145016481375\n",
      "J: 0.145016293545\n",
      "J: 0.145016087322\n",
      "J: 0.145015980282\n",
      "J: 0.145015882791\n",
      "J: 0.145015783098\n",
      "J: 0.145015646067\n",
      "J: 0.145015540127\n",
      "J: 0.145015348202\n",
      "J: 0.145015275488\n",
      "J: 0.145015158773\n",
      "J: 0.145015142561\n",
      "J: 0.145015026279\n",
      "J: 0.145014979049\n",
      "J: 0.145014918873\n",
      "J: 0.14501484761\n",
      "J: 0.145014997275\n",
      "J: 0.145014809834\n",
      "J: 0.145014737552\n",
      "J: 0.145014678075\n",
      "J: 0.14501461194\n",
      "J: 0.145014553051\n",
      "J: 0.145014515486\n",
      "J: 0.145014462863\n",
      "J: 0.145014445002\n",
      "J: 0.145014411857\n",
      "J: 0.145014389792\n",
      "J: 0.145014368462\n",
      "J: 0.145014326136\n",
      "J: 0.145014330624\n",
      "J: 0.145014300965\n",
      "J: 0.14501427138\n",
      "J: 0.145014248538\n",
      "J: 0.145014223039\n",
      "J: 0.145014201319\n",
      "J: 0.145014186632\n",
      "J: 0.145014172093\n",
      "J: 0.145014160605\n",
      "J: 0.145014144511\n",
      "J: 0.145014132904\n",
      "J: 0.145014120983\n",
      "J: 0.145014113108\n",
      "J: 0.14501410342\n",
      "J: 0.14501409736\n",
      "J: 0.145014084576\n",
      "J: 0.145014079353\n",
      "J: 0.145014073179\n",
      "J: 0.145014065242\n",
      "J: 0.145014059094\n",
      "J: 0.145014052239\n",
      "J: 0.145014048466\n",
      "J: 0.145014043993\n",
      "J: 0.145014041187\n",
      "J: 0.145014034075\n",
      "J: 0.14501403175\n",
      "J: 0.145014028934\n",
      "J: 0.145014027415\n"
     ]
    }
   ],
   "source": [
    "pc2 = PClassificationMLC(weighting=True, verticalWeighting=True)\n",
    "pc2.fit(X, Y_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction: use the minimum of positive entry score of the same example as threshold.  \n",
    "Evaluation: use F1 on all unknown entries (as a 1D array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred2 = pc2.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_index = np.nan_to_num(Y_nan).astype(np.bool)\n",
    "nan_index = np.isnan(Y_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truths = Y[nan_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = []\n",
    "preds = []\n",
    "for k in range(K):\n",
    "    val = Y_pred2[:, k][pos_index[:, k]]\n",
    "    th = np.min(val)\n",
    "    thresholds.append(th)\n",
    "    preds += (Y_pred2[nan_index[:,k], k] >= th).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011003117549972491"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score_nowarn(ground_truths, preds, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0058184639255236615, 0.10101010101010101, 0.011003117549972491, None)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(ground_truths, preds, average='binary', warn_for=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilabel p-classification with some playlist fully observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, K = Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_nan_part = Y.copy().astype(np.float)\n",
    "np.random.seed(8967321)\n",
    "nan_num = int(0.4 * N)\n",
    "indices = np.arange(N)[-nan_num:]\n",
    "ones = 0\n",
    "for k in range(int(K/2), K):\n",
    "    Y_nan_part[indices, k] = np.nan\n",
    "    ones += Y[indices, k].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.sum(Y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.nansum(Y_nan_part, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.sum(Y, axis=0) - np.nansum(Y_nan_part, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.sum(np.isnan(Y_nan_part),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ones  # number of positive entries selected to be masked as NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_nan.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of NaN entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35466"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isnan(Y_nan_part))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.sum(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train: *keep running util no overflow warning occurred*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C: 1, p: 1, weighting: True\n",
      "J: 0.214785992218\n",
      "J: 3.57672001281e+238\n",
      "J: 2.42757229971e+75\n",
      "J: 7.13232476974e+21\n",
      "J: 85013.4163448\n",
      "J: 0.550862567779\n",
      "J: 0.210623061765\n",
      "J: 0.206736563153\n",
      "J: 0.203260990066\n",
      "J: 0.200192005302\n",
      "J: 0.195906460547\n",
      "J: 0.190578905495\n",
      "J: 0.187061866756\n",
      "J: 0.185117164626\n",
      "J: 0.182401995137\n",
      "J: 0.180519109028\n",
      "J: 0.178167134018\n",
      "J: 0.177112874019\n",
      "J: 0.175476062522\n",
      "J: 0.173625020622\n",
      "J: 0.171911548343\n",
      "J: 0.170590338072\n",
      "J: 0.168763627885\n",
      "J: 0.167323896914\n",
      "J: 0.165741570123\n",
      "J: 0.164287826015\n",
      "J: 0.162913120954\n",
      "J: 0.161843477342\n",
      "J: 0.160919725558\n",
      "J: 0.159971205798\n",
      "J: 0.1590323004\n",
      "J: 0.157732590907\n",
      "J: 0.156740722288\n",
      "J: 0.15573378718\n",
      "J: 0.154597798613\n",
      "J: 0.153606508202\n",
      "J: 0.152723537261\n",
      "J: 0.151975050044\n",
      "J: 0.151345464393\n",
      "J: 0.150817990038\n",
      "J: 0.150219014941\n",
      "J: 0.149441343623\n",
      "J: 0.148706672305\n",
      "J: 0.147985710571\n",
      "J: 0.14747642678\n",
      "J: 0.147080549098\n",
      "J: 0.146645838119\n",
      "J: 0.146358964395\n",
      "J: 0.146082047504\n",
      "J: 0.145795560232\n",
      "J: 0.145539173042\n",
      "J: 0.14521548899\n",
      "J: 0.144888400476\n",
      "J: 0.144692836886\n",
      "J: 0.144504432042\n",
      "J: 0.144322076401\n",
      "J: 0.144128138758\n",
      "J: 0.143918945695\n",
      "J: 0.143758082755\n",
      "J: 0.143528475694\n",
      "J: 0.143334625096\n",
      "J: 0.143144549369\n",
      "J: 0.142940733219\n",
      "J: 0.142761438727\n",
      "J: 0.142605525734\n",
      "J: 0.142467025795\n",
      "J: 0.142337939213\n",
      "J: 0.142204306252\n",
      "J: 0.142061123701\n",
      "J: 0.141989868754\n",
      "J: 0.141898084549\n",
      "J: 0.141812706996\n",
      "J: 0.141741519428\n",
      "J: 0.141627273869\n",
      "J: 0.141786506913\n",
      "J: 0.141575719682\n",
      "J: 0.141497228303\n",
      "J: 0.141437530497\n",
      "J: 0.141369685917\n",
      "J: 0.141322058043\n",
      "J: 0.141277132038\n",
      "J: 0.141223816049\n",
      "J: 0.141181987231\n",
      "J: 0.141147650122\n",
      "J: 0.141071609617\n",
      "J: 0.141047570064\n",
      "J: 0.141017884833\n",
      "J: 0.140988800244\n",
      "J: 0.14095813411\n",
      "J: 0.140938647871\n",
      "J: 0.1409111393\n",
      "J: 0.140886964719\n",
      "J: 0.140863022558\n",
      "J: 0.140838765235\n",
      "J: 0.140828242619\n",
      "J: 0.140816526355\n",
      "J: 0.140801076957\n",
      "J: 0.14078527998\n",
      "J: 0.140773814889\n",
      "J: 0.140747465791\n",
      "J: 0.140765683931\n",
      "J: 0.140739895648\n",
      "J: 0.140732616887\n",
      "J: 0.140722974489\n",
      "J: 0.14071679776\n",
      "J: 0.140709842139\n",
      "J: 0.14070193623\n",
      "J: 0.140695010202\n",
      "J: 0.140687035494\n",
      "J: 0.140676131846\n",
      "J: 0.140669007586\n",
      "J: 0.140662355236\n",
      "J: 0.140657749629\n",
      "J: 0.140653865933\n",
      "J: 0.140651138277\n",
      "J: 0.140646272678\n",
      "J: 0.140643423836\n",
      "J: 0.14063973215\n",
      "J: 0.140633979514\n",
      "J: 0.140635856003\n",
      "J: 0.140630333386\n",
      "J: 0.140626292238\n",
      "J: 0.140622876345\n",
      "J: 0.140619731749\n",
      "J: 0.140617140684\n",
      "J: 0.140614852613\n",
      "J: 0.140612738427\n",
      "J: 0.140611090113\n",
      "J: 0.140609311974\n",
      "J: 0.140606115737\n",
      "J: 0.14060501129\n",
      "J: 0.140603528553\n",
      "J: 0.140602046741\n",
      "J: 0.140600589094\n",
      "J: 0.140599679086\n",
      "J: 0.140598476791\n",
      "J: 0.140597758432\n",
      "J: 0.140596973323\n",
      "J: 0.140595835122\n",
      "J: 0.140595158952\n",
      "J: 0.140594113436\n",
      "J: 0.140593183303\n",
      "J: 0.140592813855\n",
      "J: 0.140592242711\n",
      "J: 0.14059176232\n",
      "J: 0.140591268069\n",
      "J: 0.140590859934\n",
      "J: 0.14059046369\n",
      "J: 0.140589935657\n",
      "J: 0.140589354221\n",
      "J: 0.140588927224\n",
      "J: 0.1405886319\n",
      "J: 0.140588457982\n",
      "J: 0.140588182801\n",
      "J: 0.140587955698\n",
      "J: 0.140587738825\n",
      "J: 0.14058747245\n",
      "J: 0.140587304225\n",
      "J: 0.140587072236\n",
      "J: 0.140586912524\n",
      "J: 0.140586775231\n",
      "J: 0.140586684294\n",
      "J: 0.14058658483\n",
      "J: 0.140586475163\n",
      "J: 0.140586355409\n",
      "J: 0.140586231109\n",
      "J: 0.140586094163\n",
      "J: 0.140585984954\n",
      "J: 0.14058590565\n",
      "J: 0.140585811961\n",
      "J: 0.140585778852\n",
      "J: 0.140585729971\n",
      "J: 0.140585677987\n",
      "J: 0.140585640042\n",
      "J: 0.140585530394\n",
      "J: 0.140585580861\n",
      "J: 0.14058547672\n",
      "J: 0.140585407012\n",
      "J: 0.1405853624\n",
      "J: 0.140585332444\n",
      "J: 0.140585303169\n",
      "J: 0.140585267415\n",
      "J: 0.140585234146\n",
      "J: 0.1405852002\n",
      "J: 0.140585165058\n",
      "J: 0.140585142582\n",
      "J: 0.140585125764\n",
      "J: 0.140585096338\n",
      "J: 0.140585079311\n",
      "J: 0.140585061492\n",
      "J: 0.14058504453\n",
      "J: 0.140585031633\n",
      "J: 0.140585002456\n",
      "J: 0.140584980021\n",
      "J: 0.140584962308\n",
      "J: 0.140584949207\n",
      "J: 0.140584941175\n",
      "J: 0.140584925809\n",
      "J: 0.140584912804\n",
      "J: 0.140584901001\n",
      "J: 0.140584890565\n",
      "J: 0.14058488307\n",
      "J: 0.140584875828\n",
      "J: 0.14058486017\n",
      "J: 0.140584855515\n",
      "J: 0.140584846367\n",
      "J: 0.140584841803\n",
      "J: 0.140584837142\n",
      "J: 0.140584829648\n",
      "J: 0.140584820612\n",
      "J: 0.140584813457\n",
      "J: 0.140584805798\n",
      "J: 0.140584799309\n",
      "J: 0.140584792962\n",
      "J: 0.14058478448\n",
      "J: 0.140584779757\n",
      "J: 0.140584776282\n",
      "J: 0.140584768081\n",
      "J: 0.140584764473\n",
      "J: 0.140584759783\n",
      "J: 0.140584749665\n",
      "J: 0.140584744312\n",
      "J: 0.140584738345\n",
      "J: 0.140584728801\n",
      "J: 0.14058472583\n",
      "J: 0.140584721374\n",
      "J: 0.14058471494\n",
      "J: 0.140584706801\n",
      "J: 0.140584697317\n",
      "J: 0.140584689712\n",
      "J: 0.140584683666\n",
      "J: 0.14058467718\n",
      "J: 0.140584673066\n",
      "J: 0.140584668243\n",
      "J: 0.1405846621\n",
      "J: 0.140584655403\n",
      "J: 0.140584648517\n",
      "J: 0.140584637293\n",
      "J: 0.140584631296\n",
      "J: 0.140584624156\n",
      "J: 0.140584618461\n",
      "J: 0.140584608795\n",
      "J: 0.140584600589\n",
      "J: 0.140584593804\n",
      "J: 0.140584581346\n",
      "J: 0.140584569733\n",
      "J: 0.140584558102\n",
      "J: 0.14058454817\n",
      "J: 0.140584538067\n",
      "J: 0.140584538131\n",
      "J: 0.14058452722\n",
      "J: 0.140584512356\n",
      "J: 0.140584503023\n",
      "J: 0.140584489648\n",
      "J: 0.140584475884\n",
      "J: 0.140584460811\n",
      "J: 0.140584439537\n",
      "J: 0.140584422699\n",
      "J: 0.140584403612\n",
      "J: 0.14058439216\n",
      "J: 0.140584351332\n",
      "J: 0.140584342642\n",
      "J: 0.140584316317\n",
      "J: 0.140584305855\n",
      "J: 0.14058427585\n",
      "J: 0.140584249266\n",
      "J: 0.140584215375\n",
      "J: 0.140584161966\n",
      "J: 0.140584268258\n",
      "J: 0.140584138621\n",
      "J: 0.140584099283\n",
      "J: 0.140584071617\n",
      "J: 0.140584025184\n",
      "J: 0.140583977085\n",
      "J: 0.140583911154\n",
      "J: 0.140583812803\n",
      "J: 0.140583734895\n",
      "J: 0.14058365727\n",
      "J: 0.140583577805\n",
      "J: 0.140583517458\n",
      "J: 0.140583464621\n",
      "J: 0.140583381851\n",
      "J: 0.140583288615\n",
      "J: 0.140583201699\n",
      "J: 0.140583074544\n",
      "J: 0.1405829803\n",
      "J: 0.140582866614\n",
      "J: 0.140582737239\n",
      "J: 0.140582648452\n",
      "J: 0.140582537075\n",
      "J: 0.140582324774\n",
      "J: 0.140582231046\n",
      "J: 0.140582084959\n",
      "J: 0.140581888517\n",
      "J: 0.140581626117\n",
      "J: 0.140581369657\n",
      "J: 0.140581127994\n",
      "J: 0.140580921125\n",
      "J: 0.1405807469\n",
      "J: 0.140580479698\n",
      "J: 0.140580275877\n",
      "J: 0.140580092149\n",
      "J: 0.140579573178\n",
      "J: 0.140579273676\n",
      "J: 0.140579019676\n",
      "J: 0.14057855656\n",
      "J: 0.140578313089\n",
      "J: 0.140578114363\n",
      "J: 0.14057743344\n",
      "J: 0.14057721708\n",
      "J: 0.140576710285\n",
      "J: 0.140576484757\n",
      "J: 0.140575527214\n",
      "J: 0.140574863209\n",
      "J: 0.140574094618\n",
      "J: 0.14057293008\n",
      "J: 0.14057316343\n",
      "J: 0.140572244681\n",
      "J: 0.140571085674\n",
      "J: 0.140570503425\n",
      "J: 0.140569683733\n",
      "J: 0.140569053047\n",
      "J: 0.140568150939\n",
      "J: 0.140566869805\n",
      "J: 0.140565931339\n",
      "J: 0.140565074356\n",
      "J: 0.14056430664\n",
      "J: 0.140563638145\n",
      "J: 0.140562952335\n",
      "J: 0.140562055294\n",
      "J: 0.140560971874\n",
      "J: 0.140559691524\n",
      "J: 0.140558527863\n",
      "J: 0.14055740212\n",
      "J: 0.140556412252\n",
      "J: 0.140555714065\n",
      "J: 0.140554996637\n",
      "J: 0.140553994435\n",
      "J: 0.140553079524\n",
      "J: 0.140551760433\n",
      "J: 0.14055038696\n",
      "J: 0.14054940789\n",
      "J: 0.140549377409\n",
      "J: 0.140548690393\n",
      "J: 0.140547770744\n",
      "J: 0.140547194629\n",
      "J: 0.140546583735\n",
      "J: 0.140545885392\n",
      "J: 0.140545086407\n",
      "J: 0.140544018367\n",
      "J: 0.140543299637\n",
      "J: 0.140542752617\n",
      "J: 0.140541973932\n",
      "J: 0.140541619207\n",
      "J: 0.140541248892\n",
      "J: 0.140540687621\n",
      "J: 0.140540197193\n",
      "J: 0.140539833475\n",
      "J: 0.140538841163\n",
      "J: 0.140538718156\n",
      "J: 0.140537969725\n",
      "J: 0.140537584591\n",
      "J: 0.140537193506\n",
      "J: 0.140536748697\n",
      "J: 0.140536591016\n",
      "J: 0.140535714933\n",
      "J: 0.140535466267\n",
      "J: 0.140534866417\n",
      "J: 0.140535083145\n",
      "J: 0.140534597741\n",
      "J: 0.140534206348\n",
      "J: 0.140533952369\n",
      "J: 0.140533703898\n",
      "J: 0.14053354755\n",
      "J: 0.140533394139\n",
      "J: 0.140533227185\n",
      "J: 0.140533089689\n",
      "J: 0.140532925301\n",
      "J: 0.140532659428\n",
      "J: 0.140532557394\n",
      "J: 0.140532414884\n",
      "J: 0.140532353884\n",
      "J: 0.14053221563\n",
      "J: 0.140532125217\n",
      "J: 0.140532027908\n",
      "J: 0.140531834856\n",
      "J: 0.140531876224\n",
      "J: 0.140531695973\n",
      "J: 0.140531508727\n",
      "J: 0.140531393699\n",
      "J: 0.140531287166\n",
      "J: 0.140531230947\n",
      "J: 0.140531152615\n",
      "J: 0.14053110042\n",
      "J: 0.140531052461\n",
      "J: 0.140530941805\n",
      "J: 0.14053104929\n",
      "J: 0.140530889888\n",
      "J: 0.140530783069\n",
      "J: 0.140530709078\n",
      "J: 0.140530658617\n",
      "J: 0.140530621241\n",
      "J: 0.140530589132\n",
      "J: 0.140530547441\n",
      "J: 0.140530505343\n",
      "J: 0.140530463225\n",
      "J: 0.140530404813\n",
      "J: 0.14053036389\n",
      "J: 0.140530323857\n",
      "J: 0.140530283906\n",
      "J: 0.140530259288\n",
      "J: 0.140530218724\n",
      "J: 0.14053019866\n",
      "J: 0.140530153505\n",
      "J: 0.140530131972\n",
      "J: 0.140530100814\n",
      "J: 0.140530057416\n",
      "J: 0.140530073406\n",
      "J: 0.140530033205\n",
      "J: 0.14053000914\n",
      "J: 0.140529994449\n",
      "J: 0.140529978912\n",
      "J: 0.140529955194\n",
      "J: 0.140529927077\n",
      "J: 0.140529897174\n",
      "J: 0.140529880163\n",
      "J: 0.140529868367\n",
      "J: 0.140529852577\n",
      "J: 0.140529843002\n",
      "J: 0.14052983238\n",
      "J: 0.140529817483\n",
      "J: 0.140529806376\n",
      "J: 0.140529792731\n",
      "J: 0.140529773447\n",
      "J: 0.140529765455\n",
      "J: 0.140529752155\n",
      "J: 0.140529745351\n",
      "J: 0.14052973515\n",
      "J: 0.140529731917\n",
      "J: 0.140529718906\n",
      "J: 0.140529714157\n",
      "J: 0.140529708407\n",
      "J: 0.140529698375\n",
      "J: 0.14052968781\n",
      "J: 0.140529673905\n",
      "J: 0.140529666981\n",
      "J: 0.14052966045\n",
      "J: 0.140529658369\n"
     ]
    }
   ],
   "source": [
    "pc3 = PClassificationMLC(weighting=True, verticalWeighting=True)\n",
    "pc3.fit(X, Y_nan_part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction: use the minimum of positive entry score of the same example as threshold.  \n",
    "Evaluation: use F1 on all unknown entries (as a 1D array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred3 = pc3.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_index = np.nan_to_num(Y_nan_part).astype(np.bool)\n",
    "nan_index = np.isnan(Y_nan_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truths = Y[nan_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = []\n",
    "preds = []\n",
    "for k in range(int(K/2), K):\n",
    "    val = Y_pred3[:, k][pos_index[:, k]]\n",
    "    th = np.min(val)\n",
    "    #th = np.mean(val)\n",
    "    thresholds.append(th)\n",
    "    preds += (Y_pred3[nan_index[:,k], k] >= th).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.sum(ground_truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.sum(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016199797502531216"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score_nowarn(ground_truths, preds, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35466"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.008921933085501859, 0.087912087912087919, 0.016199797502531216, None)"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(ground_truths, preds, average='binary', warn_for=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilabel p-classification with (some playlist fully observed) and (unknowns in test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, K = Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_nan_part2 = Y.copy().astype(np.float)\n",
    "np.random.seed(8967321)\n",
    "rand_num = int(0.4 * N)\n",
    "ones = 0\n",
    "for k in range(int(K/2), K):\n",
    "    randix = np.random.permutation(np.arange(N))[:rand_num]\n",
    "    Y_nan_part2[randix, k] = np.nan\n",
    "    ones += Y[randix, k].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.sum(Y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.nansum(Y_nan_part, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.sum(Y, axis=0) - np.nansum(Y_nan_part, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ones  # number of positive entries selected to be masked as NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_nan.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of NaN entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35466"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isnan(Y_nan_part2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.sum(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C: 1, p: 1, weighting: True\n",
      "J: 0.214785992218\n",
      "J: 7.40582227984e+230\n",
      "J: 1.25494323328e+74\n",
      "J: 1.35208157252e+22\n",
      "J: 107951.338682\n",
      "J: 0.519249911069\n",
      "J: 0.210377936143\n",
      "J: 0.206502744224\n",
      "J: 0.202959380742\n",
      "J: 0.200024253201\n",
      "J: 0.197185214155\n",
      "J: 0.193248557826\n",
      "J: 0.191074074388\n",
      "J: 0.183795976999\n",
      "J: 0.190025490938\n",
      "J: 0.181967080713\n",
      "J: 0.179839158098\n",
      "J: 0.178722531319\n",
      "J: 0.177335661593\n",
      "J: 0.176211472306\n",
      "J: 0.175108335482\n",
      "J: 0.17270628711\n",
      "J: 0.170749009952\n",
      "J: 0.168370028943\n",
      "J: 0.165356747363\n",
      "J: 0.16335568034\n",
      "J: 0.162194210855\n",
      "J: 0.161300022978\n",
      "J: 0.160777624946\n",
      "J: 0.160296842303\n",
      "J: 0.159672027091\n",
      "J: 0.158878677826\n",
      "J: 0.157314541218\n",
      "J: 0.155788793128\n",
      "J: 0.154238018618\n",
      "J: 0.153075070865\n",
      "J: 0.151912412371\n",
      "J: 0.15184910652\n",
      "J: 0.151408347521\n",
      "J: 0.150949759603\n",
      "J: 0.150431030747\n",
      "J: 0.149895493384\n",
      "J: 0.149240980623\n",
      "J: 0.148596577176\n",
      "J: 0.148038337755\n",
      "J: 0.147639094361\n",
      "J: 0.147228821169\n",
      "J: 0.146855881103\n",
      "J: 0.14646370558\n",
      "J: 0.146111272178\n",
      "J: 0.145713265023\n",
      "J: 0.145342228754\n",
      "J: 0.144968534374\n",
      "J: 0.144747423171\n",
      "J: 0.144489358997\n",
      "J: 0.144376180268\n",
      "J: 0.144153501891\n",
      "J: 0.144042751429\n",
      "J: 0.143900367054\n",
      "J: 0.143639454808\n",
      "J: 0.143418428415\n",
      "J: 0.143184075337\n",
      "J: 0.143017114422\n",
      "J: 0.142876201603\n",
      "J: 0.142741661503\n",
      "J: 0.142592121325\n",
      "J: 0.142512395301\n",
      "J: 0.142402258482\n",
      "J: 0.142240669698\n",
      "J: 0.142075540057\n",
      "J: 0.141946083252\n",
      "J: 0.141806304281\n",
      "J: 0.141724919624\n",
      "J: 0.141655726725\n",
      "J: 0.141596236584\n",
      "J: 0.141551229774\n",
      "J: 0.141464496528\n",
      "J: 0.141433297064\n",
      "J: 0.141334181061\n",
      "J: 0.141303107951\n",
      "J: 0.141265859829\n",
      "J: 0.141230529938\n",
      "J: 0.141210398157\n",
      "J: 0.14118453743\n",
      "J: 0.141166922454\n",
      "J: 0.141137815184\n",
      "J: 0.141100320437\n",
      "J: 0.141058933883\n",
      "J: 0.14103547877\n",
      "J: 0.141014789117\n",
      "J: 0.141000406599\n",
      "J: 0.140982187823\n",
      "J: 0.140958854341\n",
      "J: 0.140938382377\n",
      "J: 0.140924618577\n",
      "J: 0.140902939217\n",
      "J: 0.140890783773\n",
      "J: 0.140881911306\n",
      "J: 0.140867575707\n",
      "J: 0.140859348941\n",
      "J: 0.140860599035\n",
      "J: 0.140852587763\n",
      "J: 0.140842332552\n",
      "J: 0.140834590549\n",
      "J: 0.14082523691\n",
      "J: 0.140816068624\n",
      "J: 0.140806645621\n",
      "J: 0.14079653642\n",
      "J: 0.140790655362\n",
      "J: 0.140786490981\n",
      "J: 0.140782544476\n",
      "J: 0.140778897365\n",
      "J: 0.140773273533\n",
      "J: 0.140766856423\n",
      "J: 0.140761895923\n",
      "J: 0.140756904628\n",
      "J: 0.140753025791\n",
      "J: 0.140748607324\n",
      "J: 0.140745703111\n",
      "J: 0.140743516618\n",
      "J: 0.140741837335\n",
      "J: 0.140738804515\n",
      "J: 0.140737440713\n",
      "J: 0.140735529945\n",
      "J: 0.140732677951\n",
      "J: 0.140729760631\n",
      "J: 0.140728124322\n",
      "J: 0.140726595257\n",
      "J: 0.140725750795\n",
      "J: 0.14072477804\n",
      "J: 0.140723516269\n",
      "J: 0.140722736696\n",
      "J: 0.140720929211\n",
      "J: 0.140719155103\n",
      "J: 0.140718334298\n",
      "J: 0.140717459898\n",
      "J: 0.140716882938\n",
      "J: 0.140716180641\n",
      "J: 0.140715395184\n",
      "J: 0.140714681594\n",
      "J: 0.140713929063\n",
      "J: 0.140713726816\n",
      "J: 0.140712642863\n",
      "J: 0.14071248915\n",
      "J: 0.14071217212\n",
      "J: 0.140711795997\n",
      "J: 0.140711392865\n",
      "J: 0.140711036375\n",
      "J: 0.140710569514\n",
      "J: 0.140710343654\n",
      "J: 0.140709864394\n",
      "J: 0.140709626877\n",
      "J: 0.140709504805\n",
      "J: 0.140709274055\n",
      "J: 0.140709152049\n",
      "J: 0.140708953849\n",
      "J: 0.140708838604\n",
      "J: 0.1407086406\n",
      "J: 0.14070874644\n",
      "J: 0.140708519416\n",
      "J: 0.140708322304\n",
      "J: 0.14070819562\n",
      "J: 0.140708092713\n",
      "J: 0.14070800497\n",
      "J: 0.14070793328\n",
      "J: 0.140707844422\n",
      "J: 0.140707776517\n",
      "J: 0.140707710878\n",
      "J: 0.140707596446\n",
      "J: 0.140707587253\n",
      "J: 0.140707535826\n",
      "J: 0.140707489107\n",
      "J: 0.140707409681\n",
      "J: 0.140707380829\n",
      "J: 0.140707342407\n",
      "J: 0.140707297611\n",
      "J: 0.14070726805\n",
      "J: 0.140707180833\n",
      "J: 0.140707248558\n",
      "J: 0.140707136211\n",
      "J: 0.140707080152\n",
      "J: 0.14070704563\n",
      "J: 0.140707025528\n",
      "J: 0.140707004135\n",
      "J: 0.140706987364\n",
      "J: 0.140706968479\n",
      "J: 0.140706943317\n",
      "J: 0.140706914087\n",
      "J: 0.140706888349\n",
      "J: 0.140706861668\n",
      "J: 0.1407068434\n",
      "J: 0.14070682984\n",
      "J: 0.140706808387\n",
      "J: 0.140706794303\n",
      "J: 0.140706771387\n",
      "J: 0.140706776977\n",
      "J: 0.140706758044\n",
      "J: 0.14070673713\n",
      "J: 0.140706723608\n",
      "J: 0.140706709792\n",
      "J: 0.140706700263\n",
      "J: 0.140706693512\n",
      "J: 0.140706685807\n",
      "J: 0.140706678728\n",
      "J: 0.140706668064\n",
      "J: 0.14070665466\n",
      "J: 0.140706645221\n",
      "J: 0.140706634838\n",
      "J: 0.140706632906\n"
     ]
    }
   ],
   "source": [
    "pc4 = PClassificationMLC(weighting=True, verticalWeighting=True)\n",
    "pc4.fit(X, Y_nan_part2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction: use the minimum of positive entry score of the same example as threshold.  \n",
    "Evaluation: use F1 on all unknown entries (as a 1D array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred4 = pc4.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_index = np.nan_to_num(Y_nan_part2).astype(np.bool)\n",
    "nan_index = np.isnan(Y_nan_part2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truths = Y[nan_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = []\n",
    "preds = []\n",
    "for k in range(int(K/2), K):\n",
    "    val = Y_pred4[:, k][pos_index[:, k]]\n",
    "    th = np.min(val)\n",
    "    #th = np.mean(val)\n",
    "    thresholds.append(th)\n",
    "    preds += (Y_pred4[nan_index[:,k], k] >= th).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.sum(ground_truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.sum(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011895910780669145"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score_nowarn(ground_truths, preds, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0066170388751033912, 0.058823529411764705, 0.011895910780669145, None)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(ground_truths, preds, average='binary', warn_for=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(ground_truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2418"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.logical_and(ground_truths, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011895910780669145"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 * 16 / (272+2418)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
