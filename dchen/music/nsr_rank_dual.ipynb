{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "from scipy.sparse import issparse, csc_matrix, coo_matrix, lil_matrix, isspmatrix_coo, isspmatrix_csc\n",
    "import cyipopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings0 = np.seterr(all='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NSR_Rank_Dual(cyipopt.problem):\n",
    "    \n",
    "    def __init__(self, X_train, Y_train, user_playlist_indices):\n",
    "        \"\"\"\n",
    "        Initialisation and computing shared data.\n",
    "            Input:\n",
    "                - X: feature matrix, M x D\n",
    "                - Y: label matrix,   M x N\n",
    "        \"\"\"\n",
    "        assert isspmatrix_coo(Y_train)\n",
    "        assert X_train.shape[0] == Y_train.shape[0]\n",
    "        self.X = X_train\n",
    "        self.Y = Y_train\n",
    "        self.M, self.D = self.X.shape\n",
    "        self.N = self.Y.shape[1]\n",
    "        self.cliques = user_playlist_indices\n",
    "        assert np.all(np.arange(self.N) == np.asarray(sorted([k for clq in self.cliques for k in clq])))\n",
    "        self.U = len(self.cliques)\n",
    "        self.preprocess()\n",
    "        self.trained = False\n",
    "\n",
    "    def init_var(self):\n",
    "        \"\"\"\n",
    "            Initial feasible guess:\n",
    "              y_n^i = 0: \\theta_i^n = +0.001,                   \n",
    "              y_m^i = 1: \\theta_i^m = -0.001 * (M / M_i^+ - 1), \n",
    "            which satisfy constraint:\n",
    "              \\sum_m theta_i^m + \\sum_n theta_i^n = 0, i=1...N\n",
    "        \"\"\"\n",
    "        W0 = 0.001 * np.ones((self.N, self.M), dtype=np.float)\n",
    "        row, col = self.pcol, self.prow  # NOTE: Y (M x N), W (N x M)\n",
    "        W0[row, col] = -0.001 * ((self.M / self.Msum)[self.pcol] - 1)\n",
    "        return W0.ravel()\n",
    "    \n",
    "    def preprocess(self):\n",
    "        \"\"\"\n",
    "            Compute shared data\n",
    "        \"\"\"\n",
    "        M, N = self.M, self.N\n",
    "        self.EPS = 1e-8\n",
    "        \n",
    "        self.Msum = self.Y.tocsc().sum(axis=0).A.reshape(-1)  # number of songs per playlist\n",
    "        self.P = np.log(self.N) + np.log(self.Msum)\n",
    "        self.pl2u = np.zeros(self.N, dtype=np.int)\n",
    "        for u in range(self.U):\n",
    "            clq = self.cliques[u]\n",
    "            self.pl2u[clq] = u\n",
    "        self.u2pl = {i: clq for i, clq in enumerate(self.cliques)}\n",
    "        \n",
    "        self.prow = self.Y.row\n",
    "        self.pcol = self.Y.col\n",
    "        \n",
    "        # sparse matrix to hold the jacobian structure\n",
    "        self.js = lil_matrix((N, N * M), dtype=np.bool)  # N constraints in total\n",
    "        Mvec = np.arange(M)\n",
    "        for k in range(N):\n",
    "            self.js[k, k * M + Mvec] = True\n",
    "        self.js = self.js.tocoo()\n",
    "        \n",
    "        # Jacobian of constraints\n",
    "        self.OneNM = np.ones(N * M, dtype=np.float)\n",
    "    \n",
    "    \n",
    "    def fit(self, C):\n",
    "        assert C > 0\n",
    "        self.C = C   # regularisation constant\n",
    "        M, N = self.M, self.N\n",
    "        row, col = self.pcol, self.prow  # NOTE: Y (M x N), W (N x M)\n",
    "        \n",
    "        # constraints\n",
    "        # -1e6 <= theta_i^m <= -EPS, y_m^i = 1\n",
    "        #  EPS <= theta_i^n <= 1e6,  y_n^i = 0\n",
    "        LB = np.full((N, M), self.EPS, dtype=np.float)\n",
    "        LB[row, col] = -1e6\n",
    "        UB = np.full((N, M), 1e6, dtype=np.float)\n",
    "        UB[row, col] = -self.EPS\n",
    "        \n",
    "        super(NSR_Rank_Dual, self).__init__(\n",
    "            n = N * M,        # number of variables\n",
    "            m = N,            # number of constraints\n",
    "            lb = LB.ravel(),  # lower bounds on variables\n",
    "            ub = UB.ravel(),  # upper bounds on variables\n",
    "            cl = np.zeros(N), # lower bounds on constraints: equality constraints\n",
    "            cu = np.zeros(N)  # upper bounds on constraints: equality constraints\n",
    "        )\n",
    "  \n",
    "        # Set solver options, https://www.coin-or.org/Ipopt/documentation/node51.html\n",
    "        self.addOption(b'mu_strategy', b'adaptive')\n",
    "        self.addOption(b'max_iter', int(1e4))\n",
    "        self.addOption(b'tol', 1e-7)\n",
    "        self.addOption(b'acceptable_tol', 1e-5)\n",
    "        #self.addOption(b'derivative_test', b'first-order')\n",
    "        #self.addOption(b'acceptable_constr_viol_tol', 1e-6)\n",
    "        self.addOption(b'linear_solver', b'ma57')\n",
    "\n",
    "        #try:\n",
    "        w, info = super(NSR_Rank_Dual, self).solve(self.init_var())\n",
    "        print(info['status'], info['status_msg'])\n",
    "        self.trained = True\n",
    "        self.dual2primal(w)\n",
    "        #except:\n",
    "        #    self.trained = False\n",
    "        #    print('Optimisation failed')\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        assert self.trained is True, 'Model has yet to be trained!'\n",
    "        M, N, U, D = self.M, self.N, self.U, self.D\n",
    "        assert X_test.shape[1] == D\n",
    "        Y_pred = np.zeros((X_test.shape[0], N))\n",
    "        for k in range(N):\n",
    "            u = self.pl2u[k]\n",
    "            vu = self.V[u, :]\n",
    "            wk = self.WP[k, :]\n",
    "            mu = self.mu\n",
    "            Y_pred[:, k] = np.dot(X_test, vu + wk + mu)\n",
    "        return Y_pred\n",
    "  \n",
    "\n",
    "    def dual2primal(self, w):\n",
    "        M, N, D, U, C = self.M, self.N, self.D, self.U, self.C\n",
    "        X = self.X\n",
    "        assert w.shape == (N * M,)\n",
    "        # assert np.isclose(w.sum(), 0)   # check for one constraint\n",
    "        print('max: %g, min: %g, sum: %g' % (w.max(), w.min(), w.sum()))\n",
    "        W = w.reshape(N, M)\n",
    "        self.V = np.zeros((U, D), dtype=np.float)\n",
    "        self.WP = np.zeros((N, D), dtype=np.float)\n",
    "        self.mu = -np.dot(W.sum(axis=0), X) / C\n",
    "        for u in range(U):\n",
    "            clq = self.u2pl[u]\n",
    "            self.V[u, :] = -W[clq, :].sum(axis=0).dot(X) * U / C\n",
    "        for k in range(N):\n",
    "            self.WP[k, :] = -W[k, :].dot(X) * N / C\n",
    "        \n",
    "        \n",
    "    def objective(self, w):\n",
    "        \"\"\"\n",
    "            The callback for calculating the objective\n",
    "        \"\"\"\n",
    "        # self.last_w[:] = w\n",
    "        t0 = time.time()\n",
    "        M, N, D, U, C = self.M, self.N, self.D, self.U, self.C\n",
    "        X = self.X\n",
    "        assert w.shape == (N * M,)\n",
    "        W = w.reshape(N, M)\n",
    "        J1 = 0.\n",
    "        for u in range(U):\n",
    "            Tu = W[self.u2pl[u], :].sum(axis=0)\n",
    "            J1 += Tu.dot(X).dot(X.T).dot(Tu)\n",
    "            \n",
    "        J2 = 0.\n",
    "        for k in range(N):\n",
    "            Tk = W[k, :]\n",
    "            J2 += Tk.dot(X).dot(X.T).dot(Tk)\n",
    "        \n",
    "        Tmu = W.sum(axis=0)\n",
    "        J3 = Tmu.dot(X).dot(X.T).dot(Tmu)\n",
    "        \n",
    "        row, col = self.pcol, self.prow  # NOTE: Y (M x N), W (N x M)\n",
    "        Tp = W[row, col]\n",
    "        J4 = np.dot(Tp, 1 - self.P[self.pcol] - np.log(-Tp))\n",
    "            \n",
    "        J = (U * J1 + N * J2 + J3) * 0.5 / C + J4\n",
    "        \n",
    "        #print('Eval f(): %g, %.1f seconds' % (J, time.time() - t0))\n",
    "            \n",
    "        return J\n",
    "        \n",
    "\n",
    "    def gradient(self, w):\n",
    "        \"\"\"\n",
    "            The callback for calculating the gradient\n",
    "        \"\"\"\n",
    "        t0 = time.time()\n",
    "        M, N, D, U, C = self.M, self.N, self.D, self.U, self.C\n",
    "        X = self.X\n",
    "        assert w.shape == (N * M,)\n",
    "        W = w.reshape(N, M)\n",
    "        dW = np.zeros((N, M), dtype=np.float)\n",
    "        Wsum = W.sum(axis=0)\n",
    "        for k in range(N):\n",
    "            u = self.pl2u[k]\n",
    "            clq = self.u2pl[u]\n",
    "            T = U * W[clq, :].sum(axis=0) + N * W[k, :] + Wsum\n",
    "            dW[k, :] = np.dot(X, X.T.dot(T)) / C\n",
    "        \n",
    "        row, col = self.pcol, self.prow  # NOTE: Y (M x N), W (N x M)\n",
    "        Tp = W[row, col]\n",
    "        dW[row, col] -= self.P[self.pcol] + np.log(-Tp)\n",
    "        g = dW.ravel()\n",
    "        #print('Eval g(): |g|=%g, %.1f seconds' % (np.sqrt(np.dot(g, g)), time.time() - t0))\n",
    "        return g\n",
    "    \n",
    "\n",
    "    def constraints(self, w):\n",
    "        \"\"\"\n",
    "            The callback for calculating the constraints\n",
    "        \"\"\"\n",
    "        M, N = self.M, self.N\n",
    "        assert w.shape == (N * M,)\n",
    "        W = w.reshape(N, M)\n",
    "        return W.sum(axis=1)\n",
    "    \n",
    "    \n",
    "    def jacobianstructure(self):\n",
    "        \"\"\"\n",
    "            The sparse structure (i.e., rows, cols) of the Jacobian matrix\n",
    "        \"\"\"\n",
    "        return self.js.row, self.js.col\n",
    "        \n",
    "    \n",
    "    def jacobian(self, w):\n",
    "        \"\"\"\n",
    "            The callback for calculating the Jacobian of constraints\n",
    "        \"\"\"\n",
    "        return self.OneNM\n",
    "    \n",
    "        \n",
    "#     def intermediate(\n",
    "#             self,\n",
    "#             alg_mod,\n",
    "#             iter_count,\n",
    "#             obj_value,\n",
    "#             inf_pr,\n",
    "#             inf_du,\n",
    "#             mu,\n",
    "#             d_norm,\n",
    "#             regularization_size,\n",
    "#             alpha_du,\n",
    "#             alpha_pr,\n",
    "#             ls_trials\n",
    "#         ):\n",
    "#         \"\"\"\n",
    "#             The intermediate callback\n",
    "#         \"\"\"\n",
    "#         print('Iter %5d: %20.6f' % (iter_count, obj_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import gzip\n",
    "import pickle as pkl\n",
    "from scipy.optimize import check_grad\n",
    "#datasets = ['aotm2011', '30music']\n",
    "sys.path.append('src')\n",
    "from tools import create_dataset, dataset_names, nLabels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dix = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = datasets[dix]\n",
    "# data_dir = 'data/%s/setting1' % dataset_name\n",
    "# fxtrain = os.path.join(data_dir, 'X_train.pkl.gz')\n",
    "# fytrain = os.path.join(data_dir, 'Y_train.pkl.gz')\n",
    "# fcliques = os.path.join(data_dir, 'cliques_train.pkl.gz')\n",
    "# X_train = pkl.load(gzip.open(fxtrain, 'rb'))\n",
    "# Y_train = pkl.load(gzip.open(fytrain, 'rb'))\n",
    "# cliques = pkl.load(gzip.open(fcliques, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bibtex 159\n"
     ]
    }
   ],
   "source": [
    "dataset_name = dataset_names[dix]\n",
    "nLabels = nLabels_dict[dataset_name]\n",
    "print(dataset_name, nLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = create_dataset(dataset_name, train_data=True)\n",
    "X_test,  Y_test  = create_dataset(dataset_name, train_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mean = np.mean(X_train, axis=0).reshape((1, -1))\n",
    "X_train_std = np.std(X_train, axis=0).reshape((1, -1)) + 10 ** (-6)\n",
    "X_train -= X_train_mean\n",
    "X_train /= X_train_std\n",
    "X_test  -= X_train_mean\n",
    "X_test  /= X_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dataset_info(X_train, Y_train, X_test, Y_test):\n",
    "    N_train, D = X_train.shape\n",
    "    K = Y_train.shape[1]\n",
    "    N_test = X_test.shape[0]\n",
    "    print('%-45s %s' % ('Number of training examples:', '{:,}'.format(N_train)))\n",
    "    print('%-45s %s' % ('Number of test examples:', '{:,}'.format(N_test)))\n",
    "    print('%-45s %s' % ('Number of features:', '{:,}'.format(D)))\n",
    "    print('%-45s %s' % ('Number of labels:', '{:,}'.format(K)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:                                      bibtex\n",
      "Number of training examples:                  4,880\n",
      "Number of test examples:                      2,515\n",
      "Number of features:                           1,836\n",
      "Number of labels:                             159\n"
     ]
    }
   ],
   "source": [
    "print('%-45s %s' % ('Dataset:', dataset_name))\n",
    "print_dataset_info(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_grad_loop(obj, grad, w0):\n",
    "    eps = 1.49e-08\n",
    "    w = np.zeros_like(w0)\n",
    "    for i in range(len(w0)):\n",
    "        if (i+1) % 1000 == 0:\n",
    "            sys.stdout.write('\\r%d / %d' % (i+1, len(w0)))\n",
    "        wi1 = w0.copy()\n",
    "        wi2 = w0.copy()\n",
    "        wi1[i] = wi1[i] - eps\n",
    "        wi2[i] = wi2[i] + eps\n",
    "        J1 = obj(wi1)\n",
    "        J2 = obj(wi2)\n",
    "        w[i] = (J2 - J1) / (2 * eps)\n",
    "        #print(w[i])\n",
    "    w1 = grad(w0)\n",
    "    diff = w1 - w\n",
    "    return np.sqrt(np.dot(diff, diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cliques = [[0], [1], [2, 3, 4], [5, 6, 7, 8, 9], [10, 11], [12, 13]]\n",
    "cliques = [np.arange(Y_train.shape[1])]\n",
    "model = NSR_Rank_Dual(X_train, coo_matrix(Y_train), cliques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = model.init_var()\n",
    "model.C = 1\n",
    "#%lprun -f accumulate_risk \\\n",
    "#%lprun -f objective \\\n",
    "#check_grad(model.objective, model.gradient, w0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check_grad_loop(model.objective, model.gradient, w0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 b'Algorithm stopped at a point that was converged, not to \"desired\" tolerances, but to \"acceptable\" tolerances (see the acceptable-... options).'\n",
      "max: 0.000582671, min: -0.000219973, sum: 9.65545e-09\n"
     ]
    }
   ],
   "source": [
    "model.fit(C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import calc_RPrecision_HitRate\n",
    "def calc_RP(Y_true, Y_pred):\n",
    "    assert Y_true.shape == Y_pred.shape\n",
    "    rps = []\n",
    "    for j in range(Y_true.shape[1]):\n",
    "        y_true = Y_true[:, j]\n",
    "        y_pred = Y_pred[:, j]\n",
    "        rp, _ = calc_RPrecision_HitRate(y_true, y_pred)\n",
    "        rps.append(rp)\n",
    "    return rps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rps = calc_RP(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.384380044412107"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
