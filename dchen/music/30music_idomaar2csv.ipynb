{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing: convert idomaar to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert [30Music dataset](http://crowdrec.eu/2015/11/30music-dataset-release/) from [idomaar format](https://github.com/crowdrec/idomaar/wiki/DATA-FORMAT) to CSV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys, csv, json#, gc\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COLUMNS = ['Type', 'ID', 'Timestamp', 'Properties', 'LinkedEntities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'data/30music'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert albums data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "falbums = os.path.join(data_dir, 'albums.idomaar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with open(falbums) as tsvin:\n",
    "#    tsvin = csv.reader(tsvin, delimiter='\\t')\n",
    "#    for row in tsvin:\n",
    "#        if len(row[4]) > 2:\n",
    "#            print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "albums = pd.read_csv(falbums, delimiter='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "albums.columns = COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "albums.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "albums[albums['Timestamp'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "albums[albums['LinkedEntities'] != '{}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "albums.set_index('ID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "albums.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with illegally formated JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false\n",
    "cnt = 0\n",
    "for ix in albums.index:\n",
    "    try:\n",
    "        prop = json.loads(albums.loc[ix, 'Properties'])\n",
    "        aa = (prop['MBID'], prop['title'])\n",
    "    except:\n",
    "        cnt += 1\n",
    "        #print(ix)\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_properties(props, debug=False): \n",
    "    props = props.replace(';', ',')\n",
    "    try:\n",
    "        prop = json.loads(props)\n",
    "    except:\n",
    "        # deal with duplicated \" in json string\n",
    "        props = props.replace('\"title\":', '\"TITLE\":').replace('\"', '').replace('\\\\', '')\\\n",
    "                     .replace('MBID:', '\"MBID\":\"').replace(', TITLE:', '\", \"title\":\"').replace('}', '\"}')\n",
    "        if debug is True: print(props)\n",
    "        prop = json.loads(props)\n",
    "    return pd.Series({'MBID': prop['MBID'], 'Title': prop['title']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = albums.loc[708, 'Properties']\n",
    "props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json.loads(props)  # causes exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_properties(props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_df = albums['Properties'].apply(lambda s: parse_properties(s, debug=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#albums = albums.merge(prop_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#albums.drop(['Type', 'Timestamp', 'Properties', 'LinkedEntities'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcsv_falbums = os.path.join(data_dir, 'albums.csv')\n",
    "prop_df.to_csv(fcsv_falbums, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(fcsv_falbums, index_col='ID', sep=';').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert artists data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fartists = os.path.join(data_dir, 'persons.idomaar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artists = pd.read_csv(fartists, delimiter='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists.columns = COLUMNS\n",
    "artists.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artists.set_index('ID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists[artists['Timestamp'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists[artists['LinkedEntities'] != '{}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artists.drop(['Timestamp', 'LinkedEntities'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(artists.shape)\n",
    "artists.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_artist_properties(props): \n",
    "    props = props.replace(';', ',')\n",
    "    try:\n",
    "        prop = json.loads(props)\n",
    "    except:\n",
    "        print(props)\n",
    "        sys.exit(0)\n",
    "    return pd.Series({'MBID': prop['MBID'], 'Name': prop['name']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists_prop = artists['Properties'].apply(lambda s: parse_artist_properties(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#artists_prop = artists['Properties'].apply(lambda s: \\\n",
    "#                                           pd.Series({'MBID': json.loads(s)['MBID'], 'Name': json.loads(s)['name']}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set(list(artists.index)) - set(list(artists_prop.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(artists_prop.shape)\n",
    "artists_prop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#artists_prop['Type'] = 'person'\n",
    "#artists_prop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#artists.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#artists = artists.merge(artists_prop, left_index=True, right_index=True)\n",
    "#print(artists.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with duplications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(artists.shape[0])\n",
    "print(artists.index.unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artists_prop.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artists_prop['Duplicated'] = artists_prop['ID'].duplicated(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artists_nodup = artists_prop[artists_prop['Duplicated'] == False].copy()\n",
    "artists_dup = artists_prop[artists_prop['Duplicated'] == True].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artists_nodup.set_index('ID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(artists_dup.shape[0])\n",
    "artists_dup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "print(artists_dup.shape[0])\n",
    "for ix in artists_dup.index:\n",
    "    artist_id = artists_dup.loc[ix, 'ID']\n",
    "    mbid = artists_dup.loc[ix, 'MBID']; mbid = str(mbid) if mbid is not None else mbid\n",
    "    name = artists_dup.loc[ix, 'Name']; name = str(name) if name is not None else name\n",
    "    \n",
    "    # update existing artist info\n",
    "    mbid0 = artists_nodup.loc[artist_id, 'MBID']; mbid0 = str(mbid0) if mbid0 is not None else mbid0\n",
    "    name0 = artists_nodup.loc[artist_id, 'Name']; name0 = str(name0) if name0 is not None else name0\n",
    "    \n",
    "    if mbid is not None:\n",
    "        if mbid0 is None or len(mbid) > len(mbid0): \n",
    "            artists_nodup.loc[artist_id, 'MBID'] = mbid\n",
    "    if name is not None:\n",
    "        if name0 is None or len(name) > len(name0):\n",
    "            artists_nodup.loc[artist_id, 'Name'] = name\n",
    "            \n",
    "    cnt += 1\n",
    "    if cnt % 100 == 0:\n",
    "        sys.stdout.write('\\r%d' % (cnt))\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artists_nodup.drop('Duplicated', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(artists_nodup.shape[0])\n",
    "print(artists_nodup.index.unique().shape[0])\n",
    "artists_nodup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcsv_artists = os.path.join(data_dir, 'persons.csv')\n",
    "artists_nodup.to_csv(fcsv_artists, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(fcsv_artists, index_col='ID', sep=';').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert users data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fusers = os.path.join(data_dir, 'users.idomaar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users = pd.read_csv(fusers, header=None, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.columns = COLUMNS[:-1]\n",
    "users.set_index('ID', inplace=True)\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_user_properties(props):\n",
    "    props = props.replace(';', ',')\n",
    "    try:\n",
    "        prop = json.loads(props)\n",
    "    except:\n",
    "        props = props.replace('\"\"', 'null').replace(':,', ':null,')\n",
    "        try: prop = json.loads(props)\n",
    "        except: print(props); sys.exit(0)\n",
    "    return pd.Series({'Username': prop['lastfm_username'],\n",
    "                          'Gender': str.upper(prop['gender']) if prop['gender'] is not None else None,\n",
    "                          'Age': prop['age'],\n",
    "                          'Country': prop['country'],\n",
    "                          'Playcount': prop['playcount'],\n",
    "                          '#Playlists': prop['playlists'],\n",
    "                          'Subscribertype': prop['subscribertype']})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_prop = users['Properties'].apply(lambda s: parse_user_properties(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users.drop(['Type', 'Properties'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users.merge(user_prop, left_index=True, right_index=True)\n",
    "print(users.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcsv_users = os.path.join(data_dir, 'users.csv')\n",
    "users.to_csv(fcsv_users, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(fcsv_users, index_col='ID', sep=';').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert tags data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ftags = os.path.join(data_dir, 'tags.idomaar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = pd.read_csv(ftags, header=None, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags.columns = COLUMNS\n",
    "tags.set_index('ID', inplace=True)\n",
    "tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags[tags['Timestamp'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags[tags['LinkedEntities'] != '{}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags.drop(['Type', 'Timestamp', 'LinkedEntities'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tags.shape)\n",
    "tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags.loc[58983, 'Properties']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tag_properties(props):\n",
    "    props = props.replace(';', ',')\n",
    "    try:\n",
    "        prop = json.loads(props)\n",
    "    except:\n",
    "        props = props.replace('u\"', '').replace('\\\\', '').replace('\\\\n', '')\\\n",
    "                     .replace('\"value\":', 'VALUE:').replace('\"url\":', 'URL:').replace('\"', '')\\\n",
    "                     .replace('VALUE:', '\"value\":\"').replace(', URL:', '\", \"url\":\"').replace('}', '\"}')\n",
    "        try: prop = json.loads(props)\n",
    "        except: print(props); sys.exit(0)\n",
    "    return pd.Series({'Value': prop['value'].replace('\\n', ''), 'URL': prop['url']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tags_prop = tags['Properties'].apply(lambda s: parse_tag_properties(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tags_prop.shape)\n",
    "tags_prop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_prop.loc[230795, 'Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcsv_tags = os.path.join(data_dir, 'tags.csv')\n",
    "tags_prop.to_csv(fcsv_tags, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(fcsv_tags, index_col='ID', sep=';').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert tracks data to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: there are *duplicated lines* (duplicated track ID with possibly different information) in tracks data, need to deal with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ftracks = os.path.join(data_dir, 'tracks.idomaar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = pd.read_csv(ftracks, header=None, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks.columns = COLUMNS\n",
    "#tracks.set_index('ID', inplace=True) # there's duplications\n",
    "tracks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks[tracks['Timestamp'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracks.drop(['Type', 'Timestamp'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check duplications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks['ID'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tracks.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with duplications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks['Duplicated'] = tracks['ID'].duplicated(keep='first')\n",
    "tracks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks[tracks['ID'] == 170]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fnodup = os.path.join(data_dir, 'tracks.nodup')\n",
    "fdup = os.path.join(data_dir, 'tracks.dup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks[tracks['Duplicated'] == False][COLUMNS].to_csv(fnodup, quoting=csv.QUOTE_NONE, sep='\\t', header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks[tracks['Duplicated'] == True][COLUMNS].to_csv(fdup, quoting=csv.QUOTE_NONE, sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clear object in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%xdel tracks\n",
    "#%xdel -n tracks\n",
    "#gc.collect()\n",
    "#gc.collect()\n",
    "# memory usage are still huge after these operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%reset\n",
    "# this works!\n",
    "# but needs re-import any modules needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prop_columns = ['Duration', 'Playcount', 'MBID', 'Name']\n",
    "entity_columns = ['ArtistsID', 'AlbumsID', 'TagsID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_track_properties(props):\n",
    "    try:\n",
    "        props = props.replace(';', ',')\n",
    "        prop = json.loads(props)\n",
    "    except:\n",
    "        print(props)\n",
    "        sys.exit(0)\n",
    "    return pd.Series({'Duration': prop['duration'], 'Playcount': prop['playcount'], \\\n",
    "                      'MBID': prop['MBID'], 'Name': prop['name']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tracks.loc[0, 'Properties']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json.loads(tracks.loc[0, 'LinkedEntities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_track_entities(entities):\n",
    "    try:\n",
    "        entities = entities.replace(';', ',')\n",
    "        entity = json.loads(entities)\n",
    "    except:\n",
    "        print(entities)\n",
    "        sys.exit(0)\n",
    "    return pd.Series({\n",
    "        'ArtistsID': ','.join([str(x['id']) for x in entity['artists']]) if \\\n",
    "                               entity['artists'] is not None and len(entity['artists']) > 0 else None,\n",
    "        'AlbumsID': ','.join([str(x['id']) for x in entity['albums']]) if \\\n",
    "                              entity['albums'] is not None and len(entity['albums']) > 0 else None,\n",
    "        'TagsID': ','.join([str(x['id']) for x in entity['tags']]) if \\\n",
    "                            entity['tags'] is not None and len(entity['tags']) > 0 else None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tracks.loc[0, 'LinkedEntities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse_track_entities(tracks.loc[0, 'LinkedEntities'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse non-duplicated tracks and save them to csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_nodup = tracks[tracks['Duplicated'] == False]\n",
    "lines = []\n",
    "cnt = 0\n",
    "print(tracks_nodup.shape[0])\n",
    "for ix in tracks_nodup.index:\n",
    "    track_id = tracks_nodup.loc[ix, 'ID']\n",
    "    props = parse_track_properties(tracks_nodup.loc[ix, 'Properties'])\n",
    "    entities = parse_track_entities(tracks_nodup.loc[ix, 'LinkedEntities'])\n",
    "\n",
    "    # add new track record\n",
    "    #tracks_df.ID = track_id\n",
    "    #tracks_df.loc[track_id, prop_columns] = props\n",
    "    #tracks_df.loc[track_id, entity_columns] = entities\n",
    "    line = [str(track_id)]\n",
    "    for prop in prop_columns: line.append(str(props[prop]) if props[prop] is not None else '')\n",
    "    for entity in entity_columns: line.append(str(entities[entity]) if entities[entity] is not None else '')\n",
    "    lines.append(';'.join(line))\n",
    "    \n",
    "    cnt += 1\n",
    "    if cnt % 1000 == 0:\n",
    "        sys.stdout.write('\\r%d' % (cnt))\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcsv_tracks = os.path.join(data_dir, 'tracks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(fcsv_tracks, 'w') as fcsv:\n",
    "    for line in lines: fcsv.write(line + '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df = pd.read_csv(fcsv_tracks, sep=';', keep_default_na=False, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with duplications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracks_df.columns = ['ID'] + prop_columns + entity_columns\n",
    "tracks_df.set_index('ID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tracks_df.shape[0])\n",
    "print(tracks_df.index.unique().shape[0])\n",
    "tracks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tracks_df['Duration'] = tracks_df['Duration'].astype(float)\n",
    "#tracks_df['Playcount'] = tracks_df['Playcount'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "tracks_dup = tracks[tracks['Duplicated'] == True]\n",
    "print(tracks_dup.shape[0])\n",
    "for ix in tracks_dup.index:\n",
    "    track_id = tracks_dup.loc[ix, 'ID']\n",
    "    props = parse_track_properties(tracks_dup.loc[ix, 'Properties'])\n",
    "    entities = parse_track_entities(tracks_dup.loc[ix, 'LinkedEntities'])\n",
    "\n",
    "    # update existing track\n",
    "    # ['Duration', 'Playcount', 'MBID', 'Name']\n",
    "    duration = tracks_df.loc[track_id, 'Duration']\n",
    "    playcount = tracks_df.loc[track_id, 'Playcount']\n",
    "    if type(duration) == str: \n",
    "        try: duration = int(duration)\n",
    "        except: duration = -1\n",
    "    if type(playcount) == str:\n",
    "        try: playcount = int(playcount)\n",
    "        except: playcount = -1\n",
    "    mbid = tracks_df.loc[track_id, 'MBID']; mbid = str(mbid) if mbid is not None else mbid\n",
    "    name = tracks_df.loc[track_id, 'Name']; name = str(name) if name is not None else name\n",
    "    if type(mbid) == float: print(track_id)\n",
    "    if props['Duration'] is not None:\n",
    "        if duration is None or props['Duration'] > duration: \n",
    "            tracks_df.loc[track_id, 'Duration'] = props['Duration']\n",
    "    if props['Playcount'] is not None:\n",
    "        if playcount is None or props['Playcount'] > playcount:\n",
    "            tracks_df.loc[track_id, 'Playcount'] = props['Playcount']\n",
    "    if props['MBID'] is not None:\n",
    "        if mbid is None or len(props['MBID']) > len(mbid):\n",
    "            tracks_df.loc[track_id, 'MBID'] = props['MBID']\n",
    "    if props['Name'] is not None:\n",
    "        if name is None or len(props['Name']) > len(name):\n",
    "            tracks_df.loc[track_id, 'Name'] = props['Name']\n",
    "\n",
    "    # ['ArtistsID', 'AlbumsID', 'TagsID']\n",
    "    aid = tracks_df.loc[track_id, 'ArtistsID']; aid = str(aid) if aid is not None else aid\n",
    "    bid = tracks_df.loc[track_id, 'AlbumsID']; bid = str(bid) if bid is not None else bid\n",
    "    tid = tracks_df.loc[track_id, 'TagsID']; tid = str(tid) if tid is not None else tid\n",
    "    if entities['ArtistsID'] is not None:\n",
    "        if aid is None or len(str(entities['ArtistsID'])) > len(aid):\n",
    "            tracks_df.loc[track_id, 'ArtistsID'] = entities['ArtistsID']\n",
    "    if entities['AlbumsID'] is not None:\n",
    "        if bid is None or len(str(entities['AlbumsID'])) > len(bid):\n",
    "            tracks_df.loc[track_id, 'AlbumsID'] = entities['AlbumsID']\n",
    "    if entities['TagsID'] is not None:\n",
    "        if tid is None or len(str(entities['TagsID'])) > len(tid):\n",
    "            tracks_df.loc[track_id, 'TagsID'] = entities['TagsID']\n",
    "    cnt += 1\n",
    "    if cnt % 100 == 0:\n",
    "        sys.stdout.write('\\r%d' % (cnt))\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tracks['ID'].unique().shape[0])\n",
    "print(tracks_df.shape[0])\n",
    "tracks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracks_df.to_csv(fcsv_tracks, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(fcsv_tracks, sep=';', keep_default_na=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert playlist data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fplaylist = os.path.join(data_dir, 'playlist.idomaar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist = pd.read_csv(fplaylist, header=None, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist.columns = COLUMNS\n",
    "print(playlist.shape)\n",
    "playlist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "playlist.drop(['Type', 'ID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_playlist_properties(props):\n",
    "    props = props.replace(';', ',')\n",
    "    try:\n",
    "        prop = json.loads(props)\n",
    "    except:\n",
    "        props = props.replace('\\\\', '').replace('Title', 'TITLE').replace('numtracks', 'NUMTRACKS')\\\n",
    "                     .replace('\"duration\":', 'DURATION:').replace('\"', '')\\\n",
    "                     .replace('ID:', '\"ID\":').replace('TITLE:', '\"Title\":\"').replace(',NUMTRACKS:', '\",\"numtracks\":')\\\n",
    "                     .replace('DURATION:', '\"duration\":')\n",
    "        try: prop = json.loads(props)\n",
    "        except: print(props); sys.exit(0)\n",
    "    return pd.Series({'ID': prop['ID'], 'Title': prop['Title'], '#Tracks': prop['numtracks'], \n",
    "                      'Duration': prop['duration']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#playlist.loc[0, 'Properties']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse_playlist_properties(playlist.loc[0, 'Properties'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_playlist_entities(entities):\n",
    "    entities = entities.replace(';', ',')\n",
    "    try:\n",
    "        entity = json.loads(entities.replace('[[]]', '[]'))\n",
    "    except:\n",
    "        try: entity = json.loads(entities)\n",
    "        except: print(entities); sys.exit(0)\n",
    "    return pd.Series({\n",
    "        'UserID': ','.join([str(x['id']) for x in entity['subjects']]) if len(entity['subjects']) > 0 else None,\n",
    "        'TracksID': ','.join([str(x['id']) for x in entity['objects']]) if len(entity['objects']) > 0 else None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#playlist.loc[0, 'LinkedEntities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse_playlist_entities(playlist.loc[0, 'LinkedEntities'])#['TracksID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prop_columns = ['ID', 'Title', '#Tracks', 'Duration']\n",
    "entity_columns = ['UserID', 'TracksID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in prop_columns: playlist[col] = None\n",
    "for col in entity_columns: playlist[col] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for ix in playlist.index:\n",
    "    playlist.loc[ix, prop_columns] = parse_playlist_properties(playlist.loc[ix, 'Properties'])\n",
    "    playlist.loc[ix, entity_columns] = parse_playlist_entities(playlist.loc[ix, 'LinkedEntities'])\n",
    "    cnt += 1\n",
    "    if cnt % 100 == 0:\n",
    "        sys.stdout.write('\\r%d' % (cnt))\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist.drop(['Properties', 'LinkedEntities'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(playlist.shape)\n",
    "playlist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist[playlist['UserID'].str.contains(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist['ID'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "playlist.set_index('ID', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove empty playlist (with 0 tracks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(playlist[playlist['#Tracks'] == 0].shape)\n",
    "playlist[playlist['#Tracks'] == 0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist = playlist[playlist['#Tracks'] > 0]\n",
    "playlist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcsv_playlist = os.path.join(data_dir, 'playlist.csv')\n",
    "playlist.to_csv(fcsv_playlist, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(fcsv_playlist, index_col='ID', sep=';').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram of playlist length (i.e., the number of tracks/songs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "playlist['#Tracks'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert user preference data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpref = os.path.join(data_dir, 'love.idomaar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pref = pd.read_csv(fpref, header=None, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pref.shape)\n",
    "pref.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with ugly seperated columns (the seperator should be TAB, but it's not for the last 3 columns here)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check `Type` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pref[pref[0] != 'preference'].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check `Timestamp` and `Properties` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pref[pref[2].str.startswith('-1 {\"value\":\"love\"}')].shape[0] == pref.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pref.columns = ['Type', 'ID', 'LinkedEntities']\n",
    "pref.drop('Type', axis=1, inplace=True)\n",
    "pref.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pref.loc[0, 'LinkedEntities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pref_entity(entities):\n",
    "    entities = entities.replace('-1 {\"value\":\"love\"}', '').replace(';', ',')\n",
    "    try:\n",
    "        entity = json.loads(entities)\n",
    "    except:\n",
    "        try: entity = json.loads(entities)\n",
    "        except: print(entities); sys.exit(0)\n",
    "    return pd.Series({\n",
    "        'UserID': ','.join([str(x['id']) for x in entity['subjects']]) if len(entity['subjects']) > 0 else None,\n",
    "        'TrackID': ','.join([str(x['id']) for x in entity['objects']]) if len(entity['objects']) > 0 else None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pref_entity = pref['LinkedEntities'].apply(lambda s: parse_pref_entity(s))  # use too much memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pref_columns=['UserID', 'TrackID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pref_entity = pd.DataFrame(columns=pref_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "ix = 0\n",
    "print(pref.shape[0])\n",
    "with open(fpref) as tsvin:\n",
    "    tsvin = csv.reader(tsvin, delimiter='\\t')\n",
    "    for row in tsvin:\n",
    "        assert(len(row) == 3)\n",
    "        #pref_entity.loc[ix] = parse_pref_entity(row[2])\n",
    "        prefs = parse_pref_entity(row[2])\n",
    "        lines.append(';'.join([str(prefs[col]) for col in pref_columns]))\n",
    "        \n",
    "        ix += 1\n",
    "        if ix % 1000 == 0:\n",
    "            sys.stdout.write('\\r%d' % (ix))\n",
    "            sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcsv_pref = os.path.join(data_dir, 'love.csv')\n",
    "#pref_entity.to_csv(fcsv_pref, sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(fcsv_pref, 'w') as fcsv:\n",
    "    fcsv.write(';'.join(pref_columns) + '\\n')\n",
    "    for line in lines: fcsv.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(fcsv_pref, sep=';').head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
