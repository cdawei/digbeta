{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Dev/Test split using AotM-2011 Playlists & MSD Audio Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "import gzip\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import lil_matrix, issparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/aotm-2011'\n",
    "#faotm = os.path.join(data_dir, 'aotm2011-subset.pkl')\n",
    "faotm = os.path.join(data_dir, 'aotm2011-user-playlist.pkl')\n",
    "ffeature = 'data/msd/song2feature.pkl.gz'\n",
    "fgenre = 'data/msd/song2genre.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load playlists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_playlists = pkl.load(open(faotm, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#user    : 14182\n",
      "#playlist: 84710\n"
     ]
    }
   ],
   "source": [
    "print('#user    :', len(user_playlists))\n",
    "print('#playlist:', np.sum([len(user_playlists[u]) for u in user_playlists]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_set = sorted({sid for u in user_playlists for pl in user_playlists[u] for sid in pl})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "song2genre = pkl.load(open(fgenre, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.8% of all songs do not have genre\n"
     ]
    }
   ],
   "source": [
    "nogenre = []\n",
    "for sid in song_set:\n",
    "    if sid not in song2genre:\n",
    "        nogenre.append(sid)\n",
    "print('%.1f%% of all songs do not have genre' % (100 * len(nogenre) / len(song_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = sorted(user_playlists.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SOEURWZ12A58A7B772',\n",
       " 'SOGVEJN12A6D4F9D83',\n",
       " 'SOUNSZA12A8C13A204',\n",
       " 'SOXLLMC12A8C13E499',\n",
       " 'SOQPSMN12AB0184EDA',\n",
       " 'SOKAWWA12A6701FD46']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_playlists[users[0]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average playlist length: 10.1\n"
     ]
    }
   ],
   "source": [
    "pl_lengths = [len(pl) for u in user_playlists for pl in user_playlists[u]]\n",
    "#plt.hist(pl_lengths, bins=100)\n",
    "print('Average playlist length: %.1f' % np.mean(pl_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84710"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.array(pl_lengths) >= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "857782"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pl_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "857782"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([len(set(pl)) for u in user_playlists for pl in user_playlists[u]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 45, 10.1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.min(pl_lengths), np.max(pl_lengths), float('%.1f' % np.mean(pl_lengths)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load song features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `song_id` --> `feature array` mapping: map a song to the audio features of one of its corresponding tracks in MSD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "song2Features = pkl.load(gzip.open(ffeature, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The set of songs, which is the set of labels in this formulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#song_set = sorted(song2Features.keys())  # use MSD songs as label space\n",
    "# use the intersection of MSD and AotM as label space\n",
    "song_set = sorted({sid for u in user_playlists for pl in user_playlists[u] for sid in pl})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114428"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(song_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Song-User Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transpose the user-song matrix to song-user matrix: songs as rows, users as columns, split rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_songuser_mat(user_playlists, song_set, features_MSD):\n",
    "    \"\"\"\n",
    "    Create labelled dataset: rows are songs, columns are users.\n",
    "    \n",
    "    Input:\n",
    "        - user_playlists: dictionary that maps users to a set of playlists\n",
    "        - song_set: a set of songIDs\n",
    "        - features_MSD: dictionary that maps songIDs to features from MSD\n",
    "    Output:\n",
    "        - (Feature, Label) pair (X, Y)\n",
    "          X: #songs by #features\n",
    "          Y: #songs by #users\n",
    "    \"\"\"\n",
    "    user_set = sorted(user_playlists.keys())\n",
    "    song_indices = {sid: ix for ix, sid in enumerate(song_set)}\n",
    "    N = len(song_set)\n",
    "    K = len(user_set)\n",
    "    \n",
    "    X = np.array([features_MSD[sid] for sid in song_set])\n",
    "    Y = lil_matrix((N, K), dtype=np.bool)\n",
    "    \n",
    "    for k in range(K):\n",
    "        if (k+1) % 1000 == 0:\n",
    "            sys.stdout.write('\\r%d / %d' % (k+1, K))\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "        u = user_set[k]\n",
    "        songs = sorted({sid for pl in user_playlists[u] for sid in pl})\n",
    "        indices = [song_indices[sid] for sid in songs]\n",
    "        Y[indices, k] = 1\n",
    "\n",
    "    return X, Y.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000 / 14182"
     ]
    }
   ],
   "source": [
    "X, Y = gen_songuser_mat(user_playlists=user_playlists, song_set=song_set, features_MSD=song2Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = np.sum(Y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a31653be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.subplot(111)\n",
    "pd.Series(np.array(pop).flatten()).hist(ax=ax, bins=30)\n",
    "#ax.hist(sorted(pop.tolist()))\n",
    "ax.set_yscale('log')\n",
    "#ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "653"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdir = os.path.join(data_dir, 'song_user')\n",
    "fx      = os.path.join(fdir, 'X.pkl')\n",
    "fy      = os.path.join(fdir, 'Y.pkl')\n",
    "fxtrain = os.path.join(fdir, 'X_train.pkl')\n",
    "fytrain = os.path.join(fdir, 'Y_train.pkl')\n",
    "fxdev   = os.path.join(fdir, 'X_dev.pkl')\n",
    "fydev   = os.path.join(fdir, 'Y_dev.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000 / 14182"
     ]
    }
   ],
   "source": [
    "if np.all([os.path.exists(fname) for fname in [fx, fy, fxtrain, fytrain, fxdev, fydev]]):\n",
    "    X       = pkl.load(open(fx,      'rb'))\n",
    "    Y       = pkl.load(open(fy,      'rb'))\n",
    "    X_train = pkl.load(open(fxtrain, 'rb'))\n",
    "    Y_train = pkl.load(open(fytrain, 'rb'))\n",
    "    X_dev   = pkl.load(open(fxdev,   'rb'))\n",
    "    Y_dev   = pkl.load(open(fydev,   'rb'))\n",
    "else:\n",
    "    # generate dataset\n",
    "    X, Y = gen_songuser_mat(user_playlists=user_playlists, song_set=song_set, features_MSD=song2Features)\n",
    "    \n",
    "    # data split: approximately 80/20 for training/dev\n",
    "    X_train, X_dev, Y_train, Y_dev = train_test_split(X, Y, test_size=0.2, random_state=123456789)\n",
    "    \n",
    "    # feature normalisation\n",
    "    X_train_mean = np.mean(X_train, axis=0).reshape((1, -1))\n",
    "    X_train_std = np.std(X_train, axis=0).reshape((1, -1)) + 10 ** (-6)\n",
    "    X_train -= X_train_mean\n",
    "    X_train /= X_train_std\n",
    "    X_dev   -= X_train_mean\n",
    "    X_dev   /= X_train_std\n",
    "    \n",
    "    # save to files\n",
    "    pkl.dump(X,       open(fx, 'wb'))\n",
    "    pkl.dump(Y,       open(fy, 'wb'))\n",
    "    pkl.dump(X_train, open(fxtrain, 'wb'))\n",
    "    pkl.dump(Y_train, open(fytrain, 'wb'))\n",
    "    pkl.dump(X_dev,   open(fxdev,   'wb'))\n",
    "    pkl.dump(Y_dev,   open(fydev,   'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All  :   (114428, 202) (114428, 14182)\n",
      "Train:    (91542, 202)  (91542, 14182)\n",
      "Dev  :    (22886, 202)  (22886, 14182)\n"
     ]
    }
   ],
   "source": [
    "print('All  : %15s %15s' % (X.shape, Y.shape))\n",
    "print('Train: %15s %15s' % (X_train.shape, Y_train.shape))\n",
    "print('Dev  : %15s %15s' % (X_dev.shape,   Y_dev.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.744088163228033e-15"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.mean(X_train, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.019815081566402215"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.std(X_train, axis=0)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0005716163590059731"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.mean(X_dev, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0354526080921741"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.std(X_dev, axis=0)) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playlist-Song Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The playlist-song matrix: playlists as rows, songs as columns, split rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For users with more than 10 playlists, we split their playlists approximately 70/10/20 for train/dev/test.\n",
    "- For each playlist in dev/test set, we remove the last 20% and try to predict them.\n",
    "- All remaining playlists are used for training as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(label_indices.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_training_set(playlists, label_indices, features):\n",
    "    \"\"\"\n",
    "        Create the labelled dataset: rows are playlists, columns are songs\n",
    "        \n",
    "        Input:\n",
    "            - playlists: which playlists to create features for\n",
    "            - label_indices: a dictionary that maps a songID to the index of the corresponding label\n",
    "            - features: a dictionary that maps a songID to its feature vector\n",
    "            \n",
    "        Output:\n",
    "            - (Feature, Label) pair (X, Y), with # num playlists rows\n",
    "              X comprises the features for each seed song (the 1st in playlist)\n",
    "              Y comprises the indicators of whether the given song is present in the respective playlist\n",
    "    \"\"\"\n",
    "\n",
    "    N = len(playlists)\n",
    "    K = len(label_indices)\n",
    "\n",
    "    X = [ ]\n",
    "    Y = lil_matrix((N, K), dtype=np.int8)\n",
    "    \n",
    "    cnt = 0\n",
    "    for i in range(len(playlists)):\n",
    "        cnt += 1\n",
    "        if cnt % 1000 == 0:\n",
    "            sys.stdout.write('\\r%d / %d' % (cnt, len(playlists)))\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "        playlist = playlists[i]\n",
    "        seed     = playlist[0]\n",
    "\n",
    "        X.append(features[seed])\n",
    "        #indices = [label_indices[s] for s in playlist]\n",
    "        indices = [label_indices[s] for s in playlist if s in label_indices]\n",
    "        Y[i, indices] = 1\n",
    "\n",
    "    return np.array(X), Y.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_dict = {1: 0, 2: 1, 3: 2}\n",
    "#[test_dict[s] for s in [1, 2, 5] if s in test_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdir = os.path.join(data_dir, 'setting1')\n",
    "fxtrain = os.path.join(fdir, 'X_train_audio.pkl')\n",
    "fytrain = os.path.join(fdir, 'Y_train_audio.pkl')\n",
    "fxdev   = os.path.join(fdir, 'X_dev_audio.pkl')\n",
    "fydev   = os.path.join(fdir, 'Y_dev_audio.pkl')\n",
    "fxtest  = os.path.join(fdir, 'X_test_audio.pkl')\n",
    "fytest  = os.path.join(fdir, 'Y_test_audio.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.all([os.path.exists(fname) for fname in [fxtrain, fytrain, fxdev, fydev, fxtest, fytest]]):\n",
    "    X_train = pkl.load(open(fxtrain, 'rb'))\n",
    "    Y_train = pkl.load(open(fytrain, 'rb'))\n",
    "    X_dev   = pkl.load(open(fxdev,   'rb'))\n",
    "    Y_dev   = pkl.load(open(fydev,   'rb'))\n",
    "    X_test  = pkl.load(open(fxtest,  'rb'))\n",
    "    Y_test  = pkl.load(open(fytest,  'rb'))\n",
    "else:\n",
    "    # generate dataset\n",
    "    X, Y = gen_training_set(playlists=playlists, label_indices=label_indices, features=song2Features)\n",
    "    \n",
    "    # data split: approximately 70/10/20 for training/dev/test\n",
    "    # by fixing random seed, the same playlists will be in the test set each time\n",
    "    X_train, X_other, Y_train, Y_other = train_test_split(X, Y, test_size=0.3, random_state=123456789)\n",
    "    X_dev,   X_test,  Y_dev,   Y_test  = train_test_split(X_other, Y_other, test_size=0.65, random_state=987654321)\n",
    "    \n",
    "    # feature normalisation\n",
    "    X_train_mean = np.mean(X_train, axis=0).reshape((1, -1))\n",
    "    X_train_std = np.std(X_train, axis=0).reshape((1, -1)) + 10 ** (-6)\n",
    "    X_train -= X_train_mean\n",
    "    X_train /= X_train_std\n",
    "    X_dev   -= X_train_mean\n",
    "    X_dev   /= X_train_std\n",
    "    X_test  -= X_train_mean\n",
    "    X_test  /= X_train_std\n",
    "    \n",
    "    # save to files\n",
    "    pkl.dump(X_train, open(fxtrain, 'wb'))\n",
    "    pkl.dump(Y_train, open(fytrain, 'wb'))\n",
    "    pkl.dump(X_dev,   open(fxdev,   'wb'))\n",
    "    pkl.dump(Y_dev,   open(fydev,   'wb'))\n",
    "    pkl.dump(X_test,  open(fxtest,  'wb'))\n",
    "    pkl.dump(Y_test,  open(fytest,  'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train: %15s %15s' % (X_train.shape, Y_train.shape))\n",
    "print('Dev  : %15s %15s' % (X_dev.shape,   Y_dev.shape))\n",
    "print('Test : %15s %15s' % (X_test.shape,  Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.mean(X_train, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.std(X_train, axis=0)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.mean(X_dev, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.std(X_dev, axis=0)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.mean(X_test, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.std(X_test, axis=0)) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A set of playlists as labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_training_set2(playlists, features):\n",
    "    \"\"\"\n",
    "        Create the labelled dataset: rows are songs, columns are playlists\n",
    "        \n",
    "        Input:\n",
    "            - playlists: which playlists to create features for\n",
    "            - features: a dictionary that maps a songID to its feature vector\n",
    "            \n",
    "        Output:\n",
    "            - (Feature, Label) pair (X, Y), with # num playlists rows\n",
    "              X comprises the features for each song\n",
    "              Y comprises the indicators of whether the given song is present in the respective playlist\n",
    "    \"\"\"\n",
    "    \n",
    "    song_set = sorted({sid for pl in playlists for sid in pl})\n",
    "    songInPlaylist = {sid: [] for sid in song_set}\n",
    "    N = len(song_set)\n",
    "    K = len(playlists)\n",
    "\n",
    "    for j in range(K):\n",
    "        pl = playlists[j]\n",
    "        for sid in pl:\n",
    "            songInPlaylist[sid].append(j)\n",
    "    \n",
    "    X = [ ]\n",
    "    Y = lil_matrix((N, K), dtype=np.int8)\n",
    "    for i in range(N):\n",
    "        if (i+1) % 1000 == 0:\n",
    "            sys.stdout.write('\\r%d / %d' % (i+1, N))\n",
    "            sys.stdout.flush()\n",
    "        sid = song_set[i]\n",
    "        X.append(features[sid])\n",
    "        indices = songInPlaylist[sid]\n",
    "        Y[i, indices] = 1\n",
    "        \n",
    "    return np.array(X), Y.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdir = os.path.join(data_dir, 'setting2')\n",
    "fxtrain = os.path.join(fdir, 'X_train_audio.pkl')\n",
    "fytrain = os.path.join(fdir, 'Y_train_audio.pkl')\n",
    "fxdev   = os.path.join(fdir, 'X_dev_audio.pkl')\n",
    "fydev   = os.path.join(fdir, 'Y_dev_audio.pkl')\n",
    "fxtest  = os.path.join(fdir, 'X_test_audio.pkl')\n",
    "fytest  = os.path.join(fdir, 'Y_test_audio.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.all([os.path.exists(fname) for fname in [fxtrain, fytrain, fxdev, fydev, fxtest, fytest]]):\n",
    "    X_train = pkl.load(open(fxtrain, 'rb'))\n",
    "    Y_train = pkl.load(open(fytrain, 'rb'))\n",
    "    X_dev   = pkl.load(open(fxdev,   'rb'))\n",
    "    Y_dev   = pkl.load(open(fydev,   'rb'))\n",
    "    X_test  = pkl.load(open(fxtest,  'rb'))\n",
    "    Y_test  = pkl.load(open(fytest,  'rb'))\n",
    "else:\n",
    "    # generate dataset\n",
    "    X, Y = gen_training_set2(playlists=playlists, features=song2Features)\n",
    "\n",
    "    # data split: approximately 70/10/20 for training/dev/test\n",
    "    # by fixing random seed, the same playlists will be in the test set each time\n",
    "    X_train, X_other, Y_train, Y_other = train_test_split(X, Y, test_size=0.3, random_state=59)\n",
    "    X_dev,   X_test,  Y_dev,   Y_test  = train_test_split(X_other, Y_other, test_size=0.65, random_state=71)\n",
    "\n",
    "    # feature normalisation\n",
    "    X_train_mean = np.mean(X_train, axis=0).reshape((1, -1))\n",
    "    X_train_std = np.std(X_train, axis=0).reshape((1, -1)) + 10 ** (-6)\n",
    "    X_train -= X_train_mean\n",
    "    X_train /= X_train_std\n",
    "    X_dev   -= X_train_mean\n",
    "    X_dev   /= X_train_std\n",
    "    X_test  -= X_train_mean\n",
    "    X_test  /= X_train_std\n",
    "\n",
    "    # save to files\n",
    "    pkl.dump(X_train, open(fxtrain, 'wb'))\n",
    "    pkl.dump(Y_train, open(fytrain, 'wb'))\n",
    "    pkl.dump(X_dev,   open(fxdev,   'wb'))\n",
    "    pkl.dump(Y_dev,   open(fydev,   'wb'))\n",
    "    pkl.dump(X_test,  open(fxtest,  'wb'))\n",
    "    pkl.dump(Y_test,  open(fytest,  'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train: %15s %15s' % (X_train.shape, Y_train.shape))\n",
    "print('Dev  : %15s %15s' % (X_dev.shape,   Y_dev.shape))\n",
    "print('Test : %15s %15s' % (X_test.shape,  Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.mean(X_train, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.std(X_train, axis=0)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.mean(X_dev, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.std(X_dev, axis=0)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.mean(X_test, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.std(X_test, axis=0)) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Song in playlist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_set = sorted({sid for pl in playlists for sid in pl})\n",
    "songInPlaylist = {sid: [] for sid in song_set}\n",
    "K = len(playlists)\n",
    "for j in range(K):\n",
    "    pl = playlists[j]\n",
    "    for sid in pl: songInPlaylist[sid].append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_train, S_other, dummy_train, dummy_other = train_test_split(song_set, np.arange(len(song_set)), \n",
    "                                                              test_size=0.3, random_state=59)\n",
    "S_dev, S_test, dummy_dev, dummy_test = train_test_split(S_other, dummy_other, test_size=0.65, random_state=71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(S_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(S_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = 0\n",
    "sid = S_train[ix]\n",
    "#np.equal(song2Features[sid], X_train[ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songInPlaylist[song_set[dummy_train[0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = pd.read_csv('data/f1.txt', names=['F1', '0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1['F1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pak = pd.read_csv('data/pak.txt', names=['PaK', '0'])\n",
    "pak = pak['PaK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin = np.min([np.min(f1), np.min(pak)]) - 0.00005\n",
    "xmax = np.max([np.max(f1), np.max(pak)]) + 0.00005\n",
    "plt.xlim([xmin, xmax])\n",
    "plt.ylim([xmin, xmax])\n",
    "plt.plot([xmin, xmax], [xmin, xmax], ls='--', c='g')\n",
    "plt.scatter(f1, pak)\n",
    "plt.xlabel('F1')\n",
    "plt.ylabel('Precision@K')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
