{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Dev/Test split using AotM-2011 Playlists & MSD Audio Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import lil_matrix, issparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/aotm-2011'\n",
    "faotm = os.path.join(data_dir, 'aotm2011-subset.pkl')\n",
    "ffeature = 'data/msd/songID2Features.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load playlists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists = pkl.load(open(faotm, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('#Playlists: %d' % len(playlists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('#Songs: %d' % len({songID for p in playlists for songID in p['filtered_lists'][0]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lengths = [len(p['filtered_lists'][0]) for p in playlists]\n",
    "lengths = [len(sl) for sl in playlists]\n",
    "plt.hist(lengths, bins=20)\n",
    "print('Average playlist length: %.1f' % np.mean(lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: there are duplicated songs in some playlists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum([len(pl) for pl in playlists])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum([len(set(pl)) for pl in playlists])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(pl) for pl in playlists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.min(lengths), np.max(lengths), np.mean(lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `song_id` --> `feature array` mapping: map a song to the audio features of one of its corresponding tracks in MSD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song2Features = pkl.load(open(ffeature, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The set of songs, which is the set of labels in this formulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#song_set = sorted(song2Features.keys())  # use MSD songs as label space\n",
    "song_set = sorted({sid for pl in playlists for sid in pl})   # use the intersection of MSD and AotM as label space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(song_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A set of songs as labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_indices = {songID: ix for ix, songID in enumerate(song_set)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(label_indices.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_training_set(playlists, label_indices, features):\n",
    "    \"\"\"\n",
    "        Create the labelled dataset: rows are playlists, columns are songs\n",
    "        \n",
    "        Input:\n",
    "            - playlists: which playlists to create features for\n",
    "            - label_indices: a dictionary that maps a songID to the index of the corresponding label\n",
    "            - features: a dictionary that maps a songID to its feature vector\n",
    "            \n",
    "        Output:\n",
    "            - (Feature, Label) pair (X, Y), with # num playlists rows\n",
    "              X comprises the features for each seed song (the 1st in playlist)\n",
    "              Y comprises the indicators of whether the given song is present in the respective playlist\n",
    "    \"\"\"\n",
    "\n",
    "    N = len(playlists)\n",
    "    K = len(label_indices)\n",
    "\n",
    "    X = [ ]\n",
    "    Y = lil_matrix((N, K), dtype=np.int8)\n",
    "    \n",
    "    cnt = 0\n",
    "    for i in range(len(playlists)):\n",
    "        cnt += 1\n",
    "        if cnt % 1000 == 0:\n",
    "            sys.stdout.write('\\r%d / %d' % (cnt, len(playlists)))\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "        playlist = playlists[i]\n",
    "        seed     = playlist[0]\n",
    "\n",
    "        X.append(features[seed])\n",
    "        #indices = [label_indices[s] for s in playlist]\n",
    "        indices = [label_indices[s] for s in playlist if s in label_indices]\n",
    "        Y[i, indices] = 1\n",
    "\n",
    "    return np.array(X), Y.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_dict = {1: 0, 2: 1, 3: 2}\n",
    "#[test_dict[s] for s in [1, 2, 5] if s in test_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdir = os.path.join(data_dir, 'setting1')\n",
    "fxtrain = os.path.join(fdir, 'X_train_audio.pkl')\n",
    "fytrain = os.path.join(fdir, 'Y_train_audio.pkl')\n",
    "fxdev   = os.path.join(fdir, 'X_dev_audio.pkl')\n",
    "fydev   = os.path.join(fdir, 'Y_dev_audio.pkl')\n",
    "fxtest  = os.path.join(fdir, 'X_test_audio.pkl')\n",
    "fytest  = os.path.join(fdir, 'Y_test_audio.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.all([os.path.exists(fname) for fname in [fxtrain, fytrain, fxdev, fydev, fxtest, fytest]]):\n",
    "    X_train = pkl.load(open(fxtrain, 'rb'))\n",
    "    Y_train = pkl.load(open(fytrain, 'rb'))\n",
    "    X_dev   = pkl.load(open(fxdev,   'rb'))\n",
    "    Y_dev   = pkl.load(open(fydev,   'rb'))\n",
    "    X_test  = pkl.load(open(fxtest,  'rb'))\n",
    "    Y_test  = pkl.load(open(fytest,  'rb'))\n",
    "else:\n",
    "    # generate dataset\n",
    "    X, Y = gen_training_set(playlists=playlists, label_indices=label_indices, features=song2Features)\n",
    "    \n",
    "    # data split: approximately 70/10/20 for training/dev/test\n",
    "    # by fixing random seed, the same playlists will be in the test set each time\n",
    "    X_train, X_other, Y_train, Y_other = train_test_split(X, Y, test_size=0.3, random_state=123456789)\n",
    "    X_dev,   X_test,  Y_dev,   Y_test  = train_test_split(X_other, Y_other, test_size=0.65, random_state=987654321)\n",
    "    \n",
    "    # feature normalisation\n",
    "    X_train_mean = np.mean(X_train, axis=0).reshape((1, -1))\n",
    "    X_train_std = np.std(X_train, axis=0).reshape((1, -1)) + 10 ** (-6)\n",
    "    X_train -= X_train_mean\n",
    "    X_train /= X_train_std\n",
    "    X_dev   -= X_train_mean\n",
    "    X_dev   /= X_train_std\n",
    "    X_test  -= X_train_mean\n",
    "    X_test  /= X_train_std\n",
    "    \n",
    "    # save to files\n",
    "    pkl.dump(X_train, open(fxtrain, 'wb'))\n",
    "    pkl.dump(Y_train, open(fytrain, 'wb'))\n",
    "    pkl.dump(X_dev,   open(fxdev,   'wb'))\n",
    "    pkl.dump(Y_dev,   open(fydev,   'wb'))\n",
    "    pkl.dump(X_test,  open(fxtest,  'wb'))\n",
    "    pkl.dump(Y_test,  open(fytest,  'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train: %15s %15s' % (X_train.shape, Y_train.shape))\n",
    "print('Dev  : %15s %15s' % (X_dev.shape,   Y_dev.shape))\n",
    "print('Test : %15s %15s' % (X_test.shape,  Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.mean(X_train, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.std(X_train, axis=0)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.mean(X_dev, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.std(X_dev, axis=0)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.mean(X_test, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.std(X_test, axis=0)) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A set of playlists as labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_training_set2(playlists, features):\n",
    "    \"\"\"\n",
    "        Create the labelled dataset: rows are songs, columns are playlists\n",
    "        \n",
    "        Input:\n",
    "            - playlists: which playlists to create features for\n",
    "            - features: a dictionary that maps a songID to its feature vector\n",
    "            \n",
    "        Output:\n",
    "            - (Feature, Label) pair (X, Y), with # num playlists rows\n",
    "              X comprises the features for each song\n",
    "              Y comprises the indicators of whether the given song is present in the respective playlist\n",
    "    \"\"\"\n",
    "    \n",
    "    song_set = sorted({sid for pl in playlists for sid in pl})\n",
    "    songInPlaylist = {sid: [] for sid in song_set}\n",
    "    N = len(song_set)\n",
    "    K = len(playlists)\n",
    "\n",
    "    for j in range(K):\n",
    "        pl = playlists[j]\n",
    "        for sid in pl:\n",
    "            songInPlaylist[sid].append(j)\n",
    "    \n",
    "    X = [ ]\n",
    "    Y = lil_matrix((N, K), dtype=np.int8)\n",
    "    for i in range(N):\n",
    "        if (i+1) % 1000 == 0:\n",
    "            sys.stdout.write('\\r%d / %d' % (i+1, N))\n",
    "            sys.stdout.flush()\n",
    "        sid = song_set[i]\n",
    "        X.append(features[sid])\n",
    "        indices = songInPlaylist[sid]\n",
    "        Y[i, indices] = 1\n",
    "        \n",
    "    return np.array(X), Y.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdir = os.path.join(data_dir, 'setting2')\n",
    "fxtrain = os.path.join(fdir, 'X_train_audio.pkl')\n",
    "fytrain = os.path.join(fdir, 'Y_train_audio.pkl')\n",
    "fxdev   = os.path.join(fdir, 'X_dev_audio.pkl')\n",
    "fydev   = os.path.join(fdir, 'Y_dev_audio.pkl')\n",
    "fxtest  = os.path.join(fdir, 'X_test_audio.pkl')\n",
    "fytest  = os.path.join(fdir, 'Y_test_audio.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.all([os.path.exists(fname) for fname in [fxtrain, fytrain, fxdev, fydev, fxtest, fytest]]):\n",
    "    X_train = pkl.load(open(fxtrain, 'rb'))\n",
    "    Y_train = pkl.load(open(fytrain, 'rb'))\n",
    "    X_dev   = pkl.load(open(fxdev,   'rb'))\n",
    "    Y_dev   = pkl.load(open(fydev,   'rb'))\n",
    "    X_test  = pkl.load(open(fxtest,  'rb'))\n",
    "    Y_test  = pkl.load(open(fytest,  'rb'))\n",
    "else:\n",
    "    # generate dataset\n",
    "    X, Y = gen_training_set2(playlists=playlists, features=song2Features)\n",
    "\n",
    "    # data split: approximately 70/10/20 for training/dev/test\n",
    "    # by fixing random seed, the same playlists will be in the test set each time\n",
    "    X_train, X_other, Y_train, Y_other = train_test_split(X, Y, test_size=0.3, random_state=59)\n",
    "    X_dev,   X_test,  Y_dev,   Y_test  = train_test_split(X_other, Y_other, test_size=0.65, random_state=71)\n",
    "\n",
    "    # feature normalisation\n",
    "    X_train_mean = np.mean(X_train, axis=0).reshape((1, -1))\n",
    "    X_train_std = np.std(X_train, axis=0).reshape((1, -1)) + 10 ** (-6)\n",
    "    X_train -= X_train_mean\n",
    "    X_train /= X_train_std\n",
    "    X_dev   -= X_train_mean\n",
    "    X_dev   /= X_train_std\n",
    "    X_test  -= X_train_mean\n",
    "    X_test  /= X_train_std\n",
    "\n",
    "    # save to files\n",
    "    pkl.dump(X_train, open(fxtrain, 'wb'))\n",
    "    pkl.dump(Y_train, open(fytrain, 'wb'))\n",
    "    pkl.dump(X_dev,   open(fxdev,   'wb'))\n",
    "    pkl.dump(Y_dev,   open(fydev,   'wb'))\n",
    "    pkl.dump(X_test,  open(fxtest,  'wb'))\n",
    "    pkl.dump(Y_test,  open(fytest,  'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train: %15s %15s' % (X_train.shape, Y_train.shape))\n",
    "print('Dev  : %15s %15s' % (X_dev.shape,   Y_dev.shape))\n",
    "print('Test : %15s %15s' % (X_test.shape,  Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.mean(X_train, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.std(X_train, axis=0)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.mean(X_dev, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.std(X_dev, axis=0)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.mean(X_test, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.std(X_test, axis=0)) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Song in playlist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_set = sorted({sid for pl in playlists for sid in pl})\n",
    "songInPlaylist = {sid: [] for sid in song_set}\n",
    "K = len(playlists)\n",
    "for j in range(K):\n",
    "    pl = playlists[j]\n",
    "    for sid in pl: songInPlaylist[sid].append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_train, S_other, dummy_train, dummy_other = train_test_split(song_set, np.arange(len(song_set)), \n",
    "                                                              test_size=0.3, random_state=59)\n",
    "S_dev, S_test, dummy_dev, dummy_test = train_test_split(S_other, dummy_other, test_size=0.65, random_state=71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(S_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(S_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = 0\n",
    "sid = S_train[ix]\n",
    "#np.equal(song2Features[sid], X_train[ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songInPlaylist[song_set[dummy_train[0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = pd.read_csv('data/f1.txt', names=['F1', '0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1['F1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pak = pd.read_csv('data/pak.txt', names=['PaK', '0'])\n",
    "pak = pak['PaK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin = np.min([np.min(f1), np.min(pak)]) - 0.00005\n",
    "xmax = np.max([np.max(f1), np.max(pak)]) + 0.00005\n",
    "plt.xlim([xmin, xmax])\n",
    "plt.ylim([xmin, xmax])\n",
    "plt.plot([xmin, xmax], [xmin, xmax], ls='--', c='g')\n",
    "plt.scatter(f1, pak)\n",
    "plt.xlabel('F1')\n",
    "plt.ylabel('Precision@K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
