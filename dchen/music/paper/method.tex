\section{Multitask learning for music recommendation}
\label{sec:method}

In this section, we first describe a multitask objective that supports the cold-start recommendation tasks
described in Section~(\ref{sec:problem}). We propose a ranking approach to optimise the multitask objective 
by solving an convex constrained optimisation problem.
We analyse the challenge to deal with a large number of constraints and then propose an classification approach
that approximates the multitask objective without any constraints, which results in an efficient optimisation of
the multitask objective.


\subsection{Multitask learning objective}

We decompose the representation $\w_i^u$ of a playlist $i$ from user $u$ in (\ref{eq:scorefunc}) into three components, \ie
$$
\w_i^u = \bv_i + \bmu_u + \widebar\bmu,
$$
where $\bv_i$ is a parameter vector specific for playlist $i$,
$\bmu_u$ is the component for user $u$,
and $\widebar\bmu$ is a representation shared by all users.

The learning task is to minimise the empirical risk of affinity function $f$ on dataset $\DCal$ over all parameters.
Let $\uptheta$ which represents all parameters in $\bv_i, \bmu_u, \widebar\bmu, \, u \in \{1,\dots,U\}, \, i \in P_u$.
Formally, we solve an optimisation problem
\begin{equation}
\label{eq:obj}
\min_{\uptheta} \, R(\uptheta) + \RCal(f, \DCal),
\end{equation}
where $R(\uptheta)$ is the regularisation term and $\RCal(f, \DCal)$ denotes the empirical risk.
We call the objective in problem~(\ref{eq:obj}) a multitask learning objective,
since jointly learn from multiple tasks where each task is to recommend a set of songs given either a user or a playlist.

We further assume that playlists of the \emph{same} user have \emph{similar} representations,
%and the difference between playlists $i$ and $i'$ of the same user $j$ is reflected by the playlist component $\bv_i$
%and $\bv_{i'}$, respectively.
%This assumption requires that parameters specific to playlist should be sparse,
which can be achieved by imposing an L1 regularisation, \ie $\sum_{u=1}^U \sum_{i \in P_u} \| \bv_i \|_1$
that encourages sparse representations.
Lastly, although the representations of different users are different,
we assume they nonetheless share a small number of features in their representations.
This can be formalised similarly by imposing an additional L1 regularisation term $\| \widebar\bmu \|_1$.

The regularisation terms in our multitask learning objective can be summarised as
\begin{equation}
\label{eq:reg}
R(\uptheta) = \lambda_1 \sum_{u=1}^U \sum_{i \in P_u} \|\bv_i\|_1 + \lambda_2 \sum_{u=1}^U \|\bmu_u\|_2^2 + \lambda_3 \|\widebar\bmu\|_1,
\end{equation}
where we add an L2 regularisation term to penalise large values in user representations,
and $\lambda_1, \lambda_2, \lambda_3 \in \R_+$ are regularisation constants.

Once all parameters have been learned, in the task of recommending new songs to extend an existing playlist $i$ from user $u$, 
we can score a new song $m$ by
$$
\hat f(u, i, m) = (\bv_i + \bmu_u + \widebar\bmu)^\top \x_m.
$$

Further, in the task of recommending a set of songs for an existing user $u$ (to form a playlist), 
we score song $m$ by
$$
\hat f(u, \cdot, m) = (\bmu_u + \widebar\bmu)^\top \x_m.
$$

Finally, to recommend a set of songs for a new user, each song $m$ can be scored by
$$
\hat f(\cdot, \cdot, m) = \widebar\bmu^\top \x_m.
$$


\subsection{Recommending the most probable songs}
\label{ssec:bploss}

In this section, we describe a ranking approach that learns to rank songs in playlist above
those not in it, which aims to rank the most probable songs above those unlikely when making a recommendation.
The corresponding loss function of this approach is known as the Bottom-Push loss~\cite{rudin2009p} in bipartite ranking literature.
%Formally, for playlist $i$, we would like
%\begin{equation*}
%\begin{aligned}
%\min_{m: y_m^i = 1} f(i, m) \ge f(i, n), \ \forall n \in \{1,\dots,M\} \ \text{and} \ y_n^i = 0,
%\end{aligned}
%\end{equation*}
%where $y_m^i = 1$ denotes that song $m$ is in playlist $i$,
%and $y_n^i = 0$ represents song $n$ does not appear in playlist $i$.
Formally, we minimise the number of songs not in playlist but ranked above the lowest ranked song in playlist,
%but have a higher score than the lowest ranked song in playlist, 
\ie, the (normalised) empirical risk is
\begin{equation}
\label{eq:bprisk}
\resizebox{.9\linewidth}{!}{$\displaystyle
\RCal_\textsc{rank}(\uptheta) = \frac{1}{N} \sum_{u=1}^U \sum_{i \in P_u} \frac{1}{M_-^i} \sum_{m': y_{m'}^i = 0} 
\llb \min_{m: y_m^i = 1} f(u, i, m) \le f(u, i, m') \rrb,
$}
\end{equation}
where $M_-^i$ denotes the number of songs that are not in playlist $i$,
and $\llb \cdot \rrb$ is the indicator function that represents the 0-1 loss.

As a remark, it is easy to see that the order of songs in a specific playlist does not affect the empirical 
risk~(\ref{eq:bprisk}) as long as they are scored higher than the lowest scored song in that playlist.
The optimisation problem~(\ref{eq:obj}) now become the following regularised risk minimisation:
\begin{equation}
\label{eq:obj_rank}
\min_\uptheta \ R(\uptheta) + \RCal_\textsc{rank}(\uptheta).
\end{equation}
%where the regularisation term $R(\uptheta)$ is defined in (\ref{eq:reg}).

There are two challenges to optimise the above objective,
namely, the non-differentiable 0-1 loss and the \emph{min} operator in $\RCal_\textsc{rank}(\uptheta)$.
To address these challenges, we first replace the 0-1 loss with one of its convex surrogate $\ell(f, y)$,
(\eg, the exponential loss $\ell(f, y) = e^{-fy}$, the logistic loss $\ell(f, y) = \log(1 + e^{-fy})$,
or the squared hinge loss $\ell(f, y) = [\max(0, \, 1 - fy)]^2$).
%which results in
%\begin{equation}
%\label{eq:obj}
%\min_\uptheta \ R(\uptheta) + \frac{1}{N} \sum_{i=1}^U \sum_{j \in P_i} \frac{1}{M_-^j} \sum_{m': y_{m'}^j = 0} 
%                \ell \left( \min_{m: y_m^j = 1} f(m, j) - f(m', j) \right).
%\end{equation}



\subsection{Solving a constrained optimisation problem}

Suppose we use the exponential loss to upper-bound the 0-1 loss in $\RCal_\textsc{rank}$,
the multitask learning objective~(\ref{eq:obj_rank}) can be optimised by
\begin{equation}
\label{eq:expobj_rank}
\resizebox{.9\linewidth}{!}{$\displaystyle
\min_{\uptheta} \ R(\uptheta) + \frac{1}{N} \sum_{u=1}^U \sum_{i \in P_u} \frac{1}{M_-^i} 
                  \sum_{m': y_{m'}^i = 0} \exp \left(f(u, i, m') - \min_{m: y_m^i = 1} f(u, i, m) \right).
$}
\end{equation}

%Directly solving problem (\ref{eq:expobj}) is challenging due to the \emph{min} operator.
To deal with the challenge imposed by the \emph{min} operator in the exponential function, 
we reformulate problem (\ref{eq:expobj_rank}) into a constrained optimisation problem by 
introducing slack variables $\xi_i, \, i \in P_u, \, u \in \{1,\dots,U\}$,
\begin{equation}
\label{eq:expobj_cons}
\begin{aligned}
\min_{\uptheta} \ \, & R(\uptheta) + \frac{1}{N} \sum_{u=1}^U \sum_{i \in P_u} \frac{1}{M_-^i} \sum_{m': y_{m'}^i = 0} e^{f(u, i, m') - \xi_i} \\
s.t. \ \, & \xi_i \le f(u, i, m), \ \forall m \in \{1,\dots,M\} \ \text{and} \ y_m^i = 1.
\end{aligned}
\end{equation}

One may observe that the objective of problem~(\ref{eq:expobj_cons}) is convex but not differentiable due to 
the L1 regularisation terms in $R(\uptheta)$, nonetheless, we can use its sub-gradient.
Further, the number of constraints in problem~(\ref{eq:expobj_cons}) is
$$
\sum_{u=1}^U \sum_{i \in P_u} \sum_{m=1}^M \llb y_m^i = 1 \rrb,
$$
in other words, the number of constraints equals the total number of songs played in all playlists.
Asymptotically, it is of order $O(\widebar{L} N)$ where $\widebar{L}$ is the average number of songs in playlists.
Although $\widebar{L}$ is dataset dependent, and is typically less than $100$,
the total number of playlists $N$ can be very large in production systems 
(\eg, Spotify hosts more than $2$ billion playlists~\cite{recsysch2018}),
which imposes significant challenge when optimising problem~(\ref{eq:expobj_cons}).

We want to mention two techniques that can be employed to alleviate this issue:
the cutting-plane~\cite{avriel2003nonlinear} method and the sub-gradient method.
We have found both approaches converge extremely slow in practice for this problem, 
in particular, the cutting plane method is required to deal with constrained optimisation problems 
with at least $N$ constraints, which is still challenging when $N$ is large.
%but the minimum number of constraints is still in the order of $O(N)$, and we also found these techniques do not work extremely well in practice.

In this paper, we address this issue by formulating an unconstrained optimisation problem which approximates 
the objective in problem~(\ref{eq:expobj_cons}), by leveraging an equivalence relationship between bipartite 
ranking and binary classification~\cite{ertekin2011equivalence}, we describe this approach in the following section.

%\cheng{This still sounds hard. So what do we do next? Unclear why we suddenly talk about binary classification right after this.}



%\subsection{From ranking to classification}
\subsection{Unconstrained optimisation with classification loss}

It has been known that binary classification and bipartite ranking are
closely related~\cite{ertekin2011equivalence,menon2016bipartite}.
In particular, \citet{ertekin2011equivalence} have shown that the P-Norm Push bipartite ranking loss~\cite{rudin2009p}
is equivalent to the P-Classification loss~\cite{ertekin2011equivalence} when using the exponential surrogate.
Further, the P-Norm Push loss is an approximation of the Infinite-Push loss~\cite{agarwal2011infinite},
or equivalently, the Top-Push loss~\cite{li2014top}, which focuses on the highest ranked negative example instead of
of the lowest ranked positive example as in~(\ref{eq:bprisk}).

Inspired by these connections, we first seek a bipartite ranking loss that approximates the Bottom-Push loss in~(\ref{eq:bprisk}),
then propose a classification loss that is equivalent to this bipartite ranking loss.
The reason not to directly optimise the bipartite ranking loss is due to computation cost,
and classification loss can be optimised more efficiently in general~\cite{ertekin2011equivalence}.

We can approximate the \emph{min} operator by utilising the well known Log-sum-exp approximation 
of the \emph{max} operator~\cite[p. 72]{boyd2004convex},
\begin{equation}
\label{eq:minappox}
\min_i z_i = -\max_i (-z_i) \approx -\frac{1}{p} \log \sum_i e^{-p z_i},
\end{equation}
where $p > 0$ is a parameter that trades off the approximation precision.
This approximation becomes precise when $p \to \infty$.

By Eq.~(\ref{eq:bprisk}) and (\ref{eq:minappox}), the empirical risk $\RCal_\textsc{rank}$ can be approximated
(with the exponential surrogate) by $\widetilde\RCal_\textsc{rank}$ defined as
\begin{equation}
\label{eq:rankapprox}
\resizebox{.9\linewidth}{!}{$
\begin{aligned}
\widetilde\RCal_\textsc{rank}(\uptheta)
= \frac{1}{N} \sum_{u=1}^U \sum_{i \in P_u} \frac{1}{M_-^i} \left( \sum_{m: y_m^i = 1} \left( \sum_{m': y_{m'}^i = 0} 
  e^{-(f(u, i, m) - f(u, i, m'))} \right)^p \right)^\frac{1}{p}.
\end{aligned}
$}
\end{equation}


One may note that $\widetilde\RCal_\textsc{rank}$ can be transformed into the standard P-Norm Push loss by swapping the
positives ($m: y_m^i = 1$) and negatives ($m': y_{m'}^i = 0$). % define P-Norm Push first?
Inspired by this observation, we swap the positives and negatives in the P-Classification loss (by taking care of signs),
which results in the following classification risk:
\begin{equation}
\label{eq:clfrisk}
\resizebox{.9\linewidth}{!}{$\displaystyle
\RCal_\textsc{clf}(\uptheta)
= \frac{1}{N} \sum_{u=1}^U \sum_{i \in P_u} \left(
  \frac{1}{p M_+^i} \sum_{m: y_m^i = 1} e^{-p f(u, m, i)}
  + \frac{1}{M_-^i} \sum_{m': y_{m'}^i = 0} e^{f(u, m', i)} \right).
$}
\end{equation}

We have the following lemma:
\begin{lemma}
\label{lm:rank2clf}
Let $\uptheta^* \in \argmin_{\uptheta} \RCal_\textsc{clf}$ (assuming minimisers exist),
then $\uptheta^* \in \argmin_{\uptheta} \widetilde\RCal_\textsc{rank}$.
\end{lemma}

\begin{proof}
This theorem can be proved by swapping the positives and negatives in the proof of 
the equivalence between P-Norm Push loss and P-Classification loss~\cite{ertekin2011equivalence}.
A complete proof from first principles is described in Appendix.
\end{proof}

We can therefore create an unconstrained optimisation problem using the classification risk $\RCal_\textsc{clf}$:
\begin{equation}
\label{eq:expobj_clf}
\min_\uptheta \quad R(\uptheta) + \RCal_\textsc{clf}(\uptheta).
\end{equation}

The objective in problem~(\ref{eq:expobj_clf}) is convex but not differentiable due to the L1 regularisation terms in $R(\uptheta)$,
but it can be efficiently solved using the Orthant-Wise Limited-memory Quasi-Newton (OWL-QN)~\cite{andrew2007scalable} L-BFGS variant.

We refer the approach that solves problem~(\ref{eq:expobj_clf}) as \emph{Multitask Classification} in experiment.
As a remark, the optimal solutions of problem (\ref{eq:expobj_clf}) are not necessarily the optimal solutions 
of problem $\min_\uptheta \ R(\uptheta) + \widetilde\RCal_\textsc{rank}(\uptheta)$ due to the regularisation terms,
however, when parameters $\uptheta$ are small (which is generally the case when using regularisation), the two objectives 
can nonetheless approximate each other in acceptable level.


%\cheng{Explain in words why one is ranking, and the other one classification.}

%\cheng{New subsection: Describe the difference between existing and new user.}

%\subsection{Discussion}

%In this section, we want to discuss the advantages and limitations of the
%two approaches that solve problem~(\ref{eq:expobj}),
%as well as a few practical strategies for the proposed approaches.
%
%The constrained optimisation problem~(\ref{eq:expobj_cons}) can be solved using interior-point method,
%although the large number of constraints requires a large amount of computation resources.
%Cutting-plane~\cite{avriel2003nonlinear} techniques can be employed to deal with this challenge,
%but we found it does not work extremely well in practice.
%However, this approach allows us to use other surrogate losses besides the exponential loss,
%such as squared hinge loss, which may provide a few other desired properties. % detailing this
% solvers: IPOPT, CVX etc.

%To solve the unconstrained optimisation problem~(\ref{eq:expobj_clf}),
%the Orthant-Wise Limited-memory Quasi-Newton (OWL-QN)~\cite{andrew2007scalable} L-BFGS variant can be employed to
%efficiently deal with the L1 regularisation term without imposing huge memory burdens.
% solver: pylbfgs

%\cheng{Justify why we need to compare two methods empirically: multitask classification, multitask ranking.}
