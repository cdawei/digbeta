\section{Multitask learning for playlist recommendation}
\label{sec:method}

In this section, we introduce a multitask objective that supports the three cold-start settings
described in Section~\ref{sec:problem}. 
We optimise the multitask objective by minimising a bipartite ranking loss that encourages songs in a playlist
ranked higher than those are not, which involves a convex constrained optimisation problem.
Inspired by an equivalence relationship between bipartite ranking and binary classification, 
we propose a classification loss that approximates the multitask objective without dealing with any constraints.
This enables the efficient optimisation of the multitask objective.

%We propose a ranking approach to optimise the multitask objective 
%by solving an convex constrained optimisation problem.
%We analyse the challenge to deal with a large number of constraints and then propose an classification approach
%that approximates the multitask objective without any constraints, which results in an efficient optimisation of
%the multitask objective.


\subsection{Multitask learning objective}

Let $P_u$ denote the set of playlists from user $u$.
We aim to learn a function $f(m, i, u)$ that measures the affinity between song $m$ and playlist $i$ from user $u$.
%playlist $i$ and song $m$. 
Suppose $f$ has a linear form
\begin{equation}
\label{eq:scorefunc}
f(m, i, u) = \w_{i,u}^\top \x_m,
\end{equation}
where $m \in \{1,\dots,M\}, \ i \in P_u, \ u \in \{1,\dots,U\}$,
vector $\w_{i,u}$ represents the parameters of playlist $i$ from user $u$,
and vector $\x_m$ represents features of song $m$.

We decompose the representation of playlist $i$ from user $u$ %in (\ref{eq:scorefunc}) 
into three components, \ie
$$
\w_{i,u} = \alphabm_i + \betabm_u + \bmu,
$$
where $\alphabm_i$ is a parameter vector specific for playlist $i$,
$\betabm_u$ is the component for user $u$,
and $\bmu$ is a representation shared by all users.

Let $\upthetabm$ represent all parameters in $\alphabm_i, \betabm_u, \bmu, \ i \in P_u, \ u \in \{1,\dots,U\}$.
The learning task is to minimise the empirical risk of affinity function $f$ on dataset $\DCal$ over $\upthetabm$,
%Formally, 
\ie we solve an optimisation problem
\begin{equation}
\label{eq:obj}
\min_{\upthetabm} \, \Omega(\upthetabm) + R(f, \DCal),
\end{equation}
where $\Omega(\upthetabm)$ is a regularisation term and $R(f, \DCal)$ denotes the empirical risk.
We call the objective in problem~(\ref{eq:obj}) the {\it multitask learning objective},
as it jointly learns from multiple tasks where each task is to recommend a set of songs given a user or a playlist.

We assume that playlists of the \emph{same} user have \emph{similar} representations,
%and the difference between playlists $i$ and $i'$ of the same user $j$ is reflected by the playlist component $\bv_i$
%and $\bv_{i'}$, respectively.
%This assumption requires that parameters specific to playlist should be sparse,
which can be achieved by imposing an L1 regularisation term (on playlist parameters)
that encourages sparse representations, \ie $\sum_{u=1}^U \sum_{i \in P_u} \| \alphabm_i \|_1$.
Lastly, although the representations of different users are different,
we assume they nonetheless share a small number of features in their representations.
This can be achieved similarly by imposing an %additional 
L1 regularisation term $\| \bmu \|_1$.

The regularisation terms in our multitask learning objective can thus be summarised as
\begin{equation}
\label{eq:reg}
\Omega(\upthetabm) = \lambda_1 \sum_{u=1}^U \sum_{i \in P_u} \|\alphabm_i\|_1 + \lambda_2 \sum_{u=1}^U \|\betabm_u\|_2^2 + \lambda_3 \| \bmu \|_1,
\end{equation}
% where we add an L2 regularisation term to penalise large values in user representations,
% and constants $\lambda_1, \lambda_2, \lambda_3 \in \R_+$.
where constants $\lambda_1, \lambda_2, \lambda_3 \in \R_+$,
and the  L2 regularisation term is to penalise large values in user representations.

Once all parameters have been learned, 
we make a recommendation by first score each song according to available information (\eg an existing playlist, an existing user or a new user),
then form a playlist by either taking the top-K scored songs or sampling songs proportional to their scores.
Specifically, in the {\it cold songs} setting, 
% where we recommend a set of new songs to extend an existing playlist $i$ from user $u$, 
% we score a new song $m$ by
we extend an existing playlist $i$ from user $u$ by scoring a new song $m$ as
$$
\hat f(m, i, u) = (\alphabm_i + \betabm_u + \bmu)^\top \x_m.
$$

Furthermore, in the {\it cold playlists} setting, 
% where we recommend a set of songs to form a new playlist for an existing user $u$, 
% we score song $m$ by
we form a new playlist for an existing user $u$ by scoring song $m$ as
$$
\hat f(m, \cdot, u) = (\betabm_u + \bmu)^\top \x_m.
$$

Finally, in the {\it cold users} setting, 
% where we recommend a set of songs to form a playlist for a new user,
% we score song $m$ by
we form a playlist for a new user by scoring song $m$ as
$$
\hat f(m, \cdot, \cdot) = \bmu^\top \x_m.
$$




\subsection{Recommending the most probable songs}
\label{ssec:bploss}

%In this section, we describe a ranking approach that learns to rank songs in playlist above
%those not in it, which aims to rank the most probable songs above those unlikely when making a recommendation.
%The corresponding loss function of this approach is known as the Bottom-Push loss~\cite{rudin2009p} in bipartite ranking literature.
%
%Formally, for playlist $i$, we would like
%\begin{equation*}
%\begin{aligned}
%\min_{m: y_m^i = 1} f(i, m) \ge f(i, n), \ \forall n \in \{1,\dots,M\} \ \text{and} \ y_n^i = 0,
%\end{aligned}
%\end{equation*}
%where $y_m^i = 1$ denotes that song $m$ is in playlist $i$,
%and $y_n^i = 0$ represents song $n$ does not appear in playlist $i$.
%but have a higher score than the lowest ranked song in playlist, 
%
%Formally, we minimise the number of songs not in playlist but ranked above the lowest ranked song in playlist,
We optimise the multitask objective by minimising a bipartite ranking loss 
that encourages songs in a playlist ranked higher than those are not, 
which aims to rank the most probable songs above those unlikely when making a recommendation.
In particular, we minimise the number of songs not in the playlist but ranked above the lowest ranked song in the playlist
\footnote{This is known as the Bottom-Push loss~\cite{rudin2009p} in bipartite ranking literature.},
\ie the %(normalised) 
empirical risk is
\begin{equation}
\label{eq:bprisk}
\resizebox{.9\linewidth}{!}{$\displaystyle
R_\textsc{rank}(\upthetabm) = \frac{1}{N} \sum_{u=1}^U \sum_{i \in P_u} \frac{1}{M_-^i} \sum_{m': y_{m'}^i = 0} 
\llb \min_{m: y_m^i = 1} f(m, i, u) \le f(m', i, u) \rrb,
$}
\end{equation}
where $M_-^i$ denotes the number of songs that are not in playlist $i$,
binary variable $y_m^i$ denotes whether song $m$ appears in playlist $i$,
and $\llb \cdot \rrb$ is the indicator function that represents the 0-1 loss.

As a remark, it is obvious that the order of songs in a playlist does not affect the empirical 
risk $R_\textsc{rank}$ as long as they are ranked higher than the lowest ranked song in the playlist.
The optimisation problem~(\ref{eq:obj}) can now be instantiated as 
% now become the following regularised risk minimisation:
\begin{equation}
\label{eq:obj_rank}
\min_\upthetabm \ \Omega(\upthetabm) + R_\textsc{rank}(\upthetabm).
\end{equation}
%where the regularisation term $\Omega(\upthetabm)$ is defined in (\ref{eq:reg}).

There are two challenges to %optimise the above objective,
solve problem~(\ref{eq:obj_rank}),
namely, the non-differentiable 0-1 loss and the \emph{min} operator in $R_\textsc{rank}$.
To address the first challenge, we replace the 0-1 loss with one of its convex surrogate $\ell$
(\eg the exponential loss $\ell(f, y) = e^{-fy}$, the logistic loss $\ell(f, y) = \log(1 + e^{-fy})$,
or the squared hinge loss $\ell(f, y) = [\max(0, \, 1 - fy)]^2$).
We deal with the \emph{min} operator in empirical risk $R_\textsc{rank}$ in the following sections.

%which results in
%\begin{equation}
%\label{eq:obj}
%\min_\upthetabm \ \Omega(\upthetabm) + \frac{1}{N} \sum_{i=1}^U \sum_{j \in P_i} \frac{1}{M_-^j} \sum_{m': y_{m'}^j = 0} 
%                \ell \left( \min_{m: y_m^j = 1} f(m, j) - f(m', j) \right).
%\end{equation}



\subsection{Solving a constrained optimisation problem}

Suppose we use the exponential loss $\ell(f, y) = e^{-fy}$ to upper-bound the 0-1 loss in $R_\textsc{rank}$,
%the multitask learning objective~(\ref{eq:obj_rank}) can be optimised by
problem~(\ref{eq:obj_rank}) can be optimised by
\begin{equation}
\label{eq:expobj_rank}
\resizebox{.9\linewidth}{!}{$\displaystyle
\min_{\upthetabm} \ \Omega(\upthetabm) + \frac{1}{N} \sum_{u=1}^U \sum_{i \in P_u} \frac{1}{M_-^i} 
                  \sum_{m': y_{m'}^i = 0} \exp \left(f(m', i, u) - \min_{m: y_m^i = 1} f(m, i, u) \right).
$}
\end{equation}

%Directly solving problem (\ref{eq:expobj}) is challenging due to the \emph{min} operator.
To deal with the challenge imposed by the \emph{min} operator in the exponential function, 
we introduce slack variables $\xi_i$ to lower-bound the scores of songs in playlist $i, \, i \in P_u, \, u \in \{1,\dots,U\}$ 
and 
%we 
reformulate problem (\ref{eq:expobj_rank}) into a constrained optimisation problem %by 
%introducing slack variables $\xi_i, \, i \in P_u, \, u \in \{1,\dots,U\}$,
\begin{equation}
\label{eq:expobj_cons}
\begin{aligned}
\min_{\upthetabm} \ \, & \Omega(\upthetabm) + \frac{1}{N} \sum_{u=1}^U \sum_{i \in P_u} \frac{1}{M_-^i} \sum_{m': y_{m'}^i = 0} e^{f(m', i, u) - \xi_i} \\
s.t. \ \, & \xi_i \le f(m, i, u), \ \forall m \in \{1,\dots,M\} \ \text{and} \ y_m^i = 1.
\end{aligned}
\end{equation}

One may observe that the objective of problem~(\ref{eq:expobj_cons}) is convex but not differentiable due to 
the L1 regularisation terms in $\Omega(\upthetabm)$, nonetheless, we can use its sub-gradient.
Further, the number of constraints in problem~(\ref{eq:expobj_cons}) is
$$
\sum_{u=1}^U \sum_{i \in P_u} \sum_{m=1}^M \llb y_m^i = 1 \rrb,
$$
in other words, the number of constraints equals the total number of songs played in all playlists.
Asymptotically, it is of order $O(\widebar{L} N)$ where $\widebar{L}$ is the average number of songs in playlists.
Although $\widebar{L}$ is dataset dependent, and is typically less than $100$,
the total number of playlists $N$ can be very large in production systems 
(\eg Spotify hosts more than $2$ billion playlists~\cite{recsysch2018}),
which imposes significant challenge when optimising problem~(\ref{eq:expobj_cons}).

We want to mention two techniques that can be employed to alleviate this issue:
the cutting-plane~\cite{avriel2003nonlinear} method and the sub-gradient method.
We have found both approaches converge extremely slowly for this problem in practice.
In particular, the cutting plane method is required to deal with a constrained optimisation problem 
with at least $N$ constraints in each iteration, which remains challenging when $N$ is large.
%but the minimum number of constraints is still in the order of $O(N)$, and we also found these techniques do not work extremely well in practice.

In this paper, we address this issue by formulating an unconstrained optimisation problem which approximates 
the objective in problem~(\ref{eq:expobj_cons}), by leveraging an equivalence relationship between bipartite 
ranking and binary classification~\cite{ertekin2011equivalence}, we describe this method in the next section.

%\cheng{This still sounds hard. So what do we do next? Unclear why we suddenly talk about binary classification right after this.}



%\subsection{From ranking to classification}
\subsection{Unconstrained optimisation with classification loss}

It has been known that binary classification and bipartite ranking are
closely related~\cite{ertekin2011equivalence,menon2016bipartite}.
In particular, \citet{ertekin2011equivalence} have shown that the P-Norm Push bipartite ranking loss~\cite{rudin2009p}
is equivalent to the P-Classification loss~\cite{ertekin2011equivalence} when using the exponential surrogate.
Further, the P-Norm Push loss is an approximation of the Infinite-Push loss~\cite{agarwal2011infinite},
or equivalently, the Top-Push loss~\cite{li2014top}, which focuses on the highest ranked negative example instead of
the lowest ranked positive example as in the Bottom-Push loss~\cite{rudin2009p} we adopted in~(\ref{eq:bprisk}).

Inspired by these connections, 
we first approximate the loss function in the objective of problem~(\ref{eq:expobj_rank}) with
a bipartite ranking loss, which is equivalent to a classification loss.
We then optimise the classification loss to avoid dealing with a large number of 
constraints\footnote{We choose not to directly optimise the bipartite ranking loss 
since classification loss can be optimised more efficiently in general~\cite{ertekin2011equivalence}.}.
%
%we first seek a bipartite ranking loss that approximates the Bottom-Push loss in~(\ref{eq:bprisk}),
%then propose a classification loss that is equivalent to this bipartite ranking loss.
%The reason not to directly optimise the bipartite ranking loss is due to computation cost,
%and classification loss can be optimised more efficiently in general~\cite{ertekin2011equivalence}.
In particular, 
we can approximate the \emph{min} operator by utilising the well known Log-sum-exp approximation 
of the \emph{max} operator~\cite[p. 72]{boyd2004convex},
\begin{equation}
\label{eq:minappox}
\min_i z_i = -\max_i (-z_i) \approx -\frac{1}{p} \log \sum_i e^{-p z_i},
\end{equation}
where $p > 0$ is a parameter that trades off the approximation precision.
This approximation becomes precise when $p \to \infty$.

By Eq.~(\ref{eq:bprisk}) and (\ref{eq:minappox}), the empirical risk $R_\textsc{rank}$ can be approximated
(with the exponential surrogate) by $\widetilde R_\textsc{rank}$ defined as
\begin{equation}
\label{eq:rankapprox}
\resizebox{.9\linewidth}{!}{$
\begin{aligned}
\widetilde R_\textsc{rank}(\upthetabm)
= \frac{1}{N} \sum_{u=1}^U \sum_{i \in P_u} \frac{1}{M_-^i} \left( \sum_{m: y_m^i = 1} \left( \sum_{m': y_{m'}^i = 0} 
  e^{-(f(m, i, u) - f(m', i, u))} \right)^p \right)^\frac{1}{p}.
\end{aligned}
$}
\end{equation}


One may note that $\widetilde R_\textsc{rank}$ can be transformed into the standard P-Norm Push loss by swapping the
positives ($m: y_m^i = 1$) and negatives ($m': y_{m'}^i = 0$). % define P-Norm Push first?
Inspired by this observation, we swap the positives and negatives in the P-Classification loss (by taking care of signs),
which results in the following classification risk:
\begin{equation}
\label{eq:clfrisk}
\resizebox{.9\linewidth}{!}{$\displaystyle
R_\textsc{clf}(\upthetabm)
= \frac{1}{N} \sum_{u=1}^U \sum_{i \in P_u} \left(
  \frac{1}{p M_+^i} \sum_{m: y_m^i = 1} e^{-p f(m, i, u)}
  + \frac{1}{M_-^i} \sum_{m': y_{m'}^i = 0} e^{f(m', i, u)} \right).
$}
\end{equation}

We have the following lemma:
\begin{lemma}
\label{lm:rank2clf}
Let $\upthetabm^* \in \argmin_{\upthetabm} R_\textsc{clf}$ (assuming minimisers exist),
then $\upthetabm^* \in \argmin_{\upthetabm} \widetilde R_\textsc{rank}$.
\end{lemma}

\begin{proof}
This theorem can be proved by swapping the positives and negatives in the proof of 
the equivalence between P-Norm Push loss and P-Classification loss~\cite{ertekin2011equivalence}.
A complete proof from first principles is described in Appendix.
\end{proof}

We can therefore create an unconstrained optimisation problem using the classification risk $R_\textsc{clf}$:
\begin{equation}
\label{eq:expobj_clf}
\min_\upthetabm \ \Omega(\upthetabm) + R_\textsc{clf}(\upthetabm).
\end{equation}

The objective in problem~(\ref{eq:expobj_clf}) is convex but not differentiable due to the L1 regularisation terms in $\Omega(\upthetabm)$.
However, it can be efficiently solved using the Orthant-Wise Limited-memory Quasi-Newton (OWL-QN)~\cite{andrew2007scalable} L-BFGS variant.

We refer the approach that solves problem~(\ref{eq:expobj_clf}) as \emph{Multitask Classification} (MTC) in experiment.
As a remark, the optimal solutions of problem (\ref{eq:expobj_clf}) are not necessarily the optimal solutions 
of problem $\min_\upthetabm \ \Omega(\upthetabm) + \widetilde R_\textsc{rank}(\upthetabm)$ due to the regularisation terms.
However, when parameters $\upthetabm$ are small (which is generally the case when using regularisation), the two objectives 
can nonetheless approximate each other within an acceptable level.


%\cheng{Explain in words why one is ranking, and the other one classification.}

%\cheng{New subsection: Describe the difference between existing and new user.}

%\subsection{Discussion}

%In this section, we want to discuss the advantages and limitations of the
%two approaches that solve problem~(\ref{eq:expobj}),
%as well as a few practical strategies for the proposed approaches.
%
%The constrained optimisation problem~(\ref{eq:expobj_cons}) can be solved using interior-point method,
%although the large number of constraints requires a large amount of computation resources.
%Cutting-plane~\cite{avriel2003nonlinear} techniques can be employed to deal with this challenge,
%but we found it does not work extremely well in practice.
%However, this approach allows us to use other surrogate losses besides the exponential loss,
%such as squared hinge loss, which may provide a few other desired properties. % detailing this
% solvers: IPOPT, CVX etc.

%To solve the unconstrained optimisation problem~(\ref{eq:expobj_clf}),
%the Orthant-Wise Limited-memory Quasi-Newton (OWL-QN)~\cite{andrew2007scalable} L-BFGS variant can be employed to
%efficiently deal with the L1 regularisation term without imposing huge memory burdens.
% solver: pylbfgs

%\cheng{Justify why we need to compare two methods empirically: multitask classification, multitask ranking.}
