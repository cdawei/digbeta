\section{Multitask learning for music recommendation}
\label{sec:method}

\subsection{Multitask learning objective}

We assume that existing playlists of a user can help predict songs in another playlist of the same user,
further, playlists of one user can also help predict songs in playlist of another user.
In other words, we jointly learn from multiple tasks where each task is to predict a set of songs in a playlist.
We therefore decompose the representation of a playlist $j$ from user $i$ into three components, formally,
$$
\w_j = \bv_j + \bu_i + \widebar\bu,
$$
where $\bv_j$ is a parameter vector specific for playlist $j$,
$\bu_i$ is the component for user $i$,
and $\widebar\bu$ is a representation shared by all users.


The learning task is to minimise the empirical risk of scoring function $f$ on dataset $\DCal$ over model parameters.
Let $\uptheta$ which represents all parameters in $\bv_j, \bu_i, \widebar\bu, \, i=1,\dots,U, \, j \in P_u$.
Formally, we solve an optimisation problem
\begin{equation}
\label{eq:obj}
\min_{\uptheta} \, R(\uptheta) + \RCal(f, \DCal),
\end{equation}
where $R(\uptheta)$ is the regularisation term and $\RCal(f, \DCal)$ denotes the empirical risk.

The second assumption we make in this work is playlists of the \emph{same} user have \emph{similar} representations,
%and the difference between playlists $i$ and $i'$ of the same user $j$ is reflected by the playlist component $\bv_i$
%and $\bv_{i'}$, respectively.
%This assumption requires that parameters specific to playlist should be sparse,
which can be achieved by imposing an L1 regularisation, \ie $\sum_{i=1}^U \sum_{j \in P_i} \| \bv_j \|_1$
that encourages sparse representations.

The last assumption we make is that representations of different users are different,
but they nonetheless share a small number of features in their representations.
This assumption can be formalised similarly by imposing an additional L1 regularisation term $\| \widebar\bu \|_1$.

In summary, the regularisation term in our multitask learning objective is
\begin{equation}
\label{eq:reg}
R(\uptheta) = \lambda_1 \sum_{i=1}^U \sum_{j \in P_u} \|\bv_j\|_1 + \lambda_2 \sum_{i=1}^U \|\bu_i\|_2^2 + \lambda_3 \|\widebar\bu\|_1,
\end{equation}
where we add an L2 regularisation term to penalise large values in user representations,
and $\lambda_1, \lambda_2, \lambda_3 \in \R_+$ are regularisation constants.

To make recommendations we first score each song in music collection
$$
s(\x_m) = \hat \w^\top \x_m, \ m \in \{1,\dots,M\},
$$
where an existing user $i$ implies $\hat\w = \bu_i + \widebar\bu$, and $\hat\w = \widebar\bu$ for new users,
then we can form a playlist by either taking the top-K scored songs or sampling songs proportional to their scores.

\subsection{Recommending the most probable songs}
\label{ssec:bploss}

In this section, we describe a ranking based approach that learns to rank songs in playlist higher
than those not in it, which hopefully ranks the most probable songs above those unlikely when making a recommendation.
This is known as the Bottom-Push loss~\cite{rudin2009p} in bipartite ranking literature.
%Formally, for playlist $i$, we would like
%\begin{equation*}
%\begin{aligned}
%\min_{m: y_m^i = 1} f(i, m) \ge f(i, n), \ \forall n \in \{1,\dots,M\} \ \text{and} \ y_n^i = 0,
%\end{aligned}
%\end{equation*}
%where $y_m^i = 1$ denotes that song $m$ is in playlist $i$,
%and $y_n^i = 0$ represents song $n$ does not appear in playlist $i$.


Formally, we minimise the number of songs not in playlist but ranked above the lowest ranked song in playlist,
%but have a higher score than the lowest ranked song in playlist, 
\ie the (normalised) empirical risk is
\begin{equation}
\label{eq:bprisk}
\resizebox{.9\linewidth}{!}{$\displaystyle
\RCal_\textsc{rank}(\uptheta) = \frac{1}{N} \sum_{i=1}^U \sum_{j \in P_u} \frac{1}{M_-^j} \sum_{m': y_{m'}^j = 0} 
\llb \min_{m: y_m^j = 1} f(m, j) \le f(m', j) \rrb,
$}
\end{equation}
where $M_-^j$ denotes the number of songs that are not in playlist $j$,
and $\llb \cdot \rrb$ is the indicator function that represents the 0-1 loss.

It is obvious that the order of songs in a specific playlist does not affect the empirical risk as long as they are ranked 
above the lowest scored song with regards to that playlist.

To learn parameters of playlists, we optimise the following regularised risk:
$$
\min_\uptheta \ R(\uptheta) + \RCal_\textsc{rank}(\uptheta),
$$
where the regularisation term $R(\uptheta)$ is defined in (\ref{eq:reg}).
There are two challenges to optimise the above objective,
namely, the non-differentiable 0-1 loss and the \emph{min} operator in $\RCal_\textsc{rank}(\uptheta)$.

To address these challenges, we first we replace the 0-1 loss with one of its convex surrogate $\ell(f, y)$,
(\eg the exponential loss $\ell(f, y) = e^{-fy}$, the logistic loss $\ell(f, y) = \log(1 + e^{-fy})$,
or the squared hinge loss $\ell(f, y) = [\max(0, \, 1 - fy)]^2$).
%which results in
%\begin{equation}
%\label{eq:obj}
%\min_\uptheta \ R(\uptheta) + \frac{1}{N} \sum_{i=1}^U \sum_{j \in P_i} \frac{1}{M_-^j} \sum_{m': y_{m'}^j = 0} 
%                \ell \left( \min_{m: y_m^j = 1} f(m, j) - f(m', j) \right).
%\end{equation}



\subsection{Solving a constrained optimisation problem}

Suppose we use the exponential loss, the multitask learning objective~(\ref{eq:obj}) can be optimised by
\begin{equation}
\label{eq:expobj}
\resizebox{.9\linewidth}{!}{$\displaystyle
\min_{\uptheta} \ R(\uptheta) + \frac{1}{N} \sum_{i=1}^U \sum_{j \in P_i} \frac{1}{M_-^i} 
                  \sum_{m': y_{m'}^j = 0} \exp \left(f(j, m') - \min_{m: y_m^j = 1} f(j, m) \right).
$}
\end{equation}

%Directly solving problem (\ref{eq:expobj}) is challenging due to the \emph{min} operator.
To deal with the challenge imposed by the \emph{min} operator, we reformulate problem (\ref{eq:expobj}) 
into a constrained optimisation problem by introducing slack variables $\xi_j, \, j \in P_i, \, i \in \{1,\dots,U\}$,
\begin{equation}
\label{eq:expobj_cons}
\begin{aligned}
\min_{\uptheta} \ \, & R(\uptheta) + \frac{1}{N} \sum_{i=1}^U \sum_{j \in P_i} \frac{1}{M_-^j} \sum_{m': y_{m'}^j = 0} e^{f(j, m') - \xi_j} \\
s.t. \ \, & \xi_j \le f(j, m), \ \forall m \in \{1,\dots,M\} \ \text{and} \ y_m^j = 1.
\end{aligned}
\end{equation}

One may observe that the objective of problem~(\ref{eq:expobj_cons}) is convex but not differentiable due to 
the L1 regularisation terms in $R(\uptheta)$, nonetheless, we can its sub-gradient.
Another observation is the number of constraints in problem~(\ref{eq:expobj_cons}) is
$
\sum_{i=1}^U \sum_{j \in P_i} \sum_{m=1}^M \llb y_m^j = 1 \rrb,
$
in other words, the number of constraints equals the total number of songs played in all playlists.
Asymptotically, it is of order $O(\widebar{L} N)$ where $\widebar{L}$ is the average number of songs in playlists.
Although $\widebar{L}$ is dataset dependent, and is typically less than $100$,
the total number of playlists $N$ can be very large in production systems (\eg Spotify hosts more than $2$ billion playlists~\cite{recsysch2018}),
which imposes significant challenge when optimising problem~(\ref{eq:expobj_cons}).

We want to mention two techniques that can be employed to alleviate this issue,
namely, the cutting-plane~\cite{avriel2003nonlinear} method and the sub-gradient method.
However, we have found both approaches converge extremely slow in practice for this problem, 
in particular, the cutting plane method is required to deal with constrained optimisation problems 
with at least $N$ constraints, which is still challenging when $N$ is large.
%but the minimum number of constraints is still in the order of $O(N)$, and we also found these techniques do not work extremely well in practice.

We address this issue by formulating an unconstrained optimisation problem which approximates the objective in problem~(\ref{eq:expobj_cons}),
by leveraging an equivalence relationship between bipartite ranking and binary classification~\cite{ertekin2011equivalence},
we describe this approach in the following section.

%\cheng{This still sounds hard. So what do we do next? Unclear why we suddenly talk about binary classification right after this.}



%\subsection{From ranking to classification}
\subsection{Unconstrained optimisation with classification loss}

It has been known that binary classification and bipartite ranking are
closely related~\cite{ertekin2011equivalence,menon2016bipartite}.
In particular, \citet{ertekin2011equivalence} have shown that the P-Norm Push bipartite ranking loss~\cite{rudin2009p}
is equivalent to the P-Classification loss~\cite{ertekin2011equivalence} when using the exponential surrogate.
Further, the P-Norm Push loss is an approximation of the Infinite-Push loss~\cite{agarwal2011infinite},
or equivalently, the Top-Push loss~\cite{li2014top}, which focuses on the highest ranked negative example instead of
of the lowest ranked positive example as in~(\ref{eq:bprisk}).

Inspired by these connections, we first seek a bipartite ranking loss that approximates the Bottom-Push loss in~(\ref{eq:bprisk}),
then propose a classification loss that is equivalent to this bipartite ranking loss.
The reason not to directly optimise the bipartite ranking loss is due to computation cost,
and classification loss can be optimised more efficiently in general~\cite{ertekin2011equivalence}.

We can approximate the \emph{min} operator by utilising the well known Log-sum-exp approximation 
of the \emph{max} operator~\cite[p. 72]{boyd2004convex},
\begin{equation}
\label{eq:minappox}
\min_i z_i = -\max_i (-z_i) \approx -\frac{1}{p} \log \sum_i e^{-p z_i},
\end{equation}
where $p > 0$ is a parameter that trades off the approximation precision.
This approximation becomes precise when $p \to \infty$.

By Eq.~(\ref{eq:bprisk}) and (\ref{eq:minappox}), the empirical risk $\RCal_\textsc{rank}$ can be approximated
(with the exponential surrogate) by $\widetilde\RCal_\textsc{rank}$ defined as
\begin{equation}
\label{eq:rankapprox}
\resizebox{.9\linewidth}{!}{$
\begin{aligned}
\widetilde\RCal_\textsc{rank}(\uptheta)
= \frac{1}{N} \sum_{1=1}^U \sum_{j \in P_i} \frac{1}{M_-^j} \left( \sum_{m: y_m^j = 1} \left( \sum_{m': y_{m'}^j = 0} 
  e^{-(f(m, j) - f(m', j))} \right)^p \right)^\frac{1}{p}.
\end{aligned}
$}
\end{equation}


One may note that $\widetilde\RCal_\textsc{rank}$ can be transformed into the standard P-Norm Push loss swapping the
positives ($m: y_m^j = 1$) and negatives ($m': y_{m'}^j = 0$). % define P-Norm Push first?
Inspired by this observation, we swap the positives and negatives in the P-Classification loss (by taking care of signs),
which results in the following classification risk:
\begin{equation}
\label{eq:clfrisk}
\resizebox{.9\linewidth}{!}{$\displaystyle
\RCal_\textsc{clf}(\uptheta)
= \frac{1}{N} \sum_{i=1}^U \sum_{j \in P_i} \left(
  \frac{1}{p M_+^j} \sum_{m: y_m^j = 1} e^{-p f(m, j)}
  + \frac{1}{M_-^j} \sum_{m': y_{m'}^j = 0} e^{f(m', j)} \right).
$}
\end{equation}

We have the following lemma:
\begin{lemma}
\label{lm:rank2clf}
Let $\W^* \in \argmin_{\W} \RCal_\textsc{clf}$ (assuming minimisers exist),
then $\W^* \in \argmin_{\W} \widetilde\RCal_\textsc{rank}$.
\end{lemma}

\begin{proof}
This theorem can be proved by swapping the positives and negatives in the proof of 
the equivalence between P-Norm Push loss and P-Classification loss~\cite{ertekin2011equivalence}.
A complete proof from first principles is described in Appendix.
\end{proof}

We can therefore create an unconstrained optimisation problem using the classification risk $\RCal_\textsc{clf}$:
\begin{equation}
\label{eq:expobj_clf}
\min_\uptheta \quad R(\uptheta) + \RCal_\textsc{clf}(\uptheta).
\end{equation}

The objective in problem~(\ref{eq:expobj_clf}) is convex but not differentiable due to the L1 regularisation terms in $R(\uptheta)$,
but it can be efficiently solved using the Orthant-Wise Limited-memory Quasi-Newton (OWL-QN)~\cite{andrew2007scalable} L-BFGS variant.

As a remark, the optimal solutions of problem (\ref{eq:expobj_clf}) are not necessarily the optimal solutions 
of problem $\min_\uptheta \ R(\uptheta) + \widetilde\RCal_\textsc{rank}(\uptheta)$ due to the regularisation terms,
however, when parameters $\uptheta$ are small (which is generally the case when using regularisation), the two objectives 
can nonetheless approximate each other in acceptable level.


%\cheng{Explain in words why one is ranking, and the other one classification.}

%\cheng{New subsection: Describe the difference between existing and new user.}

%\subsection{Discussion}

%In this section, we want to discuss the advantages and limitations of the
%two approaches that solve problem~(\ref{eq:expobj}),
%as well as a few practical strategies for the proposed approaches.
%
%The constrained optimisation problem~(\ref{eq:expobj_cons}) can be solved using interior-point method,
%although the large number of constraints requires a large amount of computation resources.
%Cutting-plane~\cite{avriel2003nonlinear} techniques can be employed to deal with this challenge,
%but we found it does not work extremely well in practice.
%However, this approach allows us to use other surrogate losses besides the exponential loss,
%such as squared hinge loss, which may provide a few other desired properties. % detailing this
% solvers: IPOPT, CVX etc.

%To solve the unconstrained optimisation problem~(\ref{eq:expobj_clf}),
%the Orthant-Wise Limited-memory Quasi-Newton (OWL-QN)~\cite{andrew2007scalable} L-BFGS variant can be employed to
%efficiently deal with the L1 regularisation term without imposing huge memory burdens.
% solver: pylbfgs

%\cheng{Justify why we need to compare two methods empirically: multitask classification, multitask ranking.}
