% 1. Recommend songs for playlists
% Problems description
% - playlist augmentation
% - new song recommendation
% - related work: the same, the different
%
% 2. Playlist augmentation and bipartite ranking
% Method:
% - augment one playlist can be achieved by bipartite ranking (assume order of tracks is irrelevant)
% - known: bipartite ranking == binary classification (under assumptions)
% - Theorem 1
% 
% 3. Playlist augmentation and multi-label classification
% Method:
% - augment multiple playlists -> multiple bipartite ranking -> multi-label classification
% - Theorem 2
% - one user has multiple playlists -> multi-task regularisation
%
% 4. New song recommendation: an extension of playlist augmentation
% Method:
% - the same as previous work (cold start)
% - the different (?)
%
% 5. Experiment
% - multi-label classification
% - playlist augmentation
% - new song recommendation
% 1. Recommend songs for playlists
% Problems description
% - playlist augmentation
% - new song recommendation
% - related work: the same, the different
%

\section{Problem}

% brief description of both recommendation tasks
We are motivated by the problem of automatically augmenting music playlist with a collection of songs $\SCal$,
in particular, given a partial playlist with the first $K$ songs\footnote{$K$ can be different for other partial playlists.},
we would like to recommend a subset of $\SCal$ by learning from user created playlist dataset.
This task is also known as Automatic Playlist Continuation~\cite{schedl2017,recsysch2018}.


\section{Related work}
% related work
% describe each task with related work: the same, the different
% describe that we don't use the order of songs, conflicting findings in literature
% mainly two pieces of work:
% - music recommendation
% - playlist generation

We are interested in two variants of the playlist recommendation problem,
one is augmenting a playlist by recommending a subset of songs from a collection of music $\SCal$,
given the first $K$ seed songs, where $K$ can be any positive integer from 1 to the total number of songs minus 1.
% in contrast to settings where all songs except the last one are observed\cite{}, or giving a fixed number of seed songs\cite{}.
Another variant is restricting that all recommended songs are not observed during learning,
\ie recommending newly released songs to augment a given playlist, which is an instance of the cold-start problem.
We call the first variant \emph{playlist augmentation} and the second \emph{new song recommendation}.


\section{Machine learning tasks for playlist recommendation}

\paragraph{Playlist augmentation}
We formulate the task of augmenting existing playlist as a multi-label classification problem,
that is, for each song that is not in the given playlist, 
we predict whether it will be added to augment the given playlist.
This formulation is illustrated in Figure~\ref{fig:pla},
where rows represent songs (no specific order) and columns represent playlists (no specific order).
Further, columns with white colour represent playlists in training set, 
and columns with grey colour represent playlists that should be augmented (\ie test set).
Similar to the formulation in Section~\ref{ssec:newsongrec}, if entry $(i, j)$ is \texttt{1} (or \texttt{0}), 
it means the $i$-th song is (or not) found in the $j$-th playlist, 
and a question mark \texttt{?} means that we do not know whether the $i$-th song is found in the $j$-th playlist.
As a remark, columns represent playlists in test set contain only \texttt{1} and \texttt{?} entries.

\input{fig_pla}


\paragraph{New song recommendation}
We formulate the task of recommending newly released songs to augment existing playlists
as a multi-label classification problem, where we predict, for each song, 
whether it will be included in a given playlist.
This formulation is illustrated in Figure~\ref{fig:mlr},
where rows represent songs (from top to bottom, sorted by the release date in ascending order)
and columns represent playlists (no specific order).
Further, rows with white colour represent songs in training set, and rows with grey colour represent songs in test set.
If entry $(i, j)$ is \texttt{1} (or \texttt{0}), it means the $i$-th song is (or not) found in the $j$-th playlist,
otherwise, we do not know whether the $i$-th song is found in the $j$-th playlist (\ie entry $(i, j)$ is a question mark \texttt{?}).
As a remark, we do not care about the order of songs in a playlist.

\input{fig_mlr}



\section{Methods}
{\it Two methods for the problem of automatically augmenting music playlist are described here, but only one of them is necessary for this paper.}


\subsection{Playlist augmentation as multi-label classification}
% so we can just do multiple bipartite ranking for these two problems?
% we can actually do better than this, given \ref{ertekin2011equivalence} showed that P-Classification == P-Norm Push, 
% we have (equivalence in binary setting) and (extend the equivalence to multi-label setting)
% so 
% - an independent  bipartite ranking seems to be a better baseline?
% - bottom push on MLC dataset?
% - Theorem 1
\input{binary}

% 3. Playlist augmentation and multi-label classification
% Method:
% - augment multiple playlists -> multiple bipartite ranking -> multi-label classification
% - Theorem 2
% - one user has multiple playlists -> multi-task regularisation
%
\input{multilabel}

% 4. New song recommendation: an extension of playlist augmentation
% Method:
% - the same as previous work (cold start)
% - the different (?)
%


\subsection{Playlist augmentation as bipartite ranking}
% For users with only one playlist, describe the Top push loss for bipartite ranking, and its dual
% For users with multiple playlists, use multitask regularisation + bipartite ranking w/ Top Push loss for each playlist, and the dual

Given a partial playlist with $K$ seed songs, a natural approach to recommend a subset of music collection $\SCal$ is 
ranking songs in $\SCal$ that are not seed songs, in particular, songs that are more relevant to the playlist should be
ranked higher that those that are not, which is a bipartite ranking problem.

%This can be formulated as a bipartite ranking problem where songs in the given playlist have positive labels,
%while songs that are not part of the playlist have negative labels.

% equation of bipartite ranking for playlist augmentation


\paragraph{Focusing on the most plausible songs}
One approach to focus on the most plausible songs, for a specific playlist,
is to learn a recommender system by minimising the rank of the top ranked song which is not in the playlist,
in other words, the higher it ranked over songs in playlist, the harder we penalise the learning system.
This is known as the Top Push loss in bipartite ranking~\cite{li2014top}, which is formally defined as,
\begin{equation}
\label{eq:toppush}
\LCal_\textsc{tp}(f; \DCal) 
= \frac{1}{|\DCal_+|} \sum_{\x_+ \in \DCal_+} \llb f(\x_+) \le \max_{\x_- \in \DCal_-} f(\x_-) \rrb.
\end{equation}

To optimise the objective~\ref{eq:toppush}, 
we firstly have to replace the indicator function (0-1 loss) with one of its convex surrogate loss,
such as the exponential loss $\ell(f, y) = e^{-fy}$, logistic loss $\ell(f, y) = \log(1 + e^{-fy}$, or squared hinge loss $\ell(f, y) = (1 - fy)^2$.
Further, we have to deal with challenge of the $\max$ operator in (\ref{eq:toppush}), which can sometimes be dealt with using the dual formulation.
If the ranking function $f$ has a linear form, \ie $f(\x) = \w^\top \x$, it has been shown that the dual formulation of (\ref{eq:toppush}) 
with L2 regularisation is~\cite{li2014top}:
\begin{equation*}
\begin{aligned}
\min_{\alphabm, \betabm} \, & \frac{1}{2 \lambda |\DCal_+|} \| \alphabm^\top \X^+ - \betabm^\top \X^- \|^2 + \ell^*(\alphabm), \\
s.t. \ & \one^\top \alphabm = \one^\top \betabm, \\
       & \alphabm \in \R_+^{|\DCal_+|}, \, \betabm \in \R_+^{|\DCal_-|},
\end{aligned}
\end{equation*}
where $\ell^*$ is the convex conjugate of $\ell$.


\paragraph{Multitask regularisation}
% a user, in general, has multiple playlists, a reasonable assumption is that playlists of one user are more similar than playlists of different users,
% so we use a multitask regularisation to ensure the weights of playlists for the same users should be similar
Another observation is that a user generally has more than one playlists,
a reasonable assumption is playlists of the same user share similar characteristics. 
Suppose we learn a parameter vector for each playlist, then one approach to formalise this similarity is using an extra regulariser
for each user $u$ that has $N_u$ playlists,
\begin{equation}
\label{eq:mtreg}
\begin{aligned}
&\frac{1}{2 N_u (N_u - 1) / 2} \sum_{i < j \in \{1,\dots,N_u\}} \| \w_i - \w_j \|^2 \\
&= \frac{1}{N_u (N_u - 1)} \left( (N_u - 1) \sum_{i=1}^{N_u} \w_i^\top \w_i - 2 \sum_{i < j \in \{1,\dots,N_u\}} \w_i^\top \w_j \right) \\
&= \frac{1}{N_u} \sum_{i=1}^{N_u} \w_i^\top \w_i - \frac{2}{N_u (N_u - 1)} \sum_{i < j \in \{1,\dots,N_u\}} \w_i^\top \w_j %\\
%&= \frac{1}{N_u} \sum_{i=1}^{N_u} \w_i^\top \w_i - \frac{1}{N_u (N_u - 1)} \sum_{i=1}^{N_u} \sum_{j \in \{1,\dots,N_u\}, j \ne i} \w_i^\top \w_j \\
%&= \left( \frac{1}{N_u} + \frac{1}{N_u (N_u - 1)} \right) \sum_{i=1}^{N_u} \w_i^\top \w_i 
%   - \frac{1}{N_u (N_u - 1)} \sum_{i=1}^{N_u} \sum_{j=1}^{N_u} \w_i^\top \w_j \\
%&= \frac{1}{N_u - 1} \sum_{i=1}^{N_u} \w_i^\top \w_i - \frac{1}{N_u (N_u - 1)} \sum_{i=1}^{N_u} \sum_{j=1}^{N_u} \w_i^\top \w_j.
\end{aligned}
\end{equation}
We call this regulariser \emph{multitask regulariser} as we regularise the weights of multiple bipartite ranking tasks. 

To optimise for the most plausible songs, we minimise the Top Push loss for each playlist of user $u$, 
in addition to the L2 regularisation, we take into account the multitask regulariser, which results in an objective:
\begin{equation}
\label{eq:mtobj}
\begin{aligned}
&\frac{\lambda_1}{2 N_u} \sum_{i=1}^{N_u} \| \w_i \|^2
+ \frac{\lambda_2}{2 N_u (N_u - 1) / 2} \sum_{i < j \in \{1,\dots,N_u\}} \| \w_i - \w_j \|^2 
+ \frac{1}{N_u} \sum_{i = 1}^{N_u} \frac{1}{|\DCal_+^i|} \sum_{\x_+ \in \DCal_+^i} \llb f(\x_+) \le \max_{\x_- \in \DCal_-^i} f(\x_-) \rrb \\
&= \frac{\lambda_1 + 2\lambda_2}{2 N_u} \sum_{i=1}^{N_u} \w_i^\top \w_i 
- \frac{2\lambda_2}{N_u (N_u - 1)} \sum_{i < j \in \{1,\dots,N_u\}} \w_i^\top \w_j
+ \frac{1}{N_u} \sum_{i = 1}^{N_u} \frac{1}{|\DCal_+^i|} \sum_{\x_+ \in \DCal_+^i} \llb f(\x_+) \le \max_{\x_- \in \DCal_-^i} f(\x_-) \rrb.
\end{aligned}
\end{equation}

If we assume linear ranking function $f(\x) = \w^\top \x$, we can show that the dual of (\ref{eq:mtobj}) is
\begin{equation}
\label{eq:mtdual}
\begin{aligned}
\end{aligned}
\end{equation}

\input{mt_dual}

%\section{Experiment}
% experiments on two playlist dataset
\input{experiment}
