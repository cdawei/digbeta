\subsection{Variant II}

Let function $f(\cdot; \cdot)$ be
$$
f(\x^n; \w_k) := g(\x^n; \w_k) + b_k, \ n \in \{1,\dots,N\}, \, k \in \{1,\dots,K\}
$$
where $\w_k$ and $b_k$ is the weight vector and bias parameter for the $k$-th label, respectively.
Function $g(\x^n; \w_k)$ is differentiable and bounded.

Suppose $\alpha, \beta, c \in \R_+$ are \emph{finite} positive numbers, 
and $\C, \Pb, \Q \in \R^K$ are vectors of \emph{finite} (non-zero) real numbers.
We can define $\RCal_\textsc{mc}\pb{2}$ be the following risk:
\begin{equation}
\label{eq:mc2}
\RCal_\textsc{mc}\pb{2}(\W, \bb) 
= \sum_{k=1}^K \left[ 
  \frac{P_k}{\alpha} \sum_{m: y_k^m = 1} \exp(-\alpha f(\x^m; \w_k)) +
  \frac{Q_k}{\beta } \sum_{n: y_k^n = 0} \exp( \beta  f(\x^n; \w_k)) \right].
\end{equation}
and let $\RCal_\textsc{mr}\pb{2}$ be a risk defined as
\begin{equation}
\label{eq:mr2}
\RCal_\textsc{mr}\pb{2}(\W, \bb) 
= \sum_{k=1}^K C_k
  \left[ \sum_{m: y_k^m = 1} \exp(-\alpha f(\x^m; \w_k)) \right]^\frac{c}{\alpha} 
  \left[ \sum_{n: y_k^n = 0} \exp( \beta  f(\x^n; \w_k)) \right]^\frac{c}{\beta}.
\end{equation}
Note that 
\begin{equation*}
\begin{aligned}
\RCal_\textsc{mr}\pb{2}(\W, \bb)
&= \sum_{k=1}^K C_k
   \left[ \sum_{m: y_k^m = 1} \left( \sum_{n: y_k^n = 0} 
   \exp(-\beta(f(\x^m; \w_k) - f(\x^n; \w_k))) \right)^\frac{\alpha}{\beta} \right]^\frac{c}{\alpha} \\
&= \sum_{k=1}^K C_k
   \left[ \sum_{n: y_k^n = 0} \left( \sum_{m: y_k^m = 1}
   \exp(-\alpha(f(\x^m; \w_k) - f(\x^n; \w_k))) \right)^\frac{\beta}{\alpha} \right]^\frac{c}{\beta}.
\end{aligned}
\end{equation*}
It is obvious that $\RCal_\textsc{mr}\pb{2}$ is independent of $\bb$ since $f(\x^m; \w_k) - f(\x^n; \w_k) = g(\x^m; \w_k) - g(\x^n; \w_k)$,
so we denote it as $\RCal_\textsc{mr}\pb{2}(\W)$.


\begin{theorem}
\label{theorem:mc2mr2}
If $(\W_\textsc{mc}\pb{2}, \bb_\textsc{mc}\pb{2}) \in \argmin_{\W,\bb} \RCal_\textsc{mc}\pb{2}(\W, \bb)$ (assuming minimisers exist),
then $\W_\textsc{mc}\pb{2} \in \argmin_\W \RCal_\textsc{mr}\pb{2}(\W)$.
\end{theorem}


\begin{proof}
Let $(\W_\textsc{mc}\pb{2}, \bb_\textsc{mc}\pb{2})$ be a minimiser of $\RCal_\textsc{mc}\pb{2}(\W, \bb)$ (assuming minimisers exist),
then we have
\begin{equation*}
\begin{aligned}
0 
&= \frac{\partial \, \RCal_\textsc{mc}\pb{2}(\W, \bb)} {\partial \, b_k} \Bigg|_{\W = \W_\textsc{mc}\pb{2}, \, \bb = \bb_\textsc{mc}\pb{2}} \\
&= \frac{P_k}{\alpha} \sum_{m: y_k^m = 1} \exp(-\alpha f(\x^m; \w_k)) \cdot (-\alpha) \, + \,
   \frac{Q_k}{\beta } \sum_{n: y_k^n = 0} \exp( \beta  f(\x^n; \w_k)) \cdot \beta 
   \Big|_{\W = \W_\textsc{mc}\pb{2}, \, \bb = \bb_\textsc{mc}\pb{2}},
\end{aligned}
\end{equation*}
so for $k \in \{1,\dots,K\}$, we have
\begin{equation}
\label{eq:skew_ml2}
\sum_{m: y_k^m = 1} \exp(-\alpha g(\x^m; \w_k))
\Big|_{\W = \W_\textsc{mc}\pb{2}}
= \frac{Q_k}{P_k} \exp((\alpha + \beta) b_\textsc{mc}\pb{2}) \sum_{n: y_k^n = 0} \exp( \beta g(\x^n; \w_k))
  \Big|_{\W = \W_\textsc{mc}\pb{2}}.
\end{equation}
which acts similarly as the skew condition in~\cite{ertekin2011equivalence}.

Further,
\begin{equation*}
\begin{aligned}
0 
&= \frac{\partial \, \RCal_\textsc{mc}\pb{2}(\W, \bb)} {\partial \, \w_k} \Bigg|_{\W = \W_\textsc{mc}\pb{2}, \, \bb = \bb_\textsc{mc}\pb{2}} \\
&= \frac{P_k}{\alpha} \sum_{m: y_k^m = 1} \exp(-\alpha f(\x^m; \w_k)) \cdot (-\alpha) \cdot
   \frac{\partial \, g(\x^m; \w_k)}{\partial \, \w_k} \, + \,
   \frac{Q_k}{\beta} \sum_{n: y_k^n = 0} \exp(\beta f(\x^n; \w_k) \cdot \beta \cdot
   \frac{\partial \, g(\x^n; \w_k)}{\partial \, \w_k} \Bigg|_{\W = \W_\textsc{mc}\pb{2}, \, \bb = \bb_\textsc{mc}\pb{2}},
\end{aligned}
\end{equation*}
so for $k \in \{1,\dots,K\}$, we have
\begin{equation}
\label{eq:grad_mc2_eq0}
\begin{aligned}
\sum_{m: y_k^m = 1} \exp(-\alpha g(\x^m; \w_k))
\frac{\partial \, g(\x^m; \w_k)}{\partial \, \w_k}
\Bigg|_{\W = \W_\textsc{mc}\pb{2}}
= \frac{Q_k}{P_k} \exp((\alpha + \beta) b_\textsc{mc}\pb{2}) \sum_{n: y_k^n = 0} \exp(\beta g(\x^n; \w_k)
  \frac{\partial \, g(\x^n; \w_k)}{\partial \, \w_k} 
  \Bigg|_{\W = \W_\textsc{mc}\pb{2}}.
\end{aligned}
\end{equation}

Note that
\begin{equation}
\label{eq:grad_mr2}
\begin{aligned}
\frac{\partial \, \RCal_\textsc{mr}\pb{2}(\W)} {\partial \, \w_k}
=& \left[ \sum_{m: y_k^m = 1} \exp(-\alpha f(\x^m; \w_k)) \right]^{\frac{c}{\alpha} - 1} C_k \frac{c}{\alpha} 
   \sum_{m: y_k^m = 1} \exp(-\alpha f(\x^m; \w_k)) \cdot (-\alpha) 
   \frac{\partial \, g(\x^m; \w_k)}{\partial \, \w_k}
   \left[ \sum_{n: y_k^n = 0} \exp( \beta  f(\x^n; \w_k)) \right]^\frac{c}{\beta} \\
 & + 
   \left[ \sum_{m: y_k^m = 1} \exp(-\alpha f(\x^m; \w_k)) \right]^\frac{c}{\alpha}
   \left[ \sum_{n: y_k^n = 0} \exp( \beta  f(\x^n; \w_k)) \right]^{\frac{c}{\beta} - 1} C_k \frac{c}{\beta}
   \sum_{n: y_k^n = 0} \exp( \beta  f(\x^n; \w_k)) \cdot \beta 
   \frac{\partial \, g(\x^n; \w_k)}{\partial \, \w_k} \\
=& \left[ \sum_{m: y_k^m = 1} \exp(-\alpha f(\x^m; \w_k)) \right]^{\frac{c}{\alpha} - 1}
   \left[ \sum_{n: y_k^n = 0} \exp( \beta  f(\x^n; \w_k)) \right]^{\frac{c}{\beta} - 1}
   C_k (-c) \exp((\beta - \alpha) b) \\
 & \left[ 
   \sum_{m: y_k^m = 1} \exp(-\alpha g(\x^m; \w_k))
   \frac{\partial \, g(\x^m; \w_k)}{\partial \, \w_k}
   \sum_{n: y_k^n = 0} \exp( \beta  g(\x^n; \w_k)) \right. \\
 & \quad \left. - 
   \sum_{m: y_k^m = 1} \exp(-\alpha g(\x^m; \w_k))
   \sum_{n: y_k^n = 0} \exp( \beta  g(\x^n; \w_k))
   \frac{\partial \, g(\x^n; \w_k)}{\partial \, \w_k} \right]
\end{aligned}
\end{equation}

By first using Eq.~(\ref{eq:skew_ml2}) and then (\ref{eq:grad_mc2_eq0}), we have
\begin{equation}
\label{eq:mr2_equal}
\begin{aligned}
&  \sum_{m: y_k^m = 1} \exp(-\alpha g(\x^m; \w_k))
   \sum_{n: y_k^n = 0} \exp( \beta  g(\x^n; \w_k))
   \frac{\partial \, g(\x^n; \w_k)}{\partial \, \w_k}
   \Bigg|_{\W = \W_\textsc{mc}\pb{2}} \\
&= \frac{Q_k}{P_k} \exp((\alpha + \beta) b_\textsc{mc}\pb{2}) \sum_{n: y_k^n = 0} \exp( \beta g(\x^n; \w_k))
   \sum_{n: y_k^n = 0} \exp( \beta  g(\x^n; \w_k))
   \frac{\partial \, g(\x^n; \w_k)}{\partial \, \w_k}
   \Bigg|_{\W = \W_\textsc{mc}\pb{2}} \\
&= \sum_{m: y_k^m = 1} \exp(-\alpha g(\x^m; \w_k))
   \frac{\partial \, g(\x^m; \w_k)}{\partial \, \w_k}
   \sum_{n: y_k^n = 0} \exp( \beta  g(\x^n; \w_k))
   \Bigg|_{\W = \W_\textsc{mc}\pb{2}}.
\end{aligned}
\end{equation}

Finally, by Eq.~(\ref{eq:grad_mr2}) and (\ref{eq:mr2_equal}), we have
$$
\frac{\partial \, \RCal_\textsc{mr}\pb{2}(\W)} {\partial \, \w_k} \Bigg|_{\W = \W_\textsc{mc}\pb{2}} = 0.
$$
This means $\W_\textsc{mc}\pb{2}$ is a minimiser of $\RCal_\textsc{mr}\pb{2}(\W)$.
\end{proof}


\begin{theorem}
\label{theorem:mr2mc2}
If $\W_\textsc{mr}\pb{2} \in \argmin_\W \RCal_\textsc{mr}\pb{2}(\W)$ (assuming minimisers exist),
then 
$$
(\W_\textsc{mr}\pb{2}, \bb\pb{2}) \in \argmin_{\W,\bb} \, \RCal_\textsc{mc}\pb{2}(\W, \bb),
$$ 
where
$$
b_k\pb{2}
= \frac{1}{\alpha + \beta}
  \ln \frac{P_k \sum_{m: y_k^m = 1} \exp(-\alpha g(\x^m; \w_k))} {Q_k \sum_{n: y_k^n = 0} \exp( \beta g(\x^n; \w_k))}
  \Bigg|_{\W = \W_\textsc{mc}\pb{2}},
  \quad k \in \{1,\dots,K\}.
$$
\end{theorem}
