\section{Experiment}
\label{sec:experiment}

We first evaluate the proposed method on the task of tagging text, 
using two standard multi-label classification dataset~\cite{katakis2008multilabel}.

\subsection{Multi-label classification}

Performance on multi-label dataset\footnote{Results of PRLR are taken from~\citep{lin2014multi}.}
are shown in terms of F$_1$ scores averaged over both examples and labels, 
as well as precision at $k$ which focus on the top-$k$ predictions.

The results are summarised in Table~\ref{tab:perf_mlc},
where the multi-label p-classification method output performance the binary relevance baseline by a large margin.
Further, it achieves better performance than (\citet{lin2014multi}) which encourages sparse and low-rank predictions.
Finally, it is encouraging that our method performs better than (\citet{belanger2016structured}) and (\citet{gygli2017deep}),
both work learn complex non-linear functions using deep neural networks, compared with our method which uses a linear function.

\begin{table}[!h]
\centering
\caption{Performance on multi-label dataset}
\label{tab:perf_mlc}
\resizebox{\linewidth}{!}{
\setlength{\tabcolsep}{2pt} % tweak the space between columns
%\begin{tabular}{l*{6}{c}}
\begin{tabular}{l|ccc|ccc}
\toprule
{} & \multicolumn{3}{c|}{\textbf{bibtex}} & \multicolumn{3}{c}{\textbf{bookmarks}} \\
{} &   F$_1$ Example & F$_1$ Label &    AUC &      F$_1$ Example & F$_1$ Label &    AUC \\
\midrule
Binary Relevance~\cite{}           &          $37.9$ &      $30.1$ & $85.3$ &             $29.5$ &      $21.0$ & $87.2$ \\
PRLR~\cite{lin2014multi}           &          $44.2$ &      $37.2$ &    N/A &             $34.9$ &      $23.0$ &    N/A \\
SPEN~\cite{belanger2016structured} &          $41.3$ &      $33.7$ & $92.6$ &             $35.5$ &      $24.1$ & $90.8$ \\
DVN~\cite{gygli2017deep}           &          $44.7$ &      $32.4$ & $86.7$ &             $37.2$ &      $23.7$ & $76.9$ \\
MLR (Ours)                         &          ${\bf 47.0}$ & ${\bf 38.8}$ & ${\bf 93.3}$ & ${\bf 37.7}$ & ${\bf 28.4}$ & ${\bf 91.8}$ \\
\bottomrule
\end{tabular}
}
\end{table}


\subsection{Playlist augmentation}

We further evaluate our proposed approach on a music playlist dataset, 
where we focus on the task of augmenting user created playlist.

In particular, we split the songs in AotM-2011~\cite{mcfee2012hypergraph} playlist dataset
according to the ratio 70\%:10\%:20\%, which results in the training, validation and test set, respectively.
Given a new song which does not appeared in any playlist, 
we predict, for each playlist, whether to augment it with this song.

\newpage

\subsubsection{A few conclusions on a subset}
%\begin{table}[!h]
%\centering
%\caption{Statistics of subset}
Statistics of subset \\
\resizebox{\linewidth}{!}{
\begin{tabular}{cccccc}
\toprule
\#Users & \#Songs & \#Playlists (all)  & \#Playlists (incomplete) & \#Unknown entries &\#Song Features (audio + genre) \\
\midrule
15      & 786     & 108                & 24   & 18,723  & 217 \\
\bottomrule
\end{tabular}
}
%\end{table}


\paragraph{Which type of loss is most helpful?}
%\begin{table}[!h]
%\centering
%\caption{Empirical results on subset}
Empirical results on subset \\
\resizebox{\linewidth}{!}{
\begin{tabular}{l|cccc}
\toprule
{}            & Row-wise Loss & Column-wise Loss & Row-wise + Column-wise loss & Independent Logistic Regression \\
\midrule
AUC           & {\bf 0.5421}        & 0.5294           & 0.5411     & 0.5162 \\
HitRates@100  & 0.1481        & 0.1454           & 0.1502     & {\bf 0.1630} \\
\bottomrule
\end{tabular}
}
%\end{table}

\paragraph{Experimental design:}
C: 1, 1, 1, p: 1, no multi-task regularisation


\paragraph{Is multi-task regularisation helpful?}
%\begin{table}[!h]
%\centering
%\caption{Empirical results on subset}
Empirical results on subset \\
\resizebox{\linewidth}{!}{
\begin{tabular}{l|ccc}
\toprule
{}            & Multi-task Reg. + Row-wise Loss & Multi-task reg. + Column-wise Loss & Multi-task reg. + Row-wise + Column-wise Loss  \\
\midrule
AUC           & {\bf 0.6385}        & 0.6157     & 0.6329  \\
HitRates@100  & 0.2474        & 0.2443     & {\bf 0.2532}  \\
\bottomrule
\end{tabular}
}
%\end{table}

\paragraph{Experimental design:}
C: 1, 1, 1, p: 1, with multi-task regularisation, no user specific regularisation parameter.


\paragraph{Is user-specific multi-task regularisation parameter (based on \#playlists) helpful?}
%\begin{table}[!h]
%\centering
%\caption{Empirical results on subset: user-specific regularisation parameter = 1/\#playlists}
Empirical results on subset: user-specific regularisation parameter = 1/\#playlists \\
\resizebox{\linewidth}{!}{
\begin{tabular}{l|ccc}
\toprule
{}            & Multi-task Reg. + Row-wise Loss + user-spec reg. & Multi-task reg. + Column-wise Loss + user-spec reg. & Multi-task reg. + Row-wise + Column-wise Loss + user-spec reg. \\
\midrule
AUC           & 0.5844       & {\bf 0.6091}     & 0.5959  \\
HitRates@100  & 0.2269       & {\bf 0.2528}     & 0.2317  \\
\bottomrule
\end{tabular}
}
%\end{table}


%\begin{table}[!h]
%\centering
%\caption{Empirical results on subset: user-specific regularisation parameter = 1/(1 + log(\#playlists))}
Empirical results on subset: user-specific regularisation parameter = 1/(1 + log(\#playlists)) \\
\resizebox{\linewidth}{!}{
\begin{tabular}{l|ccc}
\toprule
{}            & Multi-task Reg. + Row-wise Loss + user-spec reg. & Multi-task reg. + Column-wise Loss + user-spec reg. & Multi-task reg. + Row-wise + Column-wise Loss + user-spec reg. \\
\midrule
AUC           & 0.6200        & 0.6113     & {\bf 0.6235}  \\
HitRates@100  & 0.2089        & {\bf 0.2397}     & 0.2254  \\
\bottomrule
\end{tabular}
}
%\end{table}

\paragraph{Experimental design:}
C: 1, 1, 1, p: 1, with multi-task regularisation, with user-specific regularisation parameter.


\newpage


\subsection{New song recommendation}

\subsubsection{A few conclusions on a subset}
%\begin{table}[!h]
%\centering
%\caption{Statistics of subset}
Statistics of subset \\
\resizebox{\linewidth}{!}{
\begin{tabular}{cccccc}
\toprule
\#Users & \#Songs (train/test) & \#Playlists & \#Unknown entries &\#Song Features (audio + genre) \\
\midrule
15      & 629 / 157  & 108 & 16,956  & 217 \\
\bottomrule
\end{tabular}
}
%\end{table}

\paragraph{Which type of loss is most helpful?}
%\begin{table}[!h]
%\centering
%\caption{Empirical results on subset}
Empirical results on subset \\
\resizebox{\linewidth}{!}{
\begin{tabular}{l|cccc}
\toprule
{}            & Row-wise Loss & Column-wise Loss & Row-wise + Column-wise loss & Independent Logistic Regression \\
\midrule
AUC           & {\bf 0.6808}        & 0.6689           & 0.6771     & 0.5930 \\
HitRates@100  & {\bf 0.8844}        & 0.8687           & 0.8690     & 0.7634 \\
\bottomrule
\end{tabular}
}
%\end{table}

\paragraph{Experimental design:}
C: 1, 1, 1, p: 1, no multi-task regularisation.



\paragraph{Is multi-task regularisation helpful?}

%\begin{table}[!h]
%\centering
%\caption{Empirical results on subset}
Empirical results on subset \\
\resizebox{\linewidth}{!}{
\begin{tabular}{l|ccc}
\toprule
{}            & Multi-task Reg. + Row-wise Loss & Multi-task reg. + Column-wise Loss & Multi-task reg. + Row-wise + Column-wise Loss  \\
\midrule
AUC           & 0.6811        & {\bf 0.6869}     & 0.6856 \\
HitRates@100  & {\bf 0.8782}        & 0.8692     & 0.8544 \\
\bottomrule
\end{tabular}
}
%\end{table}

\paragraph{Experimental design:}
C: 1, 1, 1, p: 1, with multi-task regularisation, no user specific regularisation parameter.



\paragraph{Is user-specific multi-task regularisation parameter (based on \#playlists) helpful?}
%\begin{table}[!h]
%\centering
%\caption{Empirical results on subset: user-specific regularisation parameter = 1/\#playlists}
Empirical results on subset: user-specific regularisation parameter = 1/\#playlists \\
\resizebox{\linewidth}{!}{
\begin{tabular}{l|ccc}
\toprule
{}            & Multi-task Reg. + Row-wise Loss + user-spec reg. & Multi-task reg. + Column-wise Loss + user-spec reg. & Multi-task reg. + Row-wise + Column-wise Loss + user-spec reg. \\
\midrule
AUC           & {\bf 0.7116}       & 0.6956     &  0.7106 \\
HitRates@100  & 0.8843       & 0.8696     &  {\bf 0.8973} \\
\bottomrule
\end{tabular}
}
%\end{table}

%\begin{table}[!h]
%\centering
%\caption{Empirical results on subset: user-specific regularisation parameter = 1/(1 + log(\#playlists))}
Empirical results on subset: user-specific regularisation parameter = 1/(1 + log(\#playlists)) \\
\resizebox{\linewidth}{!}{
\begin{tabular}{l|ccc}
\toprule
{}            & Multi-task Reg. + Row-wise Loss + user-spec reg. & Multi-task reg. + Column-wise Loss + user-spec reg. & Multi-task reg. + Row-wise + Column-wise Loss + user-spec reg. \\
\midrule
AUC           &  0.6914       & {\bf 0.7038}     & 0.7001  \\
HitRates@100  &  0.8501       & {\bf 0.8787}     & 0.8553  \\
\bottomrule
\end{tabular}
}
%\end{table}

\paragraph{Experimental design:}
C: 1, 1, 1, p: 1, with multi-task regularisation, with user-specific regularisation parameter.
