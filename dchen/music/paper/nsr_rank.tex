\section{New song recommendation as bipartite ranking}

We can formulate the new song recommendation problem as bipartite ranking problems, 
and we want to learn a scorer $f$ such that, for a given playlist, 
songs in this playlist will be scored higher than those not in the given playlist.

\begin{equation}
\label{eq:primal}
\begin{aligned}
&\min_{\V, \W, \mubm} \ \frac{\lambda}{2} \left( \frac{1}{U} \sum_{u=1}^U \bv_u^\top \bv_u 
     + \frac{1}{N} \sum_{i=1}^N \w_i^\top \w_i + \mubm^\top \mubm \right) \\
& \hspace{4em}
     + \frac{1}{N} \sum_{i=1}^N \frac{1}{M_i^+} \sum_{m: y_i^m = 1} \ell \left( (\bv_{u(i)} + \w_i + \mubm)^\top \x^m 
     - \max_{n: y_i^n = 0} (\bv_{u(i)} + \w_i + \mubm)^\top \x^n \right).
\end{aligned}
\end{equation}


The Lagrangian dual problem of (\ref{eq:primal}) when using the exponential surrogate is
\begin{equation}
\label{eq:dual}
\begin{aligned}
\min_{\Thetabm} \ & \frac{1}{2 \lambda} \left[
     U \sum_{u=1}^U \left( \sum_{i \in P_u} \thetabm_i^\top \X \right) \left( \sum_{i \in P_u} \thetabm_i^\top \X \right)^\top
   + N \sum_{i=1}^N \left( \thetabm_i^\top \X \right) \left( \thetabm_i^\top \X \right)^\top
   + \left( \sum_{i=1}^N \thetabm_i^\top \X \right) \left( \sum_{i=1}^N \thetabm_i^\top \X \right)^\top \right] \\
& \hspace{1em}
   + \sum_{i=1}^N \left( \y_i \circ \thetabm_i \right)^\top \left( (1 - \log(N M_i^+)) \y_i - \y_i \circ \log(-\thetabm_i) \right) \\
s.t. \ & \Thetabm^\top \one_M = \zero_N \\
           & \theta_i^n \ge 0, \, i \in \{1,\dots,N\}, \, n \in \{1,\dots,M\} \ \mathrm{and} \ y_i^n = 0.
\end{aligned}
\end{equation}
Note that the above objective can be computed as
\begin{equation*}
\begin{aligned}
J &= \frac{1}{2 \lambda} \sum_{n=1}^N \sum_{n'=1}^N (U \A + N \I_N + \one_{N \times N}) 
     \circ \left( \Thetabm^\top \X \right) \left( \Thetabm^\top \X \right)^\top \\
& \hspace{2em}
     + \sum_{i=1}^N \thetabm_i^\top \left( (1 - \log(N M_i^+)) \y_i - \y_i \circ \log(-\thetabm_i) \right),
\end{aligned}
\end{equation*}
where $\I_N \in \R^{N \times N}$ is an identity matirx and $\A \in \R^{N \times N}$ is a symmetric matrix such that
\begin{equation*}
A_{ij} = 
\begin{cases}
1, & \text{playlist} \ i \ \text{and} \ j \ \text{from the same user}, \\
0, & \text{otherwise}.
\end{cases}
\end{equation*}

The gradient of the optimisation objective w.r.t. to dual variables $\thetabm_k \in \R^{M}$, $k \in \{1,\dots,N\}$,
\begin{equation*}
\begin{aligned}
\frac{\partial J}{\partial \thetabm_k}
&= \frac{1}{2 \lambda} \left( U \cdot 2 \X \left(\sum_{i \in P_{u(k)}} \thetabm_i^\top \X \right)^\top 
   + N \cdot 2 \X \left( \thetabm_k^\top \X \right)^\top
   + 2 \X \left(\sum_{i=1}^N \thetabm_i^\top \X \right)^\top \right) \\
& \hspace{2em}
   + (1 - \log(N M_k^+)) \y_k - \y_k \circ \log(-\thetabm_k) + \y_k \circ \thetabm_k \left( -\frac{-1}{-\y_k \circ \thetabm_k} \right) \\
&= \frac{\X}{\lambda} \left( U \sum_{i \in P_{u(k)}} \thetabm_i^\top \X 
   + N \thetabm_k^\top \X 
   + \sum_{i=1}^N \thetabm_i^\top \X \right)^\top
   - \log(N M_k^+) \y_k - \y_k \circ \log(-\thetabm_k) \\
&= \frac{\X \X^\top}{\lambda} \left( U \sum_{i \in P_{u(k)}} \thetabm_i + N \thetabm_k + \sum_{i=1}^N \thetabm_i \right)^\top
   - \log(N M_k^+) \y_k - \y_k \circ \log(-\thetabm_k) \\
\end{aligned}
\end{equation*}

The hessian is
\begin{equation*}
\begin{aligned}
\frac{\partial^2 J}{\partial \thetabm_k^2}
&= \frac{\X}{\lambda} \left( U \X + N \X + \X \right)^\top - \Hb_k
 = \frac{1}{\lambda} (U + N + 1) \X \X^\top - \Hb_k,
\end{aligned}
\end{equation*}
where $\Hb_k \in \R^{M \times M}$ is a diagnoal matrix such that
\begin{equation*}
H_k^m = \frac{y_k^m}{\theta_k^m}, \ m = \{1,\dots,M\}.
\end{equation*}
