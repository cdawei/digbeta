\section{New song recommendation as bipartite ranking}

We can formulate the new song recommendation problem as bipartite ranking problems, 
and we want to learn a scorer $f$ such that, for a given playlist, 
songs in this playlist will be scored higher than those not in the given playlist.
The features of song $m$ are song audio features, genre and popularity, in contrast to playlist augmentation,
here the listening events from other users are not available due to songs in test set are cold-start items.

The optimisation problem is:
\begin{equation}
\label{eq:primal_nsr}
\begin{aligned}
&\min_{\V, \W, \mubm} \ \frac{\lambda}{2} \left( \frac{1}{U} \sum_{u=1}^U \bv_u^\top \bv_u 
     + \frac{1}{N} \sum_{i=1}^N \w_i^\top \w_i + \mubm^\top \mubm \right) \\
& \hspace{5em}
     + \frac{1}{N} \sum_{i=1}^N \frac{1}{M_i^+} \sum_{m: y_m^i = 1} \ell \left( (\bv_{u(i)} + \w_i + \mubm)^\top \x_m 
     - \max_{n: y_n^i = 0} (\bv_{u(i)} + \w_i + \mubm)^\top \x_n \right).
\end{aligned}
\end{equation}

Directly optimise the above problem is challenging due to the \emph{max} operator,
readily approaches including approximate the \emph{max} operator or formulate and solve the dual problem.


\subsection{Approximate the primal problem}
The optimisation objective in (\ref{eq:primal_nsr}) can be approximated as
\begin{equation*}
\begin{aligned}
J 
&\approx \frac{\lambda}{2} \left( \frac{1}{U} \sum_{u=1}^U \bv_u^\top \bv_u + \frac{1}{N} \sum_{i=1}^N \w_i^\top \w_i + \mubm^\top \mubm \right) \\
& \hspace{3em}
  + \sum_{i=1}^N \frac{1}{N M_i^+} 
    \left( \sum_{m: y_m^i = 1} e^{-(\bv_{u(i)} + \w_i + \mubm)^\top \x_m} \right)
    \left( \sum_{n: y_n^i = 0} e^{p (\bv_{u(i)} + \w_i + \mubm)^\top \x_n} \right)^\frac{1}{p}.
\end{aligned}
\end{equation*}


\subsection{Formulate the dual problem}
The Lagrangian dual problem of (\ref{eq:primal_nsr}) when using the exponential surrogate is
\begin{equation}
\label{eq:dual_nsr}
\begin{aligned}
\min_{\Thetabm} \ & \frac{1}{2 \lambda} \left[
     U \sum_{u=1}^U \left( \sum_{i \in P_u} \thetabm_i \right)^\top \X \X^\top \left( \sum_{i \in P_u} \thetabm_i \right)
   + N \sum_{i=1}^N \thetabm_i^\top \X \X^\top \thetabm_i
   + \left( \sum_{i=1}^N \thetabm_i \right)^\top \X \X^\top \left( \sum_{i=1}^N \thetabm_i \right) \right] \\
& \hspace{2em}
   + \sum_{i=1}^N \left( \y_i \circ \thetabm_i \right)^\top \left( (1 - \log(N M_i^+)) \y_i - \y_i \circ \log(-\thetabm_i) \right), \\
s.t. \ 
& \Thetabm \one_M = \zero_N, \\
& \theta_i^m < 0, \ \mathrm{if} \ y_m^i = 1, \\
& \theta_i^n \ge 0, \ \mathrm{if} \ y_n^i = 0, \ i \in \{1,\dots,N\}, \, m,n \in \{1,\dots,M\}.
\end{aligned}
\end{equation}
