% !TEX root = ./main.tex

% \secmoveup
% \section{\trajrec as a Structured Prediction Problem}
% \label{sec:trajrec}
% \textmoveup

% We present the \trajrec problem,
% which shall serve as our canonical application of sequential recommendation.
% We first review the problem as it is typically treated in the literature,
% and then show how it may be viewed as a structured prediction problem.

% \secmoveup
% \subsection{\trajrec: standard view}
% \textbf{\trajrec: standard view}.
% \subsection{The \trajrec problem}
%\textbf{\trajrec}.

%\subsection{Examples of sequence recommendation}
%\label{sec:trajrec}

\section{Related work}
\label{sec:related}


We summarise recent work most related to sequence recommendation, 
in particular the problem of \trajrec, music playlist generation, 
and next basket prediction.

%To make the sequence recommendation problem more concrete,
%we provide three specific examples,
%starting with the problem of \trajrec
%that shall serve as a recurring motivation.
%%we explicate how a recently studied problem may be viewed as a special case.
%Note that in all these problems, one is specifically interested in sequences that are paths.

A classic approach for {\bf travel recommendation} is ranking locations with collaborative filtering~\cite{shi2011personalized,zhang2015location,ijcai13}.
%or matrix factorisation family of techniques applied to places and trajectories
Another approach regards route recommendation as a planning problem~\cite{brilhante2013shall,gioniswsdm14,ijcai15}.
%The TripBuilder system~\cite{brilhante2013shall} first solves a maximum coverage problem for user preference and then solves TSP for routing. 
The collaborative filtering approaches rank POI but do not take into account the sequence that a trip is taken. 
On the other hand, the planning approaches assume a fixed objective function that is not directly optimised to predict user behaviour. 
There have been a few approaches that jointly consider POI preferences and routes~\cite{chen2015tripplanner,kurashima2010geotag,kurashima2010geotag,cikm16paper}.

% There are, roughly, three problem settings that have been studied.
% The first setting is \emph{point of interest} (\emph{POI}) \emph{recommendation};
% Here, one wishes to rank various POIs in a city in order of how ``interesting'' they are to a given visitor,
% exploiting
% available metadata for each POI~\cite{shi2011personalized,lian2014geomf,hsieh2014mining,yuan2014graph}.
% The second setting is \emph{next location recommendation};
% here, given the sequence of a traveller's partial tour through a city,
% the goal is to recommend which POI the traveller should visit next~\cite{fpmc10,ijcai13,zhang2015location}.
%quantifying tourist traffic flow between points-of-interest~\cite{zheng2012patterns},
%formulating a binary decision or ranking problem~\cite{baraglia2013learnext}, and predicting the next location with
%or sequence models such as recurrent neural networks~\cite{aaai16}.
%The third setting is \emph{\trajrec},
%which is our interest in this paper.


% AKM: not sure these are suitable here
%
% This problem is related to automatic playlist generation,
% where we recommend a sequence of songs given a specified song (a.k.a. the seed) and the number of new songs.
% Formally, given a library of songs and a query $\mathbf{x} = (s, K)$, where $s$ is the seed and $K$ is the number of songs in playlist,
% we produce a list with $K$ songs (without duplication) by maximising the likelihood~\cite{chen2012playlist},
% \begin{equation*}
% %\max_{(y_1,\dots,y_K)} \prod_{k=2}^K \mathbb{P}(y_{k-1} \given y_k),~ y_1 = s ~\text{and}~ y_j \ne y_k,~ j \ne k.
% \mathbf{y}^* = \argmax_{\mathbf{y} \in \mathcal{P}_\mathbf{x}}~ \mathbb{P}(\mathbf{y} \given \mathbf{x}),~ \mathbf{y} = (y_1=s,\dots,y_K)
% ~\text{and}~ y_j \ne y_k ~\text{if}~ j \ne k.
% \end{equation*}

% Another similar problem is choosing a small set of photos from a large photo library and compiling them into a slideshow or movie.

%
%\subsection{\trajrec: structured view}
%\textbf{\trajrec: structured view}.
%\subsection{\trajrec as a structured prediction problem}


%%More abstractly,
%We can view \trajrec as sequence recommendation in the following way:
%given trajectory query $\x$, and a suitable scoring function $f$, we wish to find
%$\mathbf{y}^* = \argmax_{\mathbf{y} \in \mathcal{Y}}~f(\mathbf{x}, \mathbf{y}),$
%%%DW: use top-k prediction formulation or not?
%where $\mathcal{Y}$ is the set of all possible trajectories with POIs in $\mathcal{P}$ that conform to the constraints imposed by the query $\mathbf{x}$.
%In particular,
%$\mathbf{y} = (s,~ y_2, \dots, y_l)$ is a trajectory with $l$ POIs. %, which has no sub-tours. %i.e. $y_j \ne y_k$ if $j \ne k$.
%This was the view proposed in~\cite{cikm16paper} where they authors considered an
%objective function that added two components together: a POI score and a transition score.
%
%Now, our training set of historical trajectories may be written as
%$\{ ( \x\pb{i}, \{ \y\pb{ij} \}_{j=1}^{n_i} ) \}_{i=1}^{n}$,
%where each $\x\pb{i}$ is a distinct query
%with $\{ \y\pb{ij} \}_{j=1}^{n_i}$ the corresponding \emph{set} of observed trajectories.
%Note that we expect most queries to have several distinct trajectories;
%minimally,
%for example,
%there may be two nearby POIs that are visited in interchangeable order by different travellers.
%We are also interested in predicting paths $\y$, since it is unlikely a user will want to visit the same location twice.


%
%\textbf{Playlist generation}.
{\bf Playlist generation}
%As another example, 
considers recommending playlists (\ie sequences of songs) to users, given a query song~\citep{McFee:2011,chen2012playlist,hidasi2015session}.
A canonical approach is to
learn a latent representation of songs from historical playlists,
and exploit a Markovian assumption on the song transitions;
or to learn high quality transitions using RNNs~\cite{choi2016towards}.
%While a reasonable first order approximation, this assumption limits the modelling power of such approaches.

%
%\textbf{Next basket and next song prediction}.
{\bf Next basket prediction}
is another example of sequence recommendation,
%One more example of sequence recommendation is the problem of recommending 
where we recommend the next items a user might like to purchase, given the sequence of their shopping basket purchases~\citep{Rendle:2010,Wang:2015}.
The canonical approach here is to apply matrix factorisation to the Markov chain of transitions between items,
or modelling high quality transitions using RNNs.
This method is feasible because one is only interested in predicting %sequences 
one element at a time, instead of predicting a entire sequence given the initial item.



%\subsubsection{Existing approaches}
%
%Existing approaches treat the problem as one of determining a score for the intrinsic appeal of each POI.
%% based on implicit preference data in the training set.
%% Perhaps the simplest such approach is based on learning a model to predict whether a particular POI occurs, or not, in the trajectory corresponding to a query.
%% Formally, from the given set of trajectories
%% we derive a training set $\{ ( \x^{(i)}, p, y^{(i)} ) \}_{i = 1}^n$,
%% where each POI $p$ is augmented with a label $y^{(i)} \in \{ \pm 1 \}$ denoting whether or not it appeared in a trajectory corresponding to the query $\x^{(i)}$.
%% Formally, the objective used for training is
%% $$ \min_{\w} \frac{1}{2} \w^\top \w + C \cdot \sum_{i = 1}^n \sum_{p \in \mathcal{P}} \ell\left( y^{(i)} \cdot ( \w^\top \Phi( \x^{(i)}, p ) ) \right) $$
%% where
%% $\Phi( \cdot, \cdot )$ denotes a query-POI feature mapping,
%% $C > 0$ is some regularisation strength,
%% and $\ell( v )$ is any suitable margin loss, such as the logistic loss $\ell( v ) = \log( 1 + e^{-v} )$.
%% One can use the resulting model to produce a score for any POI $p$ given a new query $\x$,
%% and then pick the top-$l$ scoring POIs to produce a trajectory.
%%%For example, \citep{cikm16paper} proposed a RankSVM model,
%For example, a RankSVM model
%which %is fed as input %pairs $(p_i, p_j)$ of POIs such that $p_i$ appears ahead of $p_j$ in some trajectory.
%learns to predict whether a POI is likely to appear ahead of another POI in a trajectory corresponding to some query~\cite{cikm16paper}.
%Formally,
%from the given set of trajectories
%we derive a training set
%% $\{ ( \x^{(i)}, p, y^{(i)} ) \}_{i = 1}^n$,
%% where each POI $p$ is augmented with a label
%% %$y^{(i)} \in \{ \pm 1 \}$ denoting whether or not
%% $y^{(i)}$ denoting how many times
%% it appeared in a trajectory corresponding to the query $\x^{(i)}$.
%$\{ ( \x^{(i)}, \mathbf{r}^{(i)} ) \}_{i = 1}^n$,
%where for each trajectory query $\x^{(i)}$ there is a list of ranked POI pairs
%$\mathbf{r}^{(i)} \subseteq \mathcal{P} \times \mathcal{P}$
%such that
%$(p, p') \in \mathbf{r}^{(i)}$
%iff
%%POI $p$ is ranked above the POI $p'$ in the trajectories associated with $\x^{(i)}$, %according to some notion.
%%\eg based on the counts of the number of times a POI appears in the trajectories associated with a query.
%POI $p$ appears more times than POI $p'$ in all trajectories associated with $\x^{(i)}$. %according to some notion.
%The training objective is %then
%\begin{align}
%\resizebox{0.909\linewidth}{!}{$\displaystyle
%\displaystyle \min_{\w} ~\frac{1}{2} \w^\top \w + C \cdot \sum_{i = 1}^n \sum_{(p, p') \in \mathbf{r}^{(i)}}
%\ell\left( \w^\top ( \Psi( \x^{(i)}, p ) - \Psi( \x^{(i)}, p' ) ) \right),
%$} \label{eq:ranksvm}
%\end{align}
%for
%feature mapping $\Psi$,
%regularisation strength $C$ % > 0$,
%and squared hinge loss $\ell( v ) = \max( 0, 1 - v )^2$.
%%where $\Phi, C$ are as before,
%% where
%% $\Phi( \cdot, \cdot )$ denotes a query-POI feature mapping,
%% $C > 0$ is some regularisation strength,
%% and $\ell( v ) = \max( 0, 1 - v )^2$ is the squared hinge loss,
%% and
%% %$p \succeq_{\mathbf{x}} p'$ is denoted to mean that the
%% $\mathcal{R}( \x )$
%% denotes all pairs of POIs $(p, p')$ such that
%% POI $p$ is ranked above the POI $p'$ in the trajectories associated with $\x$, %according to some notion.
%% \eg based on the counts of the number of times a POI appears in the trajectories associated with a query.
%%For example, this may be computed by counting the number of times a POI appears in the trajectories associated with a query,
%%and using this to determine which of two POIs is more suitable for a query.



%
% To do this, we show how the problem can be cast as one of sequential recommendation,
% thus allowing us to leverage the tools developed in the previous section.

% Comparing the above to the discussion in the previous section, it is clear that
% we can cast \trajrec as a special case of the structured recommendation problem.
% Consequently, we may approach it using structured prediction methods such as the SSVM,
% as well as the extensions proposed to account for multiple ground truths and eliminate loops during training.

% AKM: repetitive
%
% standard SSVM
% We can learn a recommender by training a SSVM on the set of observed trajectories $\{\mathbf{x}^{(i')}, \mathbf{y}^{(i')}\}_{i'=1}^{N'}$,
% However, we ignore the fact that for the same query, we normally observed more than one trajectory,
% we would like to exploit this fact to better modelling the observed trajectories.

% AKM: repetitive
%
% \subsection{Query Aggregation}
% \label{sec:query}

% To modelling the fact that a given query has multiple observed trajectories,
% we firstly group trajectories according to queries, in other words,
% we now have a dataset $\{\mathbf{x}^{(i)}, \{\mathbf{y}^{(ij)}\}_{j=1}^{N_i}\}_{i=1}^N$
% with $N$ queries and queries $\mathbf{x}^{(i)}$ has $N_i$ trajectories observed.


% \subsection{Recommendation with Multiset SSVM}
% \label{sec:trajrec-ssvm}

% We can learn to recommend trajectories by training a multiset SSVM described in Section~\ref{sec:ssvm-ms}
