{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leave-one-out Evaluation of SSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leave-one-query-out evaluation of (single-/multi-label) SSVM with regularisation parameter $C$ tuned using Monte-Carlo cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import random\n",
    "import cvxopt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import pyximport; pyximport.install()\n",
    "from inference_lv import do_inference_list_viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from inference import do_inference_brute_force, do_inference_viterbi, do_inference_greedy\n",
    "from shared import TrajData, evaluate, do_evaluation\n",
    "from ssvm import SSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(1234554321)\n",
    "np.random.seed(123456789)\n",
    "cvxopt.base.setseed(123456789)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_JOBS = 6         # number of parallel jobs\n",
    "C_SET = [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100, 300, 1000, 3000]  # regularisation parameter\n",
    "MC_PORTION = 0.1   # the portion of data that sampled by Monte-Carlo cross-validation\n",
    "MC_NITER = 5       # number of iterations for Monte-Carlo cross-validation\n",
    "SSVM_SHARE_PARAMS = True  # share params among POIs/transitions in SSVM\n",
    "SSVM_MULTI_LABEL = True  # use multi-label SSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat_ix = 2\n",
    "data_dir = 'data/data-new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalised_hamming(seq1, seq2):\n",
    "    assert(len(seq1) > 1)\n",
    "    assert(len(seq2) > 1)\n",
    "    assert(len(seq1) == len(seq2))\n",
    "    length = len(seq1)\n",
    "    distance = 0\n",
    "    indicators = [seq1[i] != seq2[i] for i in range(length)]\n",
    "    return np.sum(indicators) / length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1 = [1, 3, 5]\n",
    "s2 = [1, 2, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_hamming(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_hamming(dat_obj, recdict):\n",
    "    assert(type(dat_obj) == TrajData)\n",
    "    #hamming_list = []\n",
    "    hamming_dict = dict()\n",
    "    for key in sorted(recdict.keys()):\n",
    "        assert(key in dat_obj.TRAJID_GROUP_DICT)\n",
    "        y_true_list = [dat_obj.traj_dict[tid] for tid in dat_obj.TRAJID_GROUP_DICT[key]]\n",
    "        y_hat_list = recdict[key]['PRED']\n",
    "        distance_list = [normalised_hamming(y_hat_list[0], y_true) for y_true in y_true_list]\n",
    "        #hamming_list.append(np.min(distance_list))\n",
    "        length = key[1]\n",
    "        distance = np.min(distance_list)\n",
    "        try:\n",
    "            hamming_dict[length].append(distance)\n",
    "        except KeyError:\n",
    "            hamming_dict[length] = [distance]\n",
    "    return hamming_dict\n",
    "    #avg_hamming = np.sum(hamming_list) / len(hamming_list)\n",
    "    #print('%d, %.3f' % (len(hamming_list), avg_hamming))\n",
    "    #return avg_hamming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat_obj = TrajData(dat_ix, data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_obj.dat_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = sorted(dat_obj.TRAJID_GROUP_DICT.keys())\n",
    "len(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rank = 'rank-' + dat_obj.dat_suffix[dat_ix] + '.pkl'\n",
    "#sppath = 'ssvm-A10-' + dat_obj.dat_suffix[dat_ix] + '.pkl'\n",
    "sp = 'ssvm-B-' + dat_obj.dat_suffix[dat_ix] + '.pkl'\n",
    "srpath = 'ssvm-C-' + dat_obj.dat_suffix[dat_ix] + '.pkl'\n",
    "sr = 'ssvm-D-' + dat_obj.dat_suffix[dat_ix] + '.pkl'\n",
    "\n",
    "rank_dict = pkl.load(open(os.path.join(data_dir, rank), 'rb'))\n",
    "sp_dict = pkl.load(open(os.path.join(data_dir, sp), 'rb'))\n",
    "sr_dict = pkl.load(open(os.path.join(data_dir, sr), 'rb'))\n",
    "srpath_dict = pkl.load(open(os.path.join(data_dir, srpath), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "F1_rank, pF1_rank, Tau_rank = do_evaluation(dat_obj, rank_dict, debug=DEBUG)\n",
    "F1_sp, pF1_sp, Tau_sp = do_evaluation(dat_obj, sp_dict, debug=DEBUG)\n",
    "F1_sr, pF1_sr, Tau_sr = do_evaluation(dat_obj, sr_dict, debug=DEBUG)\n",
    "F1_srpath, pF1_srpath, Tau_srpath = do_evaluation(dat_obj, srpath_dict, debug=DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "do_evaluation(dat_obj, rank_dict, debug=DEBUG)\n",
    "do_evaluation(dat_obj, sp_dict, debug=DEBUG)\n",
    "do_evaluation(dat_obj, sr_dict, debug=DEBUG)\n",
    "do_evaluation(dat_obj, srpath_dict, debug=DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rank_dist = evaluate_hamming(dat_obj, rank_dict)\n",
    "sp_dist = evaluate_hamming(dat_obj, sp_dict)\n",
    "sr_dist = evaluate_hamming(dat_obj, sr_dict)\n",
    "srpath_dist = evaluate_hamming(dat_obj, srpath_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_dicts = [rank_dist, sp_dist, sr_dist, srpath_dist]\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(dist_dicts), figsize=[15,3])\n",
    "for j in range(len(dist_dicts)):\n",
    "    X = sorted(dist_dicts[j].keys())\n",
    "    #Y = [np.mean(dist_dict[x]) for x in X]\n",
    "    #plt.plot(X, Y)\n",
    "    Y = [dist_dicts[j][x] for x in X]\n",
    "    axes[j].boxplot(Y, labels=X, showmeans=True)\n",
    "    #ax.xticks(np.arange(1,len(Y)+1), X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(rank_dist[x]) for x in sorted(rank_dist.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(sp_dist[x]) for x in sorted(sp_dist.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(sr_dist[x]) for x in sorted(sr_dist.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(srpath_dist[x]) for x in sorted(srpath_dist.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for j in range(len(queries)):\n",
    "    q = queries[j]\n",
    "    if q[1] > 2 and len(dat_obj.TRAJID_GROUP_DICT[q]) > 1:\n",
    "        if max(F1_sr[j], F1_srpath[j]) > max(F1_sp[j], F1_rank[j]) and \\\n",
    "        max(pF1_sr[j], pF1_srpath[j]) > max(pF1_sp[j], pF1_rank[j]) and \\\n",
    "        max(Tau_sr[j], Tau_srpath[j]) > max(Tau_sp[j], Tau_rank[j]):\n",
    "            print(j, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ix = 16\n",
    "print([F1_rank[ix], pF1_rank[ix], Tau_rank[ix]])\n",
    "print([F1_sp[ix], pF1_sp[ix], Tau_sp[ix]])\n",
    "print([F1_sr[ix], pF1_sr[ix], Tau_sr[ix]])\n",
    "print([F1_srpath[ix], pF1_srpath[ix], Tau_srpath[ix]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = (10, 3)\n",
    "dat_obj.TRAJID_GROUP_DICT[query]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[dat_obj.traj_dict[tid] for tid in dat_obj.TRAJID_GROUP_DICT[query]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rank_dict[query]['PRED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_dict[query]['PRED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sr_dict[query]['PRED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "srpath_dict[query]['PRED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%script false\n",
    "startdict = dict()\n",
    "for q in queries:\n",
    "    if q[0] in startdict: startdict[q[0]].append(q)\n",
    "    else: startdict[q[0]] = [q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%script false\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = sorted(startdict.keys())\n",
    "Y = [len(startdict[q]) for q in X]\n",
    "\n",
    "plt.plot(X, sorted(Y), '^')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#basename = 'rand-' + dat_obj.dat_suffix[dat_ix] + '.pkl'\n",
    "#basename = 'pop-' + dat_obj.dat_suffix[dat_ix] + '.pkl'\n",
    "#basename = 'rank-' + dat_obj.dat_suffix[dat_ix] + '.pkl'\n",
    "#basename = 'ssvm-A-' + dat_obj.dat_suffix[dat_ix] + '.pkl'\n",
    "#basename = 'ssvm-B-' + dat_obj.dat_suffix[dat_ix] + '.pkl'\n",
    "#basename = 'ssvm-A10-' + dat_obj.dat_suffix[dat_ix] + '.pkl'\n",
    "#basename = 'ssvm-B10-' + dat_obj.dat_suffix[dat_ix] + '.pkl'\n",
    "#basename = 'ssvm-C10-' + dat_obj.dat_suffix[dat_ix] + '.pkl'\n",
    "basename = 'ssvm-D10-' + dat_obj.dat_suffix[dat_ix] + '.pkl'\n",
    "#basename = 'ssvm-D15-' + dat_obj.dat_suffix[dat_ix] + '.pkl'\n",
    "#basename = 'ssvm-D-' + dat_obj.dat_suffix[dat_ix] + '-new2.pkl'\n",
    "\n",
    "recdict = pkl.load(open(os.path.join(dat_obj.data_dir, basename), 'rb'))\n",
    "#recdict = {q:{k: (v if k != 'PRED' else [recdict[q]['PRED']]) for k,v in recdict[q].items()} for q in recdict}\n",
    "#pkl.dump(recdict, open(os.path.join(dat_obj.data_dir, basename), 'wb'))\n",
    "do_evaluation(dat_obj, recdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recdict[query]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recrank = pkl.load(open(os.path.join(dat_obj.data_dir, 'rank-Glas.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recrank[query]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%script false\n",
    "cnt = 0\n",
    "keys = sorted(recdict.keys())\n",
    "for j in range(len(keys)):\n",
    "    q = keys[j]\n",
    "    for y in recdict[q]['PRED']:\n",
    "        if len(y) > len(set(y)): cnt += 1; print(j); break\n",
    "#print('total:', cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#len(set(recdict[keys[138]]['PRED'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cfname = 'bestC-D-' + dat_obj.dat_suffix[dat_ix] + '.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fssvm = os.path.join(data_dir, 'ssvm-D10-' + dat_obj.dat_suffix[dat_ix] + '.pkl')\n",
    "fssvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cdict = pkl.load(open(os.path.join(data_dir, cfname), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(cdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "queries = sorted(dat_obj.TRAJID_GROUP_DICT.keys())\n",
    "cnt = 1\n",
    "recdict_ssvm = dict()\n",
    "#for query in queries:\n",
    "qix = np.random.choice(np.arange(len(queries)), 5)\n",
    "for query in [queries[ix] for ix in qix]:\n",
    "    if query not in cdict:\n",
    "        sys.stderr.write('query %s does not exist in hyper-parameter dictionary.\\n' % str(query))\n",
    "        cnt += 1\n",
    "        continue\n",
    "\n",
    "    ps, L = query\n",
    "    \n",
    "    trajid_set_i = set(dat_obj.trajid_set_all) - dat_obj.TRAJID_GROUP_DICT[query]\n",
    "    poi_info_i = dat_obj.calc_poi_info(list(trajid_set_i))  \n",
    "    poi_set_i = {p for tid in trajid_set_i for p in dat_obj.traj_dict[tid] if len(dat_obj.traj_dict[tid]) >= 2}\n",
    "    if ps not in poi_set_i: \n",
    "        sys.stderr.write('start POI of query %s does not exist in training set.\\n' % str(keys[i]))\n",
    "        continue\n",
    "        \n",
    "    \n",
    "    best_C = cdict[query]\n",
    "    print('\\n--------------- %d/%d, Query: (%d, %d), Best_C: %f ---------------\\n' % (cnt, len(queries), ps, L, best_C))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    ssvm = SSVM(inference_train=do_inference_list_viterbi, inference_pred=do_inference_list_viterbi, \n",
    "                dat_obj=dat_obj, share_params=SSVM_SHARE_PARAMS, multi_label=SSVM_MULTI_LABEL, \n",
    "                C=best_C, poi_info=poi_info_i, debug=True)\n",
    "    if ssvm.train(sorted(trajid_set_i), n_jobs=N_JOBS) == True:\n",
    "        y_hat_list = ssvm.predict(ps, L)\n",
    "        print(cnt, y_hat_list)\n",
    "        if y_hat_list is not None:\n",
    "            recdict_ssvm[(ps, L)] = {'PRED': y_hat_list, 'MODEL': ssvm, 'C': ssvm.C}\n",
    "    cnt += 1\n",
    "#    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#do_evaluation(dat_obj, recdict_ssvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pkl.dump(recdict_ssvm, open(fssvm, 'bw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rec = pkl.load(open(fssvm, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = queries[0]\n",
    "assert(query in rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ssvm1_1 = rec[query]['MODEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ssvm1_1.predict(1, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nested cross-validation with Monte-Carlo cross-validation as inner loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inference_methods = [do_inference_brute_force, do_inference_list_viterbi, do_inference_viterbi, do_inference_greedy]\n",
    "methods_suffix = ['bruteForce', 'listViterbi', 'viterbi', 'greedy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "method_ix_train = 1\n",
    "method_ix_pred = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%script false\n",
    "recdict_ssvm = dict()\n",
    "cnt = 1\n",
    "keys = sorted(dat_obj.TRAJID_GROUP_DICT.keys())\n",
    "\n",
    "# outer loop to evaluate the test performance by cross validation\n",
    "#for i in range(len(keys)):\n",
    "for i in range(2):\n",
    "    ps, L = keys[i]\n",
    "    best_C = 1\n",
    "    #best_F1 = 0; best_pF1 = 0\n",
    "    best_Tau = 0\n",
    "    keys_cv = keys[:i] + keys[i+1:]\n",
    "    \n",
    "    # use all training+validation set to compute POI features, \n",
    "    # make sure features do NOT change for training and validation\n",
    "    trajid_set_i = set(dat_obj.trajid_set_all) - dat_obj.TRAJID_GROUP_DICT[keys[i]]\n",
    "    poi_info_i = dat_obj.calc_poi_info(list(trajid_set_i))\n",
    "    \n",
    "    poi_set_i = {p for tid in trajid_set_i for p in dat_obj.traj_dict[tid] if len(dat_obj.traj_dict[tid]) >= 2}\n",
    "    if ps not in poi_set_i: \n",
    "        sys.stderr.write('start POI of query %s does not exist in training set.\\n' % str(keys[i]))\n",
    "        continue\n",
    "    \n",
    "    # tune regularisation constant C\n",
    "    for ssvm_C in C_SET:\n",
    "        print('\\n--------------- try_C: %f ---------------\\n' % ssvm_C); sys.stdout.flush() \n",
    "        F1_ssvm = []; pF1_ssvm = []; Tau_ssvm = []        \n",
    "        \n",
    "        # inner loop to evaluate the performance of a model with a specified C by Monte-Carlo cross validation\n",
    "        for j in range(MC_NITER):\n",
    "            poi_list = []\n",
    "            while True: # make sure the start POI in test set are also in training set\n",
    "                rand_ix = np.arange(len(keys_cv)); np.random.shuffle(rand_ix)\n",
    "                test_ix = rand_ix[:int(MC_PORTION*len(rand_ix))]\n",
    "                assert(len(test_ix) > 0)\n",
    "                trajid_set_train = set(dat_obj.trajid_set_all) - dat_obj.TRAJID_GROUP_DICT[keys[i]]\n",
    "                for j in test_ix: \n",
    "                    trajid_set_train = trajid_set_train - dat_obj.TRAJID_GROUP_DICT[keys_cv[j]]\n",
    "                poi_set = {p for tid in sorted(trajid_set_train) for p in dat_obj.traj_dict[tid] \\\n",
    "                           if len(dat_obj.traj_dict[tid]) >= 2}\n",
    "                good_partition = True\n",
    "                for j in test_ix: \n",
    "                    if keys_cv[j][0] not in poi_set: good_partition = False; break\n",
    "                if good_partition == True: \n",
    "                    poi_list = sorted(poi_set)\n",
    "                    break\n",
    "\n",
    "            # train\n",
    "            ssvm = SSVM(inference_train=inference_methods[method_ix_train], \n",
    "                        inference_pred=inference_methods[method_ix_pred], \n",
    "                        dat_obj=dat_obj, share_params=SSVM_SHARE_PARAMS, multi_label=SSVM_MULTI_LABEL, \n",
    "                        C=ssvm_C, poi_info=poi_info_i.loc[poi_list].copy())\n",
    "            if ssvm.train(sorted(trajid_set_train), n_jobs=N_JOBS) == True:            \n",
    "                for j in test_ix: # test\n",
    "                    ps_cv, L_cv = keys_cv[j]\n",
    "                    y_hat_list = ssvm.predict(ps_cv, L_cv)\n",
    "                    if y_hat_list is not None:\n",
    "                        F1, pF1, tau = evaluate(dat_obj, keys_cv[j], y_hat_list)\n",
    "                        F1_ssvm.append(F1); pF1_ssvm.append(pF1); Tau_ssvm.append(tau)\n",
    "            else: \n",
    "                for j in test_ix:\n",
    "                    F1_ssvm.append(0); pF1_ssvm.append(0); Tau_ssvm.append(0)\n",
    "        \n",
    "        #mean_F1 = np.mean(F1_ssvm); mean_pF1 = np.mean(pF1_ssvm)\n",
    "        mean_Tau = np.mean(Tau_ssvm)\n",
    "        print('mean_Tau: %.3f' % mean_Tau)\n",
    "        if mean_Tau > best_Tau:\n",
    "            best_Tau = mean_Tau\n",
    "            best_C = ssvm_C\n",
    "            \n",
    "    #best_C = recdict[(ps, L)]['C']\n",
    "    print('\\n--------------- %d/%d, Query: (%d, %d), Best_C: %f ---------------\\n' % (cnt, len(keys), ps, L, best_C))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    \n",
    "    # train model using all examples in training set and measure performance on test set\n",
    "    ssvm = SSVM(inference_train=inference_methods[method_ix_train], inference_pred=inference_methods[method_ix_pred], \n",
    "                dat_obj=dat_obj, share_params=SSVM_SHARE_PARAMS, multi_label=SSVM_MULTI_LABEL, \n",
    "                C=best_C, poi_info=poi_info_i)#, debug=True)\n",
    "    if ssvm.train(sorted(trajid_set_i), n_jobs=N_JOBS) == True:\n",
    "        y_hat_list = ssvm.predict(ps, L)\n",
    "        print(cnt, y_hat_list)\n",
    "        if y_hat_list is not None:\n",
    "            recdict_ssvm[(ps, L)] = {'PRED': y_hat_list, 'W': ssvm.osssvm.w, 'C': ssvm.C}\n",
    "        \n",
    "    cnt += 1; #print_progress(cnt, len(keys)); sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%script false\n",
    "do_evaluation(dat_obj, recdict_ssvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%script false\n",
    "fssvm = os.path.join(dat_obj.data_dir, 'ssvm-' + methods_suffix[method_ix_train] + '-' + \\\n",
    "                     methods_suffix[method_ix_pred] + '-' + dat_obj.dat_suffix[dat_ix] + '-ml.pkl')\n",
    "pkl.dump(recdict_ssvm, open(fssvm, 'bw'))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
