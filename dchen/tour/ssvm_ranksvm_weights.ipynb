{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSVM with RankSVM Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This experiment is to use the trained RankSVM weights as the node weights (share weights among nodes) in SSVM.    \n",
    "By turning off transition features (i.e., both features and parameters are set to zero), we use SSVM inference to do prediction, and compare the recommendation by RankSVM and SSVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, pickle, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cvxopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(1234554321)\n",
    "np.random.seed(123456789)\n",
    "cvxopt.base.setseed(123456789)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run notebook ```ssvm.ipynb```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run 'ssvm.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load trained RankSVM parameters and prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = os.path.join(data_dir, 'rank-Glas.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rank_dict = pickle.load(open(fname, 'rb'))  # a dict: query -> {'PRED': trajectory, 'C': ranksvm-c, 'W': model_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(rank_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluation(predictions):\n",
    "    F1_all = []; pF1_all = []; tau_all = []\n",
    "    for key in sorted(predictions.keys()):\n",
    "        F1, pF1, tau = evaluate(predictions[key]['PRED'], TRAJ_GROUP_DICT[key])\n",
    "        F1_all.append(F1); pF1_all.append(pF1); tau_all.append(tau)\n",
    "    F1_mean = np.mean(F1_all); pF1_mean = np.mean(pF1_all); tau_mean = np.mean(tau_all)\n",
    "    print('F1 (%.3f, %.3f), pairsF1 (%.3f, %.3f), Tau (%.3f, %.3f)' % \\\n",
    "          (F1_mean, np.std(F1_all)/np.sqrt(len(F1_all)), \\\n",
    "           pF1_mean, np.std(pF1_all)/np.sqrt(len(pF1_all)), \\\n",
    "           tau_mean, np.std(tau_all)/np.sqrt(len(tau_all))))\n",
    "    return F1_mean, pF1_mean, tau_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate RankSVM predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluation(rank_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SSVM prediction using RankSVM weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_edge_features = 5\n",
    "\n",
    "predictions = dict()\n",
    "cnt = 1\n",
    "queries = sorted(rank_dict.keys())\n",
    "for q in queries:\n",
    "    ps, L = q\n",
    "    \n",
    "    # compute feature scaling parameters\n",
    "    trajid_set = set(trajid_set_all) - TRAJ_GROUP_DICT[q]\n",
    "    poi_set = set()\n",
    "    for tid in trajid_set: \n",
    "        if len(traj_dict[tid]) >= 2:\n",
    "            poi_set = poi_set | set(traj_dict[tid])\n",
    "    poi_list = sorted(poi_set)\n",
    "    poi_id_dict, poi_id_rdict = dict(), dict()\n",
    "    for idx, poi in enumerate(poi_list):\n",
    "        poi_id_dict[poi] = idx\n",
    "        poi_id_rdict[idx] = poi\n",
    "    n_states = len(poi_list)\n",
    "        \n",
    "    poi_info = calc_poi_info(sorted(trajid_set), traj_all, poi_all)\n",
    "\n",
    "    traj_list = [traj_dict[k] for k in sorted(trajid_set) if len(traj_dict[k]) >= 2]\n",
    "    node_features_list = Parallel(n_jobs=N_JOBS)\\\n",
    "                         (delayed(calc_node_features)\\\n",
    "                          (tr[0], len(tr), poi_list, poi_info.copy(), poi_clusters=POI_CLUSTERS, \\\n",
    "                           cats=POI_CAT_LIST, clusters=POI_CLUSTER_LIST) for tr in traj_list)\n",
    "    #edge_features = calc_edge_features(list(trajid_set), poi_list, traj_dict, poi_info.copy())\n",
    "    fdim = node_features_list[0].shape\n",
    "    X_node_all = np.vstack(node_features_list)\n",
    "    #scaler = MaxAbsScaler(copy=False)\n",
    "    scaler = MinMaxScaler(feature_range=(-1,1), copy=False)\n",
    "    scaler.fit(X_node_all)\n",
    "    \n",
    "    # features scaling\n",
    "    X_node_test = calc_node_features(ps, L, poi_list, poi_info, poi_clusters=POI_CLUSTERS, \\\n",
    "                                     cats=POI_CAT_LIST, clusters=POI_CLUSTER_LIST)\n",
    "    X_node_test = scaler.transform(X_node_test)  # feature scaling\n",
    "    \n",
    "    # inference\n",
    "    W = rank_dict[q]['W']\n",
    "    unary_params = np.tile(W, (n_states, 1))\n",
    "    pw_params = np.zeros((n_states, n_states, n_edge_features))\n",
    "    unary_features = X_node_test\n",
    "    #pw_features = edge_features.copy()\n",
    "    pw_features = np.zeros(pw_params.shape)\n",
    "        \n",
    "    y_pred = do_inference_listViterbi(poi_id_dict[ps],L,len(poi_list),unary_params,pw_params,unary_features,pw_features)\n",
    "    #y_pred = do_inference_viterbi(poi_id_dict[ps], L,len(poi_list),unary_params,pw_params,unary_features,pw_features)\n",
    "    predictions[q] = {'PRED': [poi_id_rdict[p] for p in y_pred]}\n",
    "    \n",
    "    print(cnt, rank_dict[q]['PRED'], '->', predictions[q]['PRED']); cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate SSVM predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluation(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
