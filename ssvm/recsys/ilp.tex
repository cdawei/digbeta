% !TEX root=main.tex

% \blue{
% We should probably ask Phil Kilby or Hassan about the two or three most popular subtour eliminations

% \begin{itemize}
% 	\item Elementary shortest path problems
%   %http://www.optimization-online.org/DB_FILE/2014/09/4560.pdf
% 	\item Different subtour eliminations
%   	\item (Dantzig, Fulkerson, Johnson, 1954) has 3 different versions
%   	\item (Miller, Tucker, Zemlin, 1960) has another one.
%   	\item Seems to be one more, not sure by whom (maybe Belmore, Malone, 1971)
%   %http://www.or.unc.edu/~pataki/papers/teachtsp.pdf

% \end{itemize}
% }

One exact approach to solve Equation \ref{eqn:att-recurrence}
relies on the observation that
it bears similarity to the classical travelling salesman problem (TSP).
Indeed, if the length $l = |\PCal|$, so that every POI is restricted to be visit once,
then we exactly get the TSP problem;
however, for smaller $l$, we require visiting only a \emph{subset} of POIs.
This means the problem is not a vanilla instance of TSP.

Nonetheless, we may take inspiration from methods to solve the TSP to attack our problem.
In particular, 
we can formulate the trip recommendation problem as an \emph{integer linear program} (\emph{ILP}),
which can be solved with an off-the-shelf solver (\eg {\tt Gurobi}) \citep{opt98}.
% Instead of simply bypassing repeated revisits, 
% we can make use of subtour elimination techniques developped by the TSP research community,
% by formulating the trip recommendation problem with integer linear programming (ILP).
%The additional benefits of this formulation is that fixing the subset of POIs is not required any more,
%we can optimise over all possible subset of POIs using the off-the-shelf ILP solvers.
Formally, given a starting location $s$ and the required trip length $l$,
we maximise the desired trip score over all possible subsets with $l$ POIs from the whole set of POIs $\{p_j\}_{j=1}^m$
by solving
\begin{align*}
%\max_{\bu} & \sum_{k=1}^m \w_k^\top \psi_k(\x, p_k) \sum_{j=1}^m u_{jk} +
%             \sum_{j,k=1}^m u_{jk} \w_{jk}^\top \psi_{j, k}(\x, p_j, p_k) \\
\max_{\bu} & \sum_{k=1}^m \alpha( p_k ) \cdot \sum_{j=1}^m u_{jk} +
            \sum_{j,k=1}^m u_{jk} \cdot \beta( p_j, p_k ) \\
s.t. 
& \sum_{k=2}^m u_{1k} = 1, \, \sum_{j=2}^m u_{j1} = z_1=0  \\                %\label{eq:cons1} \\
& \sum_{j=1}^m \sum_{k=1}^m u_{jk} = l-1, \, \sum_{j=1}^m u_{jj}=0  \\      %\label{eq:cons2}
& \sum_{j=1}^m u_{ji} = z_i + \sum_{k=2}^m u_{ik} \le 1, \, (\forall i \in \{2,\cdots,m\})  \\ %\label{eq:cons3} \\
& v_j - v_k + 1 \le (m-1) (1-u_{jk}), \, (\forall j,k \in \{2,\cdots,m\}).                 %\label{eq:cons4}
\end{align*}
Here, $u_{jk}$ are binary variables that are true if and only if
we visit $p_k$ immediately after visiting $p_j$,
and binary variables $z_j$ indicate whether we end up at $p_j$.
By reading off the values of $u_{jk}$, we can thus determine the predicted sequence.
Note that we index POIs such that $s = p_1$ for brevity,
and we strictly ask for a path that starts from $s$ and travels $l$ distinct POIs.

The above ILP implicitly solves both the problem of selecting the set of $l$ POIs to recommend,
and the problem of ordering them.
We could fix the set of POIs to recommend, \eg by using the POIs in the Viterbi solution;
however, we have found such an approach to have only modest improvement over the loop elimination heuristic of the previous section, which also builds upon the Viterbi solution.
