%!TEX root = main.tex

\secmoveup
\section{Introduction}
\label{sec:intro}
\textmoveup

Content recommendation has been the subject of a rich body of literature~\citep{Goldberg:1992,Sarwar:2001,Koren:2010},
with established techniques seeing widespread adoption in large e-commerce companies~\citep{Linden:2003,Agarwal:2013,Amatriain:2015,Gomez-Uribe:2015}.
The success of these methods is explained by both the explosion in availability of user's explicit and implicit preferences for content,
as well as the design of methods that can suitably exploit these to make useful recommendations~\citep{Koren:2009}.

For the most part, models for recommendation have been limited to the case of static, \emph{unstructured} content.
While this setting has considerable value by itself,
in many important scenarios one needs to recommend content that possesses some \emph{structure}.
In its simplest form, this structure may be manifest by the items we wish to recommend being \emph{sequential} in nature.
For example, consider the problem of recommending a playlist of songs to users based on their listening history~\citep{McFee:2011,chen2012playlist},
or alternately,
recommending a trajectory of points of interest in a city to a visitor~\citep{lu2010photo2trip,lu2012personalized,ijcai15,cikm16paper}.

A na\"{i}ve approach to such sequential recommendation problems is to simply ignore the structure,
and learn a standard recommendation model.
In the playlist example, we could learn a user's preference for individual songs,
and then create a playlist based on the top ranked songs.
However, it is easy to construct cases where such an approach is sub-optimal:
%This however completely ignores the fact that while a user's
for example, while a user's two favourite songs might belong
the metal and country genres respectively,
it is questionable that a playlist featuring these songs in succession will be as enjoyable to the user.
Similarly, in the trajectory recommendation problem, it is unlikely a user will want to visit three restaurants in a row.

The above raises the question of how one can effectively learn from such sequential content.
In this paper, we show how to cast sequence recommendation as a \emph{structured prediction} problem,
which allows us to leverage the toolkit of structured SVMs~\citep{tsochantaridis2005large}.
However, a vanilla application of such methods does not suffice,
as they do not account for the fact that each input can have multiple ground truths,
and the fact that \emph{loops} in predicted sequences are undesirable.
We show how one can overcome this by
suitably normalising the loss function for the model,
and by modifying the inference and prediction steps of the model using a variant of the Viterbi algorithm.
Specifically, our contributions are as follows:
\begin{itemize}[noitemsep]\itemmoveup
	\item We cast the problem of sequence recommendation as a structured prediction task, and show how this may be modelled using structured SVMs (\S\ref{sec:recseq}).
	\item We propose an important correction to the na\"{i}ve implementation of structured SVMs to the recommendation problem, so as to account for the existence of multiple ground truths for each input (\S\ref{ssec:sr}). Following \citet{joachims2009cutting} we propose both $n$-slack and 1-slack versions of the structured recommender.\footnote{This new structured recommender can in principle be applied to any problem where loss augmented inference can be efficiently computed. We focus on sequence recommendation in this paper.}
	\item We show how one can avoid recommending sequences with loops or repetitions via an extension of the classic Viterbi algorithm that returns a list of the highest scored sequences under some model; we show that this extension may be incorporated during both the training (via loss augmented inference) and prediction steps of our structured recommendation (\S\ref{ssec:subtour}).
	\item We explicate how trajectory recommendation can be seen as a sequential recommendation task (\S\ref{sec:trajrec}). We then present experiments on two real-world trajectory recommendation problems, and demonstrate our structured prediction approaches to offer consistent benefits over existing non-structured baselines (\S\ref{sec:experiment}).\itemmoveup
\end{itemize}

%We begin with an overview of related work, before presenting our model.
%We begin with an overview of the sequence recommendation problem, before presenting our model.
